# Table of Contents

1. [Secci√≥n 1](#ch1)


<a id='ch1'></a>

# Aplicaci√≥n de T√©cnicas de Validaci√≥n Cruzada
‚Ä¢ **Objetivo:**  
Aplicar y comparar diferentes t√©cnicas de validaci√≥n cruzada y m√©tricas de evaluaci√≥n sobre un modelo predictivo, utilizando datos reales. El estudiante deber√° interpretar y justificar los resultados obtenidos en base a las m√©tricas de rendimiento como precisi√≥n, recall, F1-Score, matriz de confusi√≥n, y curvas ROC y Precision-Recall.   

‚Ä¢ **Contexto:**  
Dado un conjunto de datos sobre clientes (por ejemplo, predicci√≥n de si un cliente abandonar√° un servicio o si tiene
una alta probabilidad de fraude), el objetivo es aplicar t√©cnicas de validaci√≥n cruzada para evaluar la precisi√≥n  del
modelo, analizando la capacidad de generalizaci√≥n del mismo.

----

Este notebook tiene como objetivo realizar una aplicaci√≥n y comparaci√≥n rigurosa de diferentes t√©cnicas de validaci√≥n cruzada sobre un modelo predictivo. Se profundizar√° en la interpretaci√≥n de m√©tricas de rendimiento clave (Precisi√≥n, Recall, F1-Score, Matriz de Confusi√≥n, Curvas ROC y Precision-Recall) para evaluar de manera robusta la capacidad de generalizaci√≥n y la estabilidad de un modelo en un problema de clasificaci√≥n del mundo real.

### Estructura del Notebook

1.  **Configuraci√≥n del Entorno y Carga de Datos**: Importaci√≥n de librer√≠as y carga robusta del dataset.
2.  **Preprocesamiento y Creaci√≥n de Pipelines**: Encapsulamiento de la preparaci√≥n de datos para prevenir la fuga de informaci√≥n (data leakage).
3.  **Divisi√≥n Estrat√©gica de Datos**: Separaci√≥n de los datos en conjuntos de entrenamiento y prueba.
4.  **Evaluaci√≥n Comparativa con Validaci√≥n Cruzada**: Aplicaci√≥n y an√°lisis detallado de K-Fold, Stratified K-Fold y Leave-One-Out.
5.  **Entrenamiento y Evaluaci√≥n Final del Modelo**: Entrenamiento del modelo definitivo y su evaluaci√≥n en el conjunto de prueba.
6.  **Visualizaci√≥n e Interpretaci√≥n de Resultados**: Creaci√≥n de gr√°ficos avanzados para un an√°lisis profundo del rendimiento.
7.  **An√°lisis Comparativo y Conclusiones**: Discusi√≥n de los hallazgos y justificaci√≥n de la t√©cnica m√°s adecuada.

-----

## 1\. Configuraci√≥n del Entorno y Carga de Datos

### 1.1. Importaci√≥n de Librer√≠as

Antes de cualquier an√°lisis, es fundamental importar las herramientas (librer√≠as) que necesitaremos. Organizar las importaciones al principio del script es una buena pr√°ctica que mejora la legibilidad y asegura que todos los requisitos est√©n definidos desde el inicio. Las agrupamos por funcionalidad para entender r√°pidamente qu√© tipo de operaciones se realizar√°n:

  * **Manipulaci√≥n de Datos**: `pandas` y `numpy` son el est√°ndar de oro en Python para trabajar con datos estructurados y realizar operaciones num√©ricas eficientes.
  * **Visualizaci√≥n**: `matplotlib` y `seaborn` nos permiten crear gr√°ficos est√°ticos y est√©ticamente agradables para interpretar los resultados de forma visual.
  * **Preprocesamiento y Modelado**: `scikit-learn` es la librer√≠a m√°s importante para Machine Learning en Python. De ella importamos m√≥dulos espec√≠ficos para cada tarea: preprocesamiento de datos, modelos de clasificaci√≥n, estrategias de validaci√≥n cruzada y m√©tricas de evaluaci√≥n.

<!-- end list -->


---

```python
# --- Fundamentales para Manipulaci√≥n de Datos ---
import pandas as pd
import numpy as np
# import warnings
# warnings.filterwarnings('ignore') # Ignorar advertencias para una salida m√°s limpia

# --- Librer√≠as para Visualizaci√≥n ---
import matplotlib.pyplot as plt
import seaborn as sns

# --- M√≥dulos de Scikit-learn para Preprocesamiento ---
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# --- Modelos y M√©tricas de Scikit-learn ---
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import (cross_val_score, cross_validate,
                                   KFold, StratifiedKFold, LeaveOneOut, TimeSeriesSplit)
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                           roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,
                           classification_report, roc_curve, precision_recall_curve)

# --- Configuraci√≥n de Estilo para Visualizaciones ---
# Define un estilo visual consistente y agradable para todos los gr√°ficos.
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("viridis")
print("‚úì Librer√≠as importadas y entorno configurado.")
```

```
‚úì Librer√≠as importadas y entorno configurado.

```


---

```python
%pip install kagglehub
```

```
Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)
Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)
Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)
Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)

```


---

2. [Secci√≥n 2](#ch2)


<a id='ch2'></a>

### **Carga de Datos a Prueba de Fallos**

Imaginemos que necesitamos construir un modelo predictivo, pero para empezar, necesitamos los datos. Este c√≥digo act√∫a como un asistente de log√≠stica de datos muy inteligente y precavido. Su misi√≥n principal es obtener un conjunto de datos espec√≠fico sobre la cancelaci√≥n de clientes de una empresa de telecomunicaciones (Telco) desde la plataforma Kaggle.

Sin embargo, su caracter√≠stica m√°s profesional es que **est√° preparado para el fracaso**. Sabe que las descargas por internet pueden fallar por muchas razones (no hay conexi√≥n, un error en el servidor, credenciales incorrectas, etc.). En lugar de simplemente detenerse y mostrar un error, tiene un ingenioso **plan de respaldo** para asegurar que siempre tengas datos con los que trabajar.

---

### **El Proceso Principal: El Intento de Descarga**

La primera acci√≥n que realiza el c√≥digo es intentar el "camino ideal":
1.  **Conexi√≥n con Kaggle:** Utiliza una herramienta especializada para conectarse a Kaggle y solicita la descarga del dataset "Telco Customer Churn".
2.  **Verificaci√≥n del Archivo:** Una vez descargado el paquete, no da por sentado que todo est√© bien. Realiza una segunda verificaci√≥n para asegurarse de que el archivo CSV espec√≠fico que necesita est√° realmente all√≠ y es accesible.
3.  **Carga Exitosa:** Si todo sale bien, carga los datos en una tabla estructurada (un DataFrame) y le pone una etiqueta interna de `"telco"` para recordar que est√° trabajando con los datos reales.

---

### **El Plan de Respaldo: Creaci√≥n de Datos Sint√©ticos**

Si en alg√∫n punto del proceso anterior algo sale mal, se activa el plan de respaldo. En lugar de rendirse, el c√≥digo decide **fabricar un conjunto de datos artificial** que se parezca lo m√°s posible al original.

Este no es un conjunto de datos aleatorio y sin sentido. Est√° cuidadosamente dise√±ado para imitar las propiedades estad√≠sticas clave del dataset real:

* **Tama√±o Id√©ntico:** Crea exactamente el mismo n√∫mero de filas que el original (7,043 clientes).
* **Estructura Similar:** Genera un n√∫mero similar de columnas o caracter√≠sticas.
* **Desbalance de Clases Realista:** Este es un punto crucial. Sabe que en el dataset real, aproximadamente el 27% de los clientes cancelaron su servicio. El c√≥digo replica esta misma proporci√≥n en los datos falsos. Esto es vital para entrenar un modelo de machine learning de manera realista.
* **Consistencia Garantizada:** Gracias a una "semilla" num√©rica fija, cada vez que genera los datos sint√©ticos, estos son **exactamente los mismos**. Esto asegura que los experimentos y pruebas que se realicen con estos datos sean siempre consistentes y reproducibles.

Cuando termina de crear esta tabla artificial, le asigna una etiqueta interna de `"synthetic"` para que el sistema sepa que est√° usando el plan de respaldo.

---

### **Verificaci√≥n y Resumen**

Una vez que el c√≥digo ha obtenido los datos, ya sea por la v√≠a real o por el plan de respaldo, ejecuta un √∫ltimo paso: presentar un informe.

Muestra en pantalla un resumen claro y conciso que informa al usuario sobre lo que acaba de suceder:
1.  **Informa qu√© tipo de datos se cargaron**: Muestra claramente si se est√° usando el dataset `"TELCO"` (real) o el `"SYNTHETIC"` (artificial).
2.  **Muestra las dimensiones**: Indica cu√°ntas filas y columnas tiene la tabla de datos.
3.  **Presenta una Muestra**: Muestra las primeras cinco filas de la tabla para que el usuario pueda hacer una r√°pida inspecci√≥n visual.

En resumen, este script es un ejemplo de **programaci√≥n defensiva y robusta**. Su dise√±o modular y su capacidad para manejar errores lo convierten en una herramienta profesional que garantiza la continuidad del trabajo, incluso cuando las condiciones no son ideales.


---

```python
import kagglehub
import os
import pandas as pd
from sklearn.datasets import make_classification

def create_synthetic_dataset():
    """Crea un dataset sint√©tico como respaldo si la descarga falla."""
    print("‚ö†Ô∏è Creando dataset sint√©tico como respaldo...")

    X_synthetic, y_synthetic = make_classification(
        n_samples=7043,          # Mismo n√∫mero de clientes que el dataset Telco original
        n_features=19,           # Similar n√∫mero de caracter√≠sticas predictoras
        n_informative=15,        # Caracter√≠sticas que realmente aportan informaci√≥n
        n_redundant=4,           # Caracter√≠sticas que son combinaciones de las informativas
        n_clusters_per_class=1,  # Estructura de los datos
        weights=[0.73, 0.27],    # Proporci√≥n similar de clases (No Churn vs Churn)
        random_state=42          # Semilla para reproducibilidad
    )

    # Crear un DataFrame de Pandas
    feature_names = [f'feature_{i}' for i in range(19)]
    df = pd.DataFrame(X_synthetic, columns=feature_names)
    df['Churn'] = y_synthetic

    print("‚úì Dataset sint√©tico creado con √©xito.")
    return df, "synthetic"

def load_telco_dataset():
    """Carga el dataset 'Telco Customer Churn' desde Kaggle Hub."""
    try:
        # Intentar descargar el dataset
        print("üîÑ Descargando dataset desde Kaggle Hub...")
        path = kagglehub.dataset_download("blastchar/telco-customer-churn")
        print(f"‚úì Dataset descargado en la ruta: {path}")

        # Construir la ruta completa al archivo CSV
        file_name = 'WA_Fn-UseC_-Telco-Customer-Churn.csv'
        full_path = os.path.join(path, file_name)

        # Verificar si el archivo existe y cargarlo
        if os.path.exists(full_path):
            df = pd.read_csv(full_path)
            print(f"‚úì Dataset cargado exitosamente desde: {full_path}")
            return df, "telco"
        else:
            print(f"‚ùå Archivo no encontrado en la ruta: {full_path}")
            return create_synthetic_dataset()

    except Exception as e:
        print(f"‚ùå Error durante la descarga del dataset: {e}")
        return create_synthetic_dataset()

def show_dataset_info(df, dataset_type):
    """Muestra informaci√≥n b√°sica y las primeras filas del dataset cargado."""
    if df is not None:
        print("\n" + "="*50)
        print(f"üìä TIPO DE DATASET CARGADO: {dataset_type.upper()}")
        print("="*50)
        print(f"üìê Forma del dataset: {df.shape}")
        print("\nüîç Primeras 5 filas:")
        print(df.head())
        print("="*50 + "\n")
    else:
        print("‚ùå El DataFrame no est√° disponible para mostrar informaci√≥n.")

# --- EJECUCI√ìN PRINCIPAL DEL BLOQUE 1 ---
# Cargar el dataset (real o sint√©tico como respaldo)
df, dataset_type = load_telco_dataset()

# Mostrar informaci√≥n b√°sica del dataset que se ha cargado
show_dataset_info(df, dataset_type)
```

```
üîÑ Descargando dataset desde Kaggle Hub...
Using Colab cache for faster access to the 'telco-customer-churn' dataset.
‚úì Dataset descargado en la ruta: /kaggle/input/telco-customer-churn
‚úì Dataset cargado exitosamente desde: /kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv

==================================================
üìä TIPO DE DATASET CARGADO: TELCO
==================================================
üìê Forma del dataset: (7043, 21)

üîç Primeras 5 filas:
   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \
0  7590-VHVEG  Female              0     Yes         No       1           No   
1  5575-GNVDE    Male              0      No         No      34          Yes   
2  3668-QPYBK    Male              0      No         No       2          Yes   
3  7795-CFOCW    Male              0      No         No      45           No   
4  9237-HQITU  Female              0      No         No       2          Yes   

      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \
0  No phone service             DSL             No  ...               No   
1                No             DSL            Yes  ...              Yes   
2                No             DSL            Yes  ...               No   
3  No phone service             DSL            Yes  ...              Yes   
4                No     Fiber optic             No  ...               No   

  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \
0          No          No              No  Month-to-month              Yes   
1          No          No              No        One year               No   
2          No          No              No  Month-to-month              Yes   
3         Yes          No              No        One year               No   
4          No          No              No  Month-to-month              Yes   

               PaymentMethod MonthlyCharges  TotalCharges Churn  
0           Electronic check          29.85         29.85    No  
1               Mailed check          56.95        1889.5    No  
2               Mailed check          53.85        108.15   Yes  
3  Bank transfer (automatic)          42.30       1840.75    No  
4           Electronic check          70.70        151.65   Yes  

[5 rows x 21 columns]
==================================================


```


---

3. [Secci√≥n 3](#ch3)


<a id='ch3'></a>

### **La Investigaci√≥n del Detective de Datos üïµÔ∏è‚Äç‚ôÇÔ∏è**

Este c√≥digo realiza lo que se conoce como un **An√°lisis Exploratorio de Datos** (o EDA, por sus siglas en ingl√©s). Piensa en √©l como el trabajo de un detective al llegar a la escena de un crimen. Antes de acusar a nadie o formular una teor√≠a compleja, el detective primero examina toda la evidencia, toma notas, busca pistas, identifica a los involucrados y trata de entender el contexto general.

De la misma manera, este script no construye un modelo predictivo ni llega a conclusiones finales. Su √∫nico objetivo es **"interrogar" a los datos** para comprender a fondo su estructura, identificar posibles problemas, descubrir patrones interesantes y visualizar sus caracter√≠sticas m√°s importantes. Este paso es fundamental y sienta las bases para cualquier proyecto de ciencia de datos exitoso.

---

### **Paso 1: Preparaci√≥n de la "Escena del Crimen"**

Antes de que comience el an√°lisis principal, el c√≥digo realiza una preparaci√≥n esencial para asegurarse de que la investigaci√≥n sea limpia y no contamine la evidencia original.

1.  **Crear una Copia Segura:** Primero, crea un duplicado exacto del conjunto de datos original. Esto es una pr√°ctica profesional crucial que permite experimentar y hacer modificaciones para el an√°lisis sin alterar ni da√±ar los datos originales.

2.  **Limpieza Espec√≠fica:** A continuaci√≥n, realiza un par de ajustes b√°sicos que son necesarios *solo si* est√° trabajando con el conjunto de datos real de "Telco" (y no con una versi√≥n sint√©tica).
    * **Corregir un Campo Num√©rico:** Se enfoca en la columna que registra los "cargos totales" de un cliente. A veces, esta columna puede contener valores que no son n√∫meros (por ejemplo, un espacio en blanco para clientes nuevos). El c√≥digo convierte toda la columna a un formato estrictamente num√©rico, marcando cualquier valor problem√°tico como "desconocido" o "nulo" para poder manejarlo despu√©s.
    * **Eliminar Identificadores In√∫tiles:** Descarta la columna de "ID de Cliente". Al igual que el n√∫mero de c√©dula de una persona, este es un identificador √∫nico que no ofrece ninguna pista sobre su comportamiento. No ayuda a predecir si un cliente se dar√° de baja, por lo que se elimina para simplificar el an√°lisis.

---

### **Paso 2: El Proceso de Investigaci√≥n Sistem√°tica**

Una vez que la escena est√° preparada, el "detective" comienza su investigaci√≥n en una secuencia l√≥gica y ordenada.

1.  **Revisi√≥n del "Expediente General":** El primer paso es obtener una vista panor√°mica de los datos. El c√≥digo genera un informe que responde a preguntas b√°sicas como: ¬øCu√°ntos registros (clientes) hay? ¬øCu√°ntas columnas (caracter√≠sticas) tenemos? ¬øQu√© tipo de dato contiene cada columna (texto, n√∫meros enteros, decimales)? Esto es como leer la car√°tula de un expediente para entender su contenido.

2.  **An√°lisis Forense de los N√∫meros:** A continuaci√≥n, se centra exclusivamente en las columnas num√©ricas (como la antig√ºedad del cliente, el pago mensual, etc.). Calcula un resumen estad√≠stico que revela la media (el promedio), la desviaci√≥n est√°ndar (qu√© tan dispersos est√°n los datos), el valor m√≠nimo, el m√°ximo y los percentiles. Esto ayuda a detectar r√°pidamente anomal√≠as, como un pago mensual de cero o un cliente con una antig√ºedad imposiblemente alta.

3.  **B√∫squeda de "Evidencia Faltante":** Un paso cr√≠tico en cualquier investigaci√≥n es saber qu√© informaci√≥n *no* se tiene. El c√≥digo recorre cada columna y cuenta meticulosamente cu√°ntas celdas est√°n vac√≠as o nulas. Este informe es vital, ya que los valores faltantes pueden arruinar un modelo si no se tratan adecuadamente m√°s adelante.

4.  **Foco en el "Asunto Principal" - El Churn:** Ahora, la investigaci√≥n se centra en la variable m√°s importante: la columna "Churn", que indica si un cliente abandon√≥ la empresa o no. El script realiza dos cosas:
    * **Visualizaci√≥n:** Crea un gr√°fico de barras muy claro que muestra visualmente cu√°ntos clientes se quedaron en comparaci√≥n con cu√°ntos se fueron.  Esto permite ver de un vistazo si existe un desbalance significativo entre las dos clases.
    * **C√°lculo de Proporciones:** Adem√°s del gr√°fico, calcula y muestra los porcentajes exactos. Por ejemplo, podr√≠a informar que "el 73.46% de los clientes no cancelaron, mientras que el 26.54% s√≠ lo hicieron".

5.  **An√°lisis de las Variables Categ√≥ricas:** Finalmente, el c√≥digo examina todas las dem√°s caracter√≠sticas que son textuales o categ√≥ricas (como el g√©nero, si tienen servicio de internet, el tipo de contrato, etc.). Para cada una de estas columnas, genera un gr√°fico de barras individual que muestra la distribuci√≥n de sus valores. Por ejemplo, un gr√°fico mostrar√° cu√°ntos clientes tienen contrato mes a mes, a un a√±o o a dos a√±os. Esta serie de visualizaciones es extremadamente √∫til para descubrir qu√© grupos de clientes son m√°s comunes y para empezar a formular hip√≥tesis sobre qu√© caracter√≠sticas podr√≠an estar relacionadas con la cancelaci√≥n del servicio. üìä

---

### **Conclusi√≥n: El Informe del Detective**

Al final de la ejecuci√≥n, el script no entrega una respuesta definitiva, sino algo mucho m√°s valioso en esta etapa: un **informe completo y comprensible sobre el estado de los datos**. El analista ahora sabe la estructura, las fortalezas, las debilidades (como los datos faltantes) y los patrones visuales m√°s evidentes de su conjunto de datos, y est√° perfectamente preparado para la siguiente fase: la construcci√≥n del modelo predictivo.


---

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd # Asegurarse de que pandas est√° importado aqu√≠

print("--- Iniciando An√°lisis Exploratorio de Datos (EDA) ---")

# --- Limpieza Inicial para el EDA (solo si es el dataset Telco) ---
# Se realiza una copia para no alterar el DataFrame original durante el an√°lisis.
df_eda = df.copy()

# Asegurarse de que dataset_type est√° disponible
if 'dataset_type' not in locals():
    print("Advertencia: 'dataset_type' no est√° definido. Asumiendo dataset 'telco' para EDA.")
    dataset_type = "telco" # Asumir telco si no est√° definido

if dataset_type == "telco":
    # Convertir 'TotalCharges' a num√©rico para poder calcular estad√≠sticas.
    # Usar errors='coerce' para convertir valores no num√©ricos en NaN.
    df_eda['TotalCharges'] = pd.to_numeric(df_eda['TotalCharges'], errors='coerce')
    # Eliminar 'customerID', que es un identificador √∫nico y no aporta valor predictivo.
    df_eda = df_eda.drop('customerID', axis=1, errors='ignore')

# 1. Informaci√≥n General y Tipos de Datos
print("\n--- 1. Informaci√≥n General del DataFrame ---")
df_eda.info()

# 2. Estad√≠sticas Descriptivas para Columnas Num√©ricas
print("\n--- 2. Estad√≠sticas Descriptivas (Columnas Num√©ricas) ---")
numeric_cols_eda = df_eda.select_dtypes(include=np.number).columns
if not numeric_cols_eda.empty:
    # Asegurarse de que TotalCharges es num√©rico antes de describe()
    # Si TotalCharges a√∫n tiene NaNs despu√©s de coerce, describe() lo manejar√°.
    display(df_eda[numeric_cols_eda].describe())
else:
    print("No se encontraron columnas num√©ricas para describir.")

# 3. Verificaci√≥n de Valores Faltantes
print("\n--- 3. Conteo de Valores Faltantes por Columna ---")
print(df_eda.isnull().sum())

# 4. Distribuci√≥n de la Variable Objetivo ('Churn')
print("\n--- 4. Distribuci√≥n de la Variable Objetivo (Churn) ---")
plt.figure(figsize=(7, 5))
# Usar hue='Churn' y legend=False para evitar FutureWarning
sns.countplot(x='Churn', data=df_eda, palette='viridis', hue='Churn', legend=False)
plt.title('Distribuci√≥n de Clases (Churn)', fontsize=14, fontweight='bold')
plt.xlabel('Churn')
plt.ylabel('Frecuencia')
plt.show()

# Imprimir la proporci√≥n para mayor claridad
churn_counts = df_eda['Churn'].value_counts() # Usar value_counts sin normalize=True aqu√≠
print("Proporci√≥n de Churn:")
total_samples = df_eda.shape[0]
# Iterar a trav√©s de las cuentas y imprimir la proporci√≥n formateada
for class_label, count in churn_counts.items():
    proportion = count / total_samples
    print(f"  {class_label}: {proportion:.2%}")


# 5. Visualizaci√≥n de Variables Categ√≥ricas
print("\n--- 5. Distribuci√≥n de Variables Categ√≥ricas ---")
categorical_cols_eda = df_eda.select_dtypes(include=['object', 'category']).columns.tolist()
if 'Churn' in categorical_cols_eda:
    categorical_cols_eda.remove('Churn')

if categorical_cols_eda:
    n_cols = 3
    n_rows = (len(categorical_cols_eda) + n_cols - 1) // n_cols
    plt.figure(figsize=(n_cols * 5, n_rows * 4))

    for i, col in enumerate(categorical_cols_eda):
        plt.subplot(n_rows, n_cols, i + 1)
        # Usar hue=col y legend=False para evitar FutureWarning
        sns.countplot(x=col, data=df_eda, palette='mako', hue=col, legend=False)
        plt.title(f'Distribuci√≥n de {col}')
        plt.xlabel('')
        plt.ylabel('Frecuencia')
        plt.xticks(rotation=45, ha='right')

    plt.tight_layout()
    plt.show()
else:
    print("No se encontraron otras columnas categ√≥ricas para visualizar.")

print("\n--- EDA Completado ---")
```

```
--- Iniciando An√°lisis Exploratorio de Datos (EDA) ---

--- 1. Informaci√≥n General del DataFrame ---
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7043 entries, 0 to 7042
Data columns (total 20 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   gender            7043 non-null   object 
 1   SeniorCitizen     7043 non-null   int64  
 2   Partner           7043 non-null   object 
 3   Dependents        7043 non-null   object 
 4   tenure            7043 non-null   int64  
 5   PhoneService      7043 non-null   object 
 6   MultipleLines     7043 non-null   object 
 7   InternetService   7043 non-null   object 
 8   OnlineSecurity    7043 non-null   object 
 9   OnlineBackup      7043 non-null   object 
 10  DeviceProtection  7043 non-null   object 
 11  TechSupport       7043 non-null   object 
 12  StreamingTV       7043 non-null   object 
 13  StreamingMovies   7043 non-null   object 
 14  Contract          7043 non-null   object 
 15  PaperlessBilling  7043 non-null   object 
 16  PaymentMethod     7043 non-null   object 
 17  MonthlyCharges    7043 non-null   float64
 18  TotalCharges      7032 non-null   float64
 19  Churn             7043 non-null   object 
dtypes: float64(2), int64(2), object(16)
memory usage: 1.1+ MB

--- 2. Estad√≠sticas Descriptivas (Columnas Num√©ricas) ---

```

```
       SeniorCitizen       tenure  MonthlyCharges  TotalCharges
count    7043.000000  7043.000000     7043.000000   7032.000000
mean        0.162147    32.371149       64.761692   2283.300441
std         0.368612    24.559481       30.090047   2266.771362
min         0.000000     0.000000       18.250000     18.800000
25%         0.000000     9.000000       35.500000    401.450000
50%         0.000000    29.000000       70.350000   1397.475000
75%         0.000000    55.000000       89.850000   3794.737500
max         1.000000    72.000000      118.750000   8684.800000
```

```

--- 3. Conteo de Valores Faltantes por Columna ---
gender               0
SeniorCitizen        0
Partner              0
Dependents           0
tenure               0
PhoneService         0
MultipleLines        0
InternetService      0
OnlineSecurity       0
OnlineBackup         0
DeviceProtection     0
TechSupport          0
StreamingTV          0
StreamingMovies      0
Contract             0
PaperlessBilling     0
PaymentMethod        0
MonthlyCharges       0
TotalCharges        11
Churn                0
dtype: int64

--- 4. Distribuci√≥n de la Variable Objetivo (Churn) ---

```

![Generated Image](image_placeholder.png)

```
Proporci√≥n de Churn:
  No: 73.46%
  Yes: 26.54%

--- 5. Distribuci√≥n de Variables Categ√≥ricas ---

```

![Generated Image](image_placeholder.png)

```

--- EDA Completado ---

```


---

4. [Secci√≥n 4](#ch4)


<a id='ch4'></a>

### **Prop√≥sito General: Construir una "F√°brica de Procesamiento de Datos" üè≠**

Piensa en este c√≥digo como el dise√±o y la construcci√≥n de una **l√≠nea de ensamblaje industrial automatizada**. Su objetivo no es analizar los datos ni crear un modelo final, sino construir una "f√°brica" (un `Pipeline`) que tomar√° los datos crudos y desordenados y los transformar√°, paso a paso, en piezas perfectamente limpias, estandarizadas y listas para ser utilizadas por un algoritmo de machine learning.

Los algoritmos son como motores de alta precisi√≥n: no puedes simplemente echarles arena, piedras y madera (datos crudos). Necesitan piezas met√°licas de un tama√±o exacto y conectores de pl√°stico estandarizados (datos procesados). Este script construye la maquinaria que realiza esa transformaci√≥n de manera eficiente y consistente.

---

### **Fase 1: Preparaci√≥n de la Materia Prima**

Antes de que la l√≠nea de ensamblaje se ponga en marcha, un operario realiza una preparaci√≥n inicial de los materiales.

1.  **Duplicado de Seguridad:** Primero, se hace una copia de los datos originales. Esto es para asegurar que la "materia prima" original permanezca intacta y sin alteraciones.

2.  **Ajustes Manuales:** Se realizan algunas conversiones b√°sicas para que los materiales sean manejables:
    * **Traducci√≥n del Objetivo:** La columna principal, "Churn", que indica si un cliente se fue o no, se traduce a un lenguaje universal para las m√°quinas: el binario. Las palabras "Yes" y "No" se convierten en **1** y **0**, respectivamente.
    * **Limpieza de Otros Materiales:** Se realizan las mismas limpiezas que en la fase de an√°lisis: se corrigen los n√∫meros en la columna de "cargos totales" y se descarta el "ID de cliente", que es como quitar una etiqueta de env√≠o que no forma parte del producto final.

3.  **Separaci√≥n de Instrucciones y Materiales:** El c√≥digo separa inteligentemente los datos en dos grupos:
    * **Las Caracter√≠sticas (X):** Toda la informaci√≥n sobre los clientes (antig√ºedad, contrato, etc.). Esta es la "materia prima" que pasar√° por la l√≠nea de ensamblaje.
    * **La Variable Objetivo (y):** La columna "Churn" (ahora con 0s y 1s). Este es el "plano" o la "respuesta correcta" que el modelo intentar√° aprender. Se mantiene separada porque no necesita ser procesada, solo se usa como referencia para el aprendizaje.

---

### **Fase 2: Dise√±o de las Estaciones de Trabajo**

Ahora comienza el dise√±o de la l√≠nea de ensamblaje. La f√°brica tendr√° diferentes estaciones, cada una especializada en un tipo de material.

1.  **Clasificaci√≥n Autom√°tica:** El sistema primero inspecciona toda la materia prima (las caracter√≠sticas) y la clasifica autom√°ticamente en dos tipos: **num√©ricos** (metales, como la antig√ºedad o los pagos mensuales) y **categ√≥ricos** (pl√°sticos de colores, como el g√©nero o el tipo de contrato).

2.  **Dise√±o de la Estaci√≥n para "Metales" (Datos Num√©ricos):** Se dise√±a una l√≠nea de procesamiento espec√≠fica para todos los datos num√©ricos. Esta estaci√≥n realiza dos tareas en orden:
    * **Reparaci√≥n de Piezas (Imputaci√≥n):** Si alguna pieza met√°lica llega con un agujero o un valor faltante, esta m√°quina lo rellena autom√°ticamente. Utiliza una t√©cnica inteligente (la mediana) para asegurarse de que el "parche" sea un valor representativo y no uno extremo.
    * **Estandarizaci√≥n de Tama√±o (Escalado):** Los algoritmos pueden confundirse si una pieza mide 1000 mil√≠metros y otra 2 metros. Esta m√°quina ajusta la escala de todas las piezas num√©ricas para que tengan un tama√±o y un rango comparables. Esto asegura que ninguna caracter√≠stica domine a las dem√°s solo por tener n√∫meros m√°s grandes.

3.  **Dise√±o de la Estaci√≥n para "Pl√°sticos" (Datos Categ√≥ricos):** Se dise√±a otra l√≠nea de procesamiento para los materiales que son texto o categor√≠as. Esta estaci√≥n tambi√©n tiene dos tareas:
    * **Manejo de Desconocidos (Imputaci√≥n):** Si llega una pieza de pl√°stico sin color definido, se le asigna una etiqueta est√°ndar de "desconocido".
    * **Traducci√≥n a Lenguaje de M√°quina (Codificaci√≥n):** Esta es una de las transformaciones m√°s importantes. El motor final no entiende palabras como "Contrato Mensual" o "Transferencia Bancaria". Esta m√°quina convierte esas etiquetas de texto en un sistema de interruptores de encendido/apagado (0s y 1s). Por ejemplo, en lugar de una columna "Contrato" con tres opciones, crear√° dos nuevas columnas: "¬øEs Contrato Anual?" (1 si es s√≠, 0 si no) y "¬øEs Contrato Bianual?" (1 si es s√≠, 0 si no). Este proceso se llama **One-Hot Encoding**.

---

### **Fase 3: Ensamblaje Final de la F√°brica**

Con todas las estaciones de trabajo dise√±adas, el paso final es unirlas en una √∫nica y gran l√≠nea de producci√≥n.

Se utiliza un **"Controlador Maestro" (`ColumnTransformer`)** que dirige el tr√°fico. Se le dan instrucciones claras: "Toma todas las piezas met√°licas y env√≠alas a la estaci√≥n de procesamiento num√©rico. Toma todas las piezas de pl√°stico y env√≠alas a la estaci√≥n de procesamiento categ√≥rico. Si sobra alg√∫n otro tipo de material, simplemente desc√°rtalo".

---

### **Resultado Final: Una F√°brica Lista para Producir**

Al final de la ejecuci√≥n, el c√≥digo no ha procesado ning√∫n dato. En cambio, ha construido y dejado lista una **f√°brica de preprocesamiento completa, automatizada y reutilizable**.

Esta "f√°brica" (`preprocessor`) es ahora un objeto que se puede usar una y otra vez. Cada vez que le entregues datos crudos, los pasar√° por toda la l√≠nea de ensamblaje en el orden correcto y devolver√° piezas perfectas y estandarizadas, listas para alimentar el motor de machine learning. Esto garantiza que el procesamiento sea **consistente, eficiente y libre de errores humanos**.


---

```python
print("\n--- Creando Pipeline de Preprocesamiento para Modelado ---")

# --- Preparaci√≥n de datos espec√≠fica para el pipeline ---
df_processed = df.copy()

# 1. Aplicar transformaciones iniciales seg√∫n el tipo de dataset
if dataset_type == "telco":
    # Convertir 'TotalCharges' a num√©rico. Los errores se vuelven NaN para ser imputados por el pipeline.
    df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')
    # Eliminar la columna 'customerID' ya que no es una caracter√≠stica predictora.
    df_processed = df_processed.drop('customerID', axis=1, errors='ignore')
    # Convertir la variable objetivo 'Churn' a formato num√©rico (0 para 'No', 1 para 'Yes').
    if df_processed['Churn'].dtype == 'object':
        df_processed['Churn'] = df_processed['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)
else:
    # Para el dataset sint√©tico, solo asegurar que 'Churn' sea de tipo entero.
    df_processed['Churn'] = df_processed['Churn'].astype(int)

# 2. Separar caracter√≠sticas (X) y variable objetivo (y)
X = df_processed.drop('Churn', axis=1)
y = df_processed['Churn']

# 3. Identificar autom√°ticamente los tipos de caracter√≠sticas
numeric_features = X.select_dtypes(include=np.number).columns.tolist()
categorical_features = X.select_dtypes(include='object').columns.tolist()
print(f"\nCaracter√≠sticas Num√©ricas Identificadas: {len(numeric_features)}")
print(f"-> {numeric_features}")
print(f"Caracter√≠sticas Categ√≥ricas Identificadas: {len(categorical_features)}")
print(f"-> {categorical_features}")

# 4. Definir el pipeline para transformaciones num√©ricas
#   - Imputaci√≥n: Rellena valores faltantes (NaN) con la mediana.
#   - Escalado: Estandariza los datos (media 0, desviaci√≥n est√°ndar 1).
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# 5. Definir el pipeline para transformaciones categ√≥ricas
#   - Imputaci√≥n: Rellena valores faltantes con una constante 'unknown'.
#   - Codificaci√≥n: Aplica One-Hot Encoding para convertir categor√≠as en columnas num√©ricas.
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))
])

# 6. Ensamblar los pipelines en un preprocesador √∫nico con ColumnTransformer
#   Este objeto aplicar√° las transformaciones correctas a las columnas correctas.
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'  # Ignora cualquier columna no especificada.
)

print("\n‚úì Pipeline de preprocesamiento robusto creado y listo para usar.")
# Para ver el pipeline, puedes imprimir el objeto:
# print(preprocessor)
```

```

--- Creando Pipeline de Preprocesamiento para Modelado ---

Caracter√≠sticas Num√©ricas Identificadas: 4
-> ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']
Caracter√≠sticas Categ√≥ricas Identificadas: 15
-> ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']

‚úì Pipeline de preprocesamiento robusto creado y listo para usar.

```


---

5. [Secci√≥n 5](#ch5)


<a id='ch5'></a>

### **La Secuencia L√≥gica: De la F√°brica a la Calibraci√≥n**

1.  **C√≥digo Anterior (El Dise√±o):** En el √∫ltimo bloque, dise√±amos y construimos una "f√°brica" (`preprocessor`) lista para transformar nuestra materia prima (`X` y `y`). Ten√≠amos los planos de la maquinaria y los materiales listos y separados.

2.  **Este Nuevo C√≥digo (La Divisi√≥n para Pruebas):** Antes de encender la maquinaria para una producci√≥n a gran escala (el entrenamiento del modelo), debemos ser cient√≠ficos. No podemos usar todos nuestros materiales para ajustar las m√°quinas y luego usar esos mismos materiales para verificar si funcionan bien. Eso ser√≠a hacer trampa.

Este nuevo c√≥digo act√∫a como el **jefe de control de calidad** que divide la materia prima en dos lotes distintos:

* **Lote de Entrenamiento (80%):** La mayor parte de los datos. Estos ser√°n los materiales que usaremos para **calibrar y ense√±ar** a nuestra maquinaria (`X_train`, `y_train`). El modelo aprender√° los patrones a partir de este lote.

* **Lote de Prueba (20%):** Una porci√≥n m√°s peque√±a y valiosa de los datos que se **guarda bajo llave** (`X_test`, `y_test`). El modelo nunca ver√° estos datos durante su fase de aprendizaje. Ser√°n la prueba final y objetiva para ver si la maquinaria, una vez calibrada, funciona correctamente con materiales nuevos que nunca antes ha procesado.

### **La Importancia de la "Estratificaci√≥n"**

El c√≥digo no solo divide los datos al azar. La instrucci√≥n `stratify=y` es crucial y muy profesional.

Imagina que en tu lote total de materiales, el 27% son "defectuosos" (clientes que hacen Churn). Una divisi√≥n aleatoria podr√≠a, por pura mala suerte, poner el 35% de los defectuosos en el lote de entrenamiento y solo el 10% en el de prueba. Esto desequilibrar√≠a todo el proceso.

La **estratificaci√≥n** evita esto. Act√∫a como un supervisor meticuloso que se asegura de que la proporci√≥n de materiales "defectuosos" sea **exactamente la misma** en el lote de entrenamiento, en el lote de prueba y en el lote original. Como muestra el resultado impreso, si el 26.5% de los clientes originales hicieron Churn, entonces aproximadamente el 26.5% de los clientes en el conjunto de entrenamiento *y* en el conjunto de prueba tambi√©n lo habr√°n hecho.

Este c√≥digo es el puente indispensable entre tener los datos preparados y poder entrenar un modelo de forma fiable. Separa los datos de manera inteligente para garantizar que podamos ense√±ar al modelo con un conjunto y luego evaluarlo de manera justa y realista con otro que nunca ha visto.


---

```python
# Realizar la divisi√≥n estratificada para asegurar la representatividad de las clases.
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,       # 20% de los datos se reservan para la prueba final.
    random_state=42,     # Semilla para que la divisi√≥n sea reproducible.
    stratify=y           # ¬°Crucial! Asegura proporciones de clase consistentes.
)

print("--- Resumen de la Divisi√≥n de Datos ---")
print(f"Tama√±o del conjunto de entrenamiento: {len(X_train)} muestras ({len(X_train)/len(X):.1%})")
print(f"Tama√±o del conjunto de prueba: {len(X_test)} muestras ({len(X_test)/len(X):.1%})")
print(f"\nDistribuci√≥n de la clase 'Churn':")
print(f"  En el conjunto de entrenamiento: {y_train.mean():.2%}")
print(f"  En el conjunto de prueba:        {y_test.mean():.2%}")
print(f"  En el dataset original:        {y.mean():.2%}")
print("\n‚úì Las proporciones son consistentes, la estratificaci√≥n fue exitosa.")
```

```
--- Resumen de la Divisi√≥n de Datos ---
Tama√±o del conjunto de entrenamiento: 5634 muestras (80.0%)
Tama√±o del conjunto de prueba: 1409 muestras (20.0%)

Distribuci√≥n de la clase 'Churn':
  En el conjunto de entrenamiento: 26.54%
  En el conjunto de prueba:        26.54%
  En el dataset original:        26.54%

‚úì Las proporciones son consistentes, la estratificaci√≥n fue exitosa.

```


---

6. [Secci√≥n 6](#ch6)


<a id='ch6'></a>

### **Construir y Ensamblar el Motor Predictivo**

Este c√≥digo representa la culminaci√≥n de todos los pasos de preparaci√≥n anteriores. Si los bloques de c√≥digo previos construyeron la "f√°brica" para procesar datos (`preprocessor`) y organizaron la "materia prima" (datos de entrenamiento y prueba), este bloque se encarga de construir **el "cerebro" o el "motor"** que tomar√° las decisiones (`model`) y luego lo ensambla de manera experta con la f√°brica para crear una l√≠nea de producci√≥n completamente funcional y automatizada (`pipeline`).

---

### **Parte 1: La Creaci√≥n del "Cerebro" Predictivo (El Modelo)**

El primer paso es construir el modelo de machine learning en s√≠. No se elige un modelo gen√©rico, sino uno muy espec√≠fico y potente llamado **`RandomForestClassifier`** (Clasificador de Bosque Aleatorio), y se le configura cuidadosamente con reglas espec√≠ficas para que funcione de manera √≥ptima y evite errores comunes.

Pensemos en el `RandomForestClassifier` no como un √∫nico experto, sino como un **comit√© de 100 expertos** (los "√°rboles de decisi√≥n"). En lugar de confiar en la opini√≥n de una sola persona, se le pregunta a todo el comit√© y la decisi√≥n final se toma por votaci√≥n mayoritaria. Esto hace que el resultado sea mucho m√°s robusto, preciso y menos propenso a los sesgos de un solo individuo.

El c√≥digo configura a este "comit√© de expertos" con las siguientes directivas:

* **Regla de Consistencia (`random_state=42`):** Esta es una instrucci√≥n para garantizar la **reproducibilidad**. Asegura que, aunque el proceso tiene elementos de aleatoriedad, el comit√© se forme exactamente de la misma manera cada vez que se ejecute el c√≥digo. Esto es crucial para que los experimentos sean consistentes.

* **Ajuste de Imparcialidad (`class_weight='balanced'`):** Esta es quiz√°s la configuraci√≥n m√°s importante para este problema. El modelo sabe que hay muchos m√°s clientes que "No cancelan" que los que "S√≠ cancelan". Esta regla act√∫a como un **ajuste contra el sesgo**, dici√©ndole al comit√©: "Presten especial atenci√≥n y denle m√°s importancia a los casos de clientes que 'S√≠ cancelan', porque son m√°s raros pero igual de importantes". Esto evita que el modelo simplemente aprenda a predecir "No cancela" todo el tiempo porque es la opci√≥n m√°s frecuente.

* **Reglas Anti-Sobrean√°lisis (`max_depth=10` y `min_samples_leaf=5`):** Estas dos reglas son salvaguardas para evitar que el modelo se "obsesione" con los datos de entrenamiento y pierda la capacidad de generalizar.
    * La primera regla (`max_depth=10`) limita la **profundidad del razonamiento**. Impide que cada experto del comit√© haga una cadena de preguntas excesivamente larga y compleja para llegar a una conclusi√≥n.
    * La segunda regla (`min_samples_leaf=5`) exige que cada conclusi√≥n final a la que llegue un experto se base en un **m√≠nimo de 5 casos**. Esto evita que el modelo cree reglas muy espec√≠ficas basadas en la situaci√≥n de un solo cliente, lo cual ser√≠a memorizar en lugar de aprender.

El resultado es un modelo inteligente, justo y prudente, dise√±ado espec√≠ficamente para manejar datos desbalanceados y evitar el sobreajuste.

---

### **Parte 2: El Ensamblaje Final de la L√≠nea de Producci√≥n (El Pipeline)**

Una vez que tenemos la "f√°brica" (`preprocessor`) y el "cerebro" (`model`), el √∫ltimo paso es unirlos en un solo sistema cohesivo. Eso es exactamente lo que hace el **`Pipeline`**.

El `Pipeline` es un objeto que encapsula toda la secuencia de trabajo. Se le dan las instrucciones en orden:
1.  **Primer Paso (`preprocessor`):** Cuando lleguen nuevos datos crudos, p√°salos primero por toda la f√°brica de preprocesamiento que construimos antes.
2.  **Segundo Paso (`classifier`):** Toma las "piezas" limpias y estandarizadas que salen de la f√°brica y env√≠alas directamente al "cerebro" para que emita una predicci√≥n.

Crear este `pipeline` final es una pr√°ctica profesional de primer nivel. Convierte un proceso de m√∫ltiples pasos en **una sola unidad de trabajo**. Ahora, en lugar de tener que recordar preprocesar los datos y luego pasarlos al modelo, simplemente podemos darle los datos crudos al `pipeline` y √©l se encargar√° de toda la secuencia de forma autom√°tica, eficiente y sin riesgo de errores.

Este c√≥digo finaliza la fase de dise√±o, dej√°ndonos con un **√∫nico objeto `pipeline`** que contiene toda la l√≥gica, desde la limpieza inicial de los datos hasta la predicci√≥n final. Este sistema est√° ahora completamente listo para ser entrenado.


---

```python
# Crear el modelo base con hiperpar√°metros razonables para evitar el sobreajuste.
model = RandomForestClassifier(
    random_state=42,
    n_estimators=100,
    class_weight='balanced', # Clave para datasets desbalanceados
    max_depth=10,            # Limita la profundidad de los √°rboles
    min_samples_leaf=5       # Requiere un m√≠nimo de muestras en cada hoja
)

# Ensamblar el pipeline final: preprocesamiento seguido del modelo.
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', model)
])

print("‚úì Modelo y pipeline final configurados.")
```

```
‚úì Modelo y pipeline final configurados.

```


---

7. [Secci√≥n 7](#ch7)


<a id='ch7'></a>

### **El Protocolo de Pruebas de Estr√©s y Control de Calidad üö¶**

Hemos llegado a un punto cr√≠tico. Tenemos nuestra l√≠nea de producci√≥n completamente ensamblada (`pipeline`), que toma datos crudos y los convierte en predicciones. Pero, ¬øqu√© tan buena es realmente? ¬øFue suerte que funcionara bien en un ejemplo? ¬øEs confiable?

Este c√≥digo implementa un **protocolo de control de calidad y pruebas de estr√©s** riguroso conocido como **Validaci√≥n Cruzada (Cross-Validation)**. Su objetivo es obtener una medida honesta, fiable y estable del rendimiento real de nuestro `pipeline` antes de ponerlo a prueba con los datos finales que guardamos bajo llave (el `test set`).

Pi√©nsalo como un fabricante de autom√≥viles. No prueban un solo coche en una sola pista y lo dan por bueno. Prueban m√∫ltiples unidades del mismo modelo en diferentes pistas, con diferentes pilotos y en diferentes condiciones clim√°ticas. Solo promediando los resultados de todas esas pruebas pueden afirmar con confianza cu√°l es el rendimiento real del coche. Este c√≥digo hace exactamente eso, pero con datos.

---

### **Fase 1: El Dise√±o del Protocolo de Pruebas**

La funci√≥n principal de este c√≥digo est√° dise√±ada para ejecutar una de estas pruebas de estr√©s de principio a fin.

1.  **La Metodolog√≠a de Prueba (Validaci√≥n Cruzada):** En lugar de hacer una sola divisi√≥n de los datos de entrenamiento, la validaci√≥n cruzada divide el lote de entrenamiento (`X_train`, `y_train`) en varias partes m√°s peque√±as (por ejemplo, 5 o 10 "pliegues" o *folds*). Luego, realiza una serie de rondas de prueba:
    * **Ronda 1:** Usa el pliegue 1 como pista de prueba y entrena el `pipeline` con los pliegues 2, 3, 4 y 5.
    * **Ronda 2:** Usa el pliegue 2 como pista de prueba y entrena el `pipeline` con los pliegues 1, 3, 4 y 5.
    * **... y as√≠ sucesivamente**, hasta que cada pliegue haya sido la "pista de prueba" exactamente una vez.

2.  **La "Hoja de Puntuaci√≥n" (Las M√©tricas):** Una simple calificaci√≥n de "aprobado" o "reprobado" no es suficiente. El c√≥digo define una hoja de puntuaci√≥n detallada para evaluar el rendimiento en cada ronda, especialmente porque nuestro problema tiene un desbalance (pocos clientes cancelan). Las m√©tricas clave son:
    * **Accuracy (Exactitud):** La calificaci√≥n m√°s simple: ¬øQu√© porcentaje de predicciones totales fueron correctas?
    * **Precision (Precisi√≥n):** De todas las veces que la alarma de "este cliente cancelar√°" son√≥, ¬øcu√°ntas veces fue una alarma real? Mide la calidad de las predicciones positivas.
    * **Recall (Sensibilidad):** De todos los clientes que realmente cancelaron, ¬øa cu√°ntos logramos identificar correctamente? Mide nuestra capacidad para "atrapar" los casos que nos interesan.
    * **F1-Score:** Una calificaci√≥n de equilibrio que combina la Precisi√≥n y el Recall en un solo n√∫mero. Es √∫til para obtener una visi√≥n general r√°pida.
    * **ROC-AUC:** Una m√©trica m√°s avanzada que eval√∫a qu√© tan bueno es el modelo para distinguir entre un cliente que cancelar√° y uno que no.

---

### **Fase 2: La Ejecuci√≥n de las Pruebas y el An√°lisis de Resultados**

Una vez que el protocolo y la hoja de puntuaci√≥n est√°n definidos, el c√≥digo ejecuta las pruebas de manera eficiente.

1.  **Ejecuci√≥n Paralela:** Le indica al sistema que use toda la potencia de procesamiento disponible (`n_jobs=-1`) para realizar las m√∫ltiples rondas de prueba simult√°neamente, como si se estuvieran probando varios coches en diferentes pistas al mismo tiempo. Esto acelera enormemente el proceso.

2.  **El Informe Final:** Despu√©s de que todas las rondas han terminado, el c√≥digo no solo muestra los resultados individuales, sino que genera un informe consolidado y f√°cil de entender.
    * **Rendimiento Promedio (`mean`):** Calcula la puntuaci√≥n **media** para cada m√©trica en la hoja de puntuaci√≥n. Este promedio es la estimaci√≥n m√°s fiable y realista de c√≥mo se comportar√° nuestro `pipeline` con datos nuevos que nunca ha visto.
    * **Nivel de Consistencia (`std`):** Tambi√©n calcula la **desviaci√≥n est√°ndar**. Un valor bajo aqu√≠ es una excelente noticia, ya que significa que el `pipeline` tuvo un rendimiento muy similar y estable en todas las rondas de prueba. Un valor alto ser√≠a una se√±al de alerta, indicando que el rendimiento es err√°tico y poco fiable.

Finalmente, el c√≥digo est√° preparado para guardar estos informes detallados en un diccionario, lo que permite ejecutar diferentes tipos de "protocolos de prueba" (por ejemplo, con 5 pliegues, con 10 pliegues, etc.) y luego compararlos f√°cilmente para ver cu√°l ofrece la evaluaci√≥n m√°s robusta.

Este c√≥digo es el **proceso de certificaci√≥n de calidad**. Somete a nuestro `pipeline` a un examen riguroso y multifac√©tico para darnos una confianza estad√≠stica s√≥lida sobre su verdadero poder predictivo y su estabilidad.


---

```python
def evaluate_cv_technique(pipeline, X_train, y_train, cv_method, cv_name):
    """
    Ejecuta la validaci√≥n cruzada usando un m√©todo espec√≠fico, calcula m√∫ltiples
    m√©tricas de rendimiento y presenta los resultados de forma clara.
    """
    print(f"\n{'='*50}\nEVALUANDO: {cv_name}\n{'='*50}")

    # Definir las m√©tricas que nos interesan para un problema de clasificaci√≥n desbalanceado.
    scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc']

    # Ejecutar cross_validate para obtener un diccionario detallado de resultados.
    cv_results = cross_validate(
        pipeline, X_train, y_train,
        cv=cv_method,
        scoring=scoring_metrics,
        n_jobs=-1  # Utilizar todos los n√∫cleos de CPU disponibles para acelerar.
    )

    # Convertir los resultados en un DataFrame para un an√°lisis m√°s f√°cil.
    results_df = pd.DataFrame({
        'Fold': range(1, cv_method.get_n_splits(X_train) + 1),
        'Accuracy': cv_results['test_accuracy'],
        'Precision': cv_results['test_precision_macro'],
        'Recall': cv_results['test_recall_macro'],
        'F1-Score': cv_results['test_f1_macro'],
        'ROC-AUC': cv_results['test_roc_auc']
    })

    # Imprimir estad√≠sticas resumidas clave.
    print("Estad√≠sticas Resumidas de las M√©tricas:")
    summary_stats = results_df.iloc[:, 1:].agg(['mean', 'std'])
    print(summary_stats.round(4))

    return results_df

# Diccionario para almacenar los resultados de cada t√©cnica para comparaci√≥n posterior.
all_cv_results = {}
```


---

8. [Secci√≥n 8](#ch8)


<a id='ch8'></a>

### **Ejecuci√≥n y Comparaci√≥n de Dos Protocolos de Prueba**

Hemos dise√±ado nuestra funci√≥n para realizar "pruebas de estr√©s" (`evaluate_cv_technique`), que es como tener el manual para un protocolo de control de calidad. Ahora, este c√≥digo es el **ingeniero de calidad que ejecuta el manual**, no una, sino dos veces, utilizando dos metodolog√≠as de prueba ligeramente diferentes pero conceptualmente importantes.

El objetivo es doble: primero, obtener una evaluaci√≥n robusta del rendimiento de nuestro `pipeline`; y segundo, comparar los dos m√©todos de prueba para confirmar cu√°l es el m√°s adecuado y fiable para nuestro problema espec√≠fico. Al final, tendremos dos informes de rendimiento completos, listos para ser comparados.

---

### **Primera Prueba: El Protocolo Est√°ndar (`K-Fold`)**

La primera ejecuci√≥n utiliza el m√©todo de validaci√≥n cruzada m√°s com√∫n y fundamental, conocido como `K-Fold`.

* **C√≥mo Funciona:** Imagina que todos tus datos de entrenamiento son una baraja de cartas. Este m√©todo primero **baraja toda la baraja de forma completamente aleatoria**. Luego, la corta en 5 montones iguales (porque se especific√≥ `n_splits=5`). El proceso de prueba se realiza como se describi√≥ anteriormente: se entrena el modelo con 4 montones y se prueba con el quinto, repitiendo el proceso hasta que cada mont√≥n ha servido como prueba una vez.

* **Su Peque√±a Debilidad:** Aunque es un buen m√©todo, su aleatoriedad pura tiene una peque√±a debilidad potencial, especialmente en nuestro caso. Como la baraja se baraja sin tener en cuenta el contenido de las cartas, por pura casualidad, uno de los 5 montones podr√≠a terminar con una proporci√≥n extra√±a de "clientes que cancelaron" (por ejemplo, muchos m√°s o muchos menos que el promedio del 27%). Si esto ocurre, la prueba en esa ronda espec√≠fica no ser√≠a totalmente representativa del problema general, y podr√≠a darnos una lectura de rendimiento ligeramente sesgada (demasiado optimista o pesimista).

El c√≥digo configura este protocolo est√°ndar y luego llama a nuestra funci√≥n principal de evaluaci√≥n para que ejecute la prueba completa. El informe detallado de esta prueba se guarda en nuestro registro de resultados con la etiqueta **"K-Fold"**.

---

### **Segunda Prueba: El Protocolo de Precisi√≥n (`Stratified K-Fold`)**

La segunda ejecuci√≥n utiliza una versi√≥n mejorada y m√°s inteligente del protocolo, dise√±ada espec√≠ficamente para problemas de clasificaci√≥n como el nuestro. Se llama `Stratified K-Fold` (K-Fold Estratificado).

* **C√≥mo Funciona (La Mejora Clave):** Este m√©todo es m√°s meticuloso. Antes de barajar y cortar, primero **separa las cartas en dos mazos**: uno con todos los "clientes que cancelaron" y otro con todos los que "no cancelaron". Luego, cuando crea los 5 montones de prueba, se asegura de tomar una porci√≥n proporcional de cada mazo. El resultado es que **cada uno de los 5 montones finales tiene exactamente la misma proporci√≥n** de clientes que cancelaron y que no cancelaron que la baraja original completa.

* **Su Gran Ventaja:** Esto elimina por completo el riesgo de tener un mont√≥n de prueba "desafortunado" o desbalanceado. Es como garantizar que cada pista de pruebas para nuestros coches tenga exactamente la misma mezcla de curvas, rectas y baches. Cada ronda de la prueba es una representaci√≥n justa y equitativa del problema general, lo que hace que los resultados sean **m√°s fiables y consistentes**. Por esta raz√≥n, es el m√©todo **altamente recomendado** para este tipo de an√°lisis.

El c√≥digo configura este protocolo de precisi√≥n y vuelve a llamar a nuestra funci√≥n de evaluaci√≥n. El informe de esta segunda prueba, m√°s rigurosa, se guarda en el registro con la etiqueta **"Stratified K-Fold"**.

---

### **Dos Informes para una Decisi√≥n Informada**

Al final de la ejecuci√≥n de este bloque, nuestro registro (`all_cv_results`) contendr√° dos informes completos. El analista puede ahora compararlos. Lo m√°s probable es que los resultados promedio sean muy similares, lo que confirmar√≠a que nuestro `pipeline` es estable. Sin embargo, el informe del `Stratified K-Fold` se considerar√° la **medida de rendimiento definitiva y m√°s trustworthy**, ya que se obtuvo mediante un protocolo de prueba superior y m√°s adecuado para la naturaleza de nuestros datos.


---

```python
# --- K-Fold (Est√°ndar) ---
kf = KFold(n_splits=5, shuffle=True, random_state=42)
all_cv_results['K-Fold'] = evaluate_cv_technique(
    pipeline, X_train, y_train, kf, "K-Fold Cross Validation (K=5)"
)

# --- Stratified K-Fold (Recomendado para Clasificaci√≥n) ---
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
all_cv_results['Stratified K-Fold'] = evaluate_cv_technique(
    pipeline, X_train, y_train, skf, "Stratified K-Fold Cross Validation (K=5)"
)
```

```

==================================================
EVALUANDO: K-Fold Cross Validation (K=5)
==================================================
Estad√≠sticas Resumidas de las M√©tricas:
      Accuracy  Precision  Recall  F1-Score  ROC-AUC
mean    0.7744     0.7258  0.7664    0.7368   0.8456
std     0.0065     0.0131  0.0120    0.0124   0.0070

==================================================
EVALUANDO: Stratified K-Fold Cross Validation (K=5)
==================================================
Estad√≠sticas Resumidas de las M√©tricas:
      Accuracy  Precision  Recall  F1-Score  ROC-AUC
mean    0.7741     0.7255  0.7657    0.7365   0.8455
std     0.0125     0.0151  0.0200    0.0161   0.0116

```


---

9. [Secci√≥n 9](#ch9)


<a id='ch9'></a>

### **Interpretaci√≥n de Resultados de Validaci√≥n Cruzada**

Los resultados de la validaci√≥n cruzada indican que el modelo de `RandomForest` configurado es **s√≥lido, estable y prometedor**. El rendimiento promedio es consistente a trav√©s de dos metodolog√≠as de prueba diferentes, lo que genera una alta confianza en que los resultados no son producto del azar. Aunque ambas t√©cnicas de validaci√≥n arrojan conclusiones casi id√©nticas sobre el rendimiento, el **`Stratified K-Fold` sigue siendo el m√©todo preferido por su rigor metodol√≥gico**, a pesar de una variabilidad ligeramente mayor en esta ejecuci√≥n particular. En resumen, el modelo tiene un buen punto de partida para la evaluaci√≥n final.

---

### **1. An√°lisis del Rendimiento General del Modelo (M√©tricas Promedio - `mean`)**

El rendimiento promedio del modelo, evaluado a lo largo de 5 rondas de prueba, es consistentemente bueno.

* **ROC-AUC (‚âà 0.845):** Este es el indicador m√°s fuerte. Una puntuaci√≥n de casi 0.85 significa que el modelo tiene una **capacidad excelente** para distinguir entre un cliente que cancelar√° y uno que no. Un modelo aleatorio tendr√≠a una puntuaci√≥n de 0.50, por lo que nuestro modelo es significativamente mejor que adivinar al azar.

* **Accuracy (‚âà 77.4%):** El modelo acierta en su predicci√≥n general aproximadamente 77 de cada 100 veces. Si bien es un buen n√∫mero, la exactitud puede ser enga√±osa en problemas con clases desbalanceadas (m√°s clientes que no cancelan que los que s√≠), por lo que es crucial analizar las siguientes m√©tricas.

* **F1-Score (‚âà 0.737):** Este es quiz√°s el mejor indicador √∫nico para el rendimiento en clasificaci√≥n. Un F1-Score de casi 74% indica que el modelo mantiene un **excelente equilibrio entre la Precisi√≥n y el Recall**. No est√° sacrificando una m√©trica por la otra.

* **Precision (‚âà 72.6%) y Recall (‚âà 76.6%):** Estas m√©tricas nos cuentan la historia del equilibrio:
    * **Recall del 76.6%:** Significa que el modelo **logra identificar correctamente a casi el 77% de todos los clientes que realmente cancelaron**. Es bastante bueno "atrapando" a los clientes en riesgo.
    * **Precision del 72.6%:** Significa que cuando el modelo predice que un cliente cancelar√°, **acierta en su predicci√≥n aproximadamente el 73% de las veces**. El 27% restante ser√≠an "falsas alarmas".

En conjunto, estas medias pintan la imagen de un modelo √∫til y bien balanceado.

---

### **2. An√°lisis de la Estabilidad del Modelo (Desviaci√≥n Est√°ndar - `std`)**

La desviaci√≥n est√°ndar nos dice qu√© tan consistentes fueron los resultados en las 5 rondas de prueba.

* **Valores Bajos = Alta Confianza:** En ambos experimentos, todos los valores de `std` son muy bajos (entre 0.006 y 0.020). Esto es una **excelente noticia**. Significa que el rendimiento del modelo no vari√≥ mucho entre las diferentes submuestras de datos. El modelo es **estable y fiable**; su buen rendimiento no fue una casualidad de una sola ronda afortunada.

---

### **3. Comparaci√≥n de T√©cnicas: K-Fold vs. Stratified K-Fold**

Aqu√≠ comparamos no el modelo, sino los dos protocolos de prueba.

* **Rendimiento Promedio Id√©ntico:** La observaci√≥n m√°s importante es que las puntuaciones medias son pr√°cticamente id√©nticas en ambas tablas. Esto nos dice que, para este conjunto de datos, una divisi√≥n puramente aleatoria (`K-Fold`) y una divisi√≥n estratificada y cuidadosa (`Stratified K-Fold`) llevaron a la misma conclusi√≥n sobre el rendimiento del modelo. Esto refuerza a√∫n m√°s la idea de que nuestro modelo es estable.

* **An√°lisis de la Varianza (La Sorpresa Te√≥rica):** Contrario a la expectativa te√≥rica (donde se espera que `Stratified K-Fold` sea m√°s estable), en esta ejecuci√≥n espec√≠fica, `K-Fold` mostr√≥ una desviaci√≥n est√°ndar marginalmente m√°s baja.
    * **¬øPor qu√© ocurri√≥ esto?** La explicaci√≥n m√°s probable es que, debido al tama√±o del dataset y a la aleatoriedad de la divisi√≥n (`random_state=42`), el `K-Fold` est√°ndar tuvo la "suerte" de crear 5 pliegues que ya eran muy representativos y balanceados por s√≠ mismos.
    * **¬øCu√°l es la conclusi√≥n profesional?** Aunque los n√∫meros de esta √∫nica ejecuci√≥n favorecen ligeramente la estabilidad de `K-Fold`, el **`Stratified K-Fold` sigue siendo el m√©todo metodol√≥gicamente superior y recomendado**. Proporciona una **garant√≠a** de que las proporciones de clase se conservan, mientras que `K-Fold` depende de la suerte del barajado. La diferencia en la desviaci√≥n est√°ndar es tan peque√±a que es pr√°cticamente insignificante, por lo que debemos seguir confiando en la t√©cnica que es te√≥ricamente m√°s robusta.



Finalmente, el modelo demuestra un rendimiento **bueno (‚âà 74% F1-Score, ‚âà 85% ROC-AUC)** y **altamente estable (std < 0.02)**. Ambas t√©cnicas de validaci√≥n cruzada validan este resultado. Basado en estos hallazgos, tenemos una alta confianza para proceder al siguiente y √∫ltimo paso: **entrenar el modelo con todos los datos de entrenamiento y evaluarlo en el conjunto de prueba final**.


---

10. [Secci√≥n 10](#ch10)


<a id='ch10'></a>

----
### **La Prueba de Fuego ‚Äî El Examen Individual y Exhaustivo**

Este c√≥digo introduce una tercera y √∫ltima metodolog√≠a de prueba, la m√°s intensiva y granular de todas, conocida como **Validaci√≥n Cruzada Dejando-Uno-Fuera (`Leave-One-Out` o LOO)**.

Si los m√©todos anteriores (`K-Fold`) eran como probar coches en lotes en diferentes pistas, `Leave-One-Out` es el equivalente a un **examen personalizado e individual para cada coche que sale de la l√≠nea de producci√≥n**. Es la forma m√°s exhaustiva posible de verificar el rendimiento, ya que se centra en la capacidad del sistema para predecir cada caso individualmente, bas√°ndose en todos los dem√°s.

---

### **Fase 1: El Desaf√≠o Pr√°ctico y la Soluci√≥n Inteligente**

La metodolog√≠a `Leave-One-Out` tiene un gran desaf√≠o: es extremadamente costosa en t√©rminos de tiempo y recursos computacionales. Si tienes 5,000 datos de entrenamiento, este m√©todo requiere entrenar el modelo 5,000 veces. Para la mayor√≠a de los proyectos, esto es sencillamente inviable.

El c√≥digo aborda este problema con una soluci√≥n muy pr√°ctica e inteligente:

1.  **Creaci√≥n de una Muestra Representativa:** En lugar de intentar esta prueba exhaustiva con miles de datos, primero crea una **peque√±a muestra de 200 clientes** a partir del conjunto de entrenamiento.
2.  **Muestreo Estratificado:** Crucialmente, no elige 200 clientes al azar. Utiliza un **muestreo estratificado** para garantizar que esta peque√±a muestra tenga **exactamente la misma proporci√≥n** de clientes que cancelaron y que no cancelaron que el conjunto de datos m√°s grande. De esta manera, el grupo de 200 clientes es un microcosmos fiable del problema general.

Al hacer esto, el c√≥digo nos permite observar c√≥mo funciona la metodolog√≠a LOO sin tener que esperar horas o d√≠as para que se complete el c√°lculo.

---

### **Fase 2: La Metodolog√≠a del "Caso de Estudio"**

Una vez que tenemos nuestra muestra de 200 clientes, el protocolo `Leave-One-Out` se ejecuta de la siguiente manera, casi como si fuera un tutor personal o un detective resolviendo 200 casos individuales:

1.  **Caso 1:** Se toma al **primer cliente** de la muestra y se le aparta. Luego, se entrena todo el `pipeline` (la f√°brica y el cerebro) utilizando la informaci√≥n de los **199 clientes restantes**. Finalmente, se utiliza este modelo reci√©n entrenado para hacer una predicci√≥n sobre ese primer cliente que se hab√≠a apartado. Se anota el resultado.
2.  **Caso 2:** Se toma al **segundo cliente** y se le aparta. Se entrena el `pipeline` con los otros 199 clientes (incluido el primero). Se hace la predicci√≥n sobre el segundo cliente y se anota el resultado.
3.  **... y as√≠ sucesivamente**, hasta que este proceso se ha repetido 200 veces.

Al final de este procedimiento, cada uno de los 200 clientes ha sido utilizado exactamente una vez como un "conjunto de prueba" individual.

---

### **Fase 3: El Veredicto Final**

Para esta prueba tan espec√≠fica, el c√≥digo simplifica la evaluaci√≥n y se concentra en una √∫nica m√©trica de rendimiento muy fiable: el **F1-Score**. Esta m√©trica ofrece un excelente equilibrio entre la capacidad del modelo para identificar correctamente a los clientes que cancelan (Recall) y la precisi√≥n de esas identificaciones (Precision).

Tras completar las 200 rondas, el c√≥digo presenta un informe final que contiene:

* **El Rendimiento Promedio:** La puntuaci√≥n media del F1-Score a lo largo de las 200 pruebas. Este n√∫mero se considera una estimaci√≥n muy estable y poco sesgada del rendimiento del modelo.
* **La Consistencia (`std`):** La desviaci√≥n est√°ndar de esas 200 puntuaciones, que nos indica qu√© tan consistente fue el rendimiento del modelo al predecir cada caso individual.

En resumen, este c√≥digo no solo ejecuta una prueba m√°s, sino que demuestra una t√©cnica de validaci√≥n acad√©micamente rigurosa, adapt√°ndola de manera inteligente para que sea computacionalmente factible. Es una prueba de fuego que, aunque no se usa com√∫nmente en datasets grandes por su coste, ofrece la visi√≥n m√°s granular posible sobre la estabilidad y el poder predictivo de un modelo.


---

```python
%%time

print(f"\n{'='*50}\nEVALUANDO: Leave-One-Out (LOO) - sobre una muestra de 200\n{'='*50}")

# Tomar una peque√±a muestra estratificada para que la ejecuci√≥n sea factible.
X_sample, _, y_sample, _ = train_test_split(
    X_train, y_train, train_size=200, random_state=42, stratify=y_train
)

loo = LeaveOneOut()
print("‚è≥ Ejecutando LOO... (esto puede tardar unos segundos)")

# Usamos cross_val_score por simplicidad, ya que solo necesitamos el promedio y std.
loo_scores = cross_val_score(
    pipeline, X_sample, y_sample, cv=loo, scoring='f1_macro', n_jobs=-1
)

print(f"\nResultados de LOO (F1-Score):")
print(f"  Promedio: {loo_scores.mean():.4f}")
print(f"  Desviaci√≥n Est√°ndar: {loo_scores.std():.4f}")
```

```

==================================================
EVALUANDO: Leave-One-Out (LOO) - sobre una muestra de 200
==================================================
‚è≥ Ejecutando LOO... (esto puede tardar unos segundos)

Resultados de LOO (F1-Score):
  Promedio: 0.7850
  Desviaci√≥n Est√°ndar: 0.4108
CPU times: user 660 ms, sys: 46.4 ms, total: 706 ms
Wall time: 25.5 s

```


---

11. [Secci√≥n 11](#ch11)


<a id='ch11'></a>

### **Interpretaci√≥n de Resultados de Validaci√≥n Leave-One-Out (LOO)**


Los resultados de la prueba `Leave-One-Out` (LOO) confirman que el modelo tiene un **rendimiento predictivo fuerte**, mostrando una puntuaci√≥n F1 promedio incluso superior a la observada en las pruebas K-Fold. Sin embargo, la **desviaci√≥n est√°ndar extremadamente alta no debe interpretarse como una inestabilidad del modelo**, sino como una caracter√≠stica matem√°tica inherente a la propia metodolog√≠a LOO. En resumen, esta prueba nos da m√°s confianza en la capacidad predictiva del modelo, pero tambi√©n ilustra por qu√© `K-Fold` es a menudo una herramienta m√°s pr√°ctica para evaluar la estabilidad.

---

### **1. An√°lisis del Rendimiento Promedio (La Media: 0.7850)**

La puntuaci√≥n F1 promedio de **0.7850** es un resultado muy positivo. Es notablemente m√°s alta que la media de ~0.737 obtenida con las pruebas `K-Fold` y `Stratified K-Fold`.

* **¬øPor qu√© es m√°s alta?** La raz√≥n principal es la naturaleza de la prueba LOO. En cada una de las 200 rondas de prueba, el modelo se entrena con 199 de las 200 muestras, es decir, el **99.5% de los datos disponibles**. Al entrenar con casi toda la informaci√≥n posible en cada iteraci√≥n, es natural que el modelo alcance un rendimiento ligeramente superior en su predicci√≥n para el √∫nico caso restante. Esto nos da una visi√≥n optimista pero valiosa del potencial del modelo cuando se le proporciona la m√°xima cantidad de datos de entrenamiento.

---

### **2. An√°lisis de la Varianza (La Desviaci√≥n Est√°ndar: 0.4108)**

Este es el punto m√°s importante y el que requiere una interpretaci√≥n cuidadosa. Una desviaci√≥n est√°ndar de **0.4108** parece alarmantemente alta, especialmente en comparaci√≥n con los valores extremadamente bajos (~0.016) que vimos en las pruebas K-Fold.

* **¬øSignifica que el modelo es inestable?** No, en absoluto. Esta alta varianza es un **artefacto matem√°tico de la metodolog√≠a LOO** y no un reflejo de un modelo err√°tico.

* **La Explicaci√≥n Sencilla:** Pensemos en c√≥mo se calcula. La prueba realiza 200 "ex√°menes" individuales. En cada examen, solo hay un estudiante (un dato). La calificaci√≥n de ese examen es esencialmente binaria: o el modelo acierta (calificaci√≥n de 1) o se equivoca (calificaci√≥n de 0). La lista final de 200 resultados es, por lo tanto, una secuencia de unos y ceros (por ejemplo: `[1, 0, 1, 1, 1, 0, ...]`). La desviaci√≥n est√°ndar de una lista de este tipo, que solo contiene dos valores extremos, ser√° matem√°ticamente muy alta por definici√≥n, ya que los valores est√°n muy dispersos respecto a la media.

* **En Conclusi√≥n:** La alta desviaci√≥n est√°ndar no indica que el rendimiento del modelo "salte" de bueno a malo. Simplemente refleja la naturaleza binaria (√©xito/fracaso) de cada una de las 200 pruebas individuales.

---

### **3. Consideraciones Pr√°cticas (Tiempo de Ejecuci√≥n: 25.5 segundos)**

El informe indica que la prueba tard√≥ casi 26 segundos en completarse para una muestra min√∫scula de solo **200 clientes**. Si extrapolamos este tiempo al conjunto de entrenamiento completo (que tiene miles de clientes), la ejecuci√≥n tardar√≠a muchos minutos o incluso horas. Esto confirma de manera pr√°ctica por qu√© la prueba LOO, a pesar de su rigor acad√©mico, es **inviable para la mayor√≠a de los proyectos con conjuntos de datos de tama√±o moderado a grande**.

Finalmente la prueba `Leave-One-Out` cumpli√≥ su prop√≥sito:
1.  **Confirm√≥ el fuerte rendimiento del modelo**, d√°ndonos una estimaci√≥n optimista de su potencial.
2.  **Ilustr√≥ las propiedades estad√≠sticas de esta t√©cnica**, explicando por qu√© su alta varianza no debe ser malinterpretada.
3.  **Demostr√≥ su coste computacional**, reforzando por qu√© `Stratified K-Fold` es la opci√≥n preferida para obtener un balance ideal entre una evaluaci√≥n robusta y un tiempo de ejecuci√≥n pr√°ctico.


---

12. [Secci√≥n 12](#ch12)


<a id='ch12'></a>

----
### **El Examen Final y la Graduaci√≥n del Modelo üéì**

Este es el momento de la verdad. Todos los pasos anteriores ‚Äîla construcci√≥n de la f√°brica (`pipeline`), las pruebas de estr√©s (validaci√≥n cruzada) y la preparaci√≥n de los datos‚Äî han culminado en este punto. Este c√≥digo representa **el examen final y definitivo** para nuestro modelo.

Aqu√≠, el modelo se entrenar√° una √∫ltima vez con todo el conocimiento disponible y luego se enfrentar√° a un conjunto de datos completamente nuevo y desconocido (el `test set`) para demostrar su val√≠a. Los resultados obtenidos en este paso son la medida m√°s honesta y representativa de c√≥mo se comportar√° el modelo en el mundo real.

---

### **Paso 1: El Entrenamiento Final ‚Äî La Sesi√≥n de Estudio Intensiva**

La primera acci√≥n es tomar nuestro `pipeline` completo (la f√°brica de preprocesamiento y el cerebro predictivo ya ensamblados) y entrenarlo con la **totalidad de los datos de entrenamiento** (`X_train`, `y_train`).

Durante las pruebas de estr√©s (validaci√≥n cruzada), el modelo se entren√≥ repetidamente pero solo con *partes* del conjunto de entrenamiento. Ahora, para su versi√≥n final, le permitimos "estudiar" de todo el material disponible. Es como un estudiante que, despu√©s de hacer muchos ex√°menes de pr√°ctica, se sienta a repasar todos los libros y apuntes una √∫ltima vez antes del examen final. El objetivo es que el modelo absorba la m√°xima cantidad de informaci√≥n y patrones posibles para estar lo mejor preparado.

### **Paso 2: El Momento de la Verdad ‚Äî Las Predicciones sobre Datos Nuevos**

Una vez que el modelo est√° completamente entrenado, se le presentan los datos de prueba (`X_test`), aquel 20% de los datos que se guard√≥ bajo llave y que el modelo **jam√°s ha visto antes**. El modelo debe ahora emitir su juicio sobre estos nuevos casos.

El c√≥digo le pide al modelo que proporcione dos tipos de respuestas:

1.  **La Decisi√≥n Final (`y_pred`):** Para cada cliente en el conjunto de prueba, el modelo da un veredicto claro y directo: **0 (No cancelar√°)** o **1 (S√≠ cancelar√°)**. Esta es la predicci√≥n definitiva.

2.  **El Grado de Certeza (`y_pred_proba`):** Esta es una respuesta mucho m√°s rica y √∫til. En lugar de un simple s√≠/no, el modelo asigna una **probabilidad** a cada cliente. Por ejemplo, podr√≠a decir: "Para el cliente A, estoy un 85% seguro de que cancelar√°", y "Para el cliente B, solo hay un 12% de probabilidad de que cancele". Este nivel de confianza es extremadamente valioso en un entorno de negocio, ya que permite priorizar a los clientes con mayor riesgo.

### **Paso 3 y 4: El Bolet√≠n de Calificaciones ‚Äî El Informe Final de Rendimiento**

Finalmente, una vez que tenemos las predicciones del modelo y las respuestas correctas (`y_test`), el c√≥digo genera el **informe de calificaciones final**.

1.  **El Informe Detallado (`classification_report`):** Este es un resumen exhaustivo que act√∫a como el bolet√≠n de notas del modelo. No solo da una calificaci√≥n general, sino que desglosa el rendimiento para cada clase:
    * ¬øQu√© tan bueno fue prediciendo a los clientes que **No cancelaron**?
    * ¬øQu√© tan bueno fue prediciendo a los clientes que **S√≠ cancelaron**?

    Para cada una, muestra las m√©tricas clave (Precisi√≥n, Recall, F1-Score), d√°ndonos una visi√≥n completa de las fortalezas y debilidades del modelo.

2.  **La Calificaci√≥n Global (`ROC-AUC Score`):** Esta es la calificaci√≥n final, como el promedio general de un estudiante. Es un √∫nico n√∫mero que resume la capacidad total del modelo para **distinguir correctamente entre un cliente que cancelar√° y uno que no**. Un valor cercano a 1.0 indica un modelo excelente, mientras que un valor de 0.5 significa que no es mejor que adivinar al azar.

Este bloque de c√≥digo no solo completa el proceso t√©cnico, sino que tambi√©n produce los resultados finales y tangibles que se presentar√≠an a un equipo de negocio. Es la evidencia final que demuestra si todo el trabajo de preparaci√≥n y modelado ha resultado en una herramienta predictiva √∫til y fiable.


---

```python
print(f"\n{'='*50}\nENTRENAMIENTO Y EVALUACI√ìN FINAL\n{'='*50}")

# 1. Entrenar el pipeline completo con TODOS los datos de entrenamiento.
print("üîÑ Entrenando el modelo final...")
pipeline.fit(X_train, y_train)

# 2. Realizar predicciones en el conjunto de prueba.
y_pred = pipeline.predict(X_test)
y_pred_proba = pipeline.predict_proba(X_test)[:, 1] # Probabilidades para la clase positiva (Churn=1)

# 3. Imprimir el informe de clasificaci√≥n.
print("\nüìä INFORME DE CLASIFICACI√ìN DETALLADO (Conjunto de Prueba):")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))

# 4. Calcular el √°rea bajo la curva ROC (ROC-AUC).
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC-AUC Score: {roc_auc:.4f}")
```

```

==================================================
ENTRENAMIENTO Y EVALUACI√ìN FINAL
==================================================
üîÑ Entrenando el modelo final...

üìä INFORME DE CLASIFICACI√ìN DETALLADO (Conjunto de Prueba):
              precision    recall  f1-score   support

    No Churn       0.90      0.76      0.83      1035
       Churn       0.54      0.77      0.64       374

    accuracy                           0.77      1409
   macro avg       0.72      0.77      0.73      1409
weighted avg       0.81      0.77      0.78      1409

ROC-AUC Score: 0.8459

```


---

13. [Secci√≥n 13](#ch13)


<a id='ch13'></a>

### **Interpretaci√≥n del Informe de Evaluaci√≥n Final**

El modelo ha superado con √©xito la prueba final, demostrando ser una **herramienta valiosa y comercialmente viable** para predecir la cancelaci√≥n de clientes. Su rendimiento en el conjunto de prueba, que nunca antes hab√≠a visto, es **consistente con los resultados de las pruebas de estr√©s (validaci√≥n cruzada)**, lo que confirma su estabilidad y fiabilidad.

El punto m√°s destacado es su **alta capacidad para identificar a la mayor√≠a de los clientes en riesgo (Recall del 77% para "Churn")**. Aunque esto se logra a costa de un n√∫mero considerable de "falsas alarmas" (Precisi√≥n del 54%), este es un **intercambio estrat√©gico favorable** para la mayor√≠a de las campa√±as de retenci√≥n, donde el costo de perder un cliente es mucho mayor que el de contactar a un cliente feliz por error.

---

### **1. Consistencia y Fiabilidad General del Modelo**

La primera se√±al de un modelo bien construido es la consistencia.

* **ROC-AUC Score (0.8459):** Esta puntuaci√≥n es casi id√©ntica a la obtenida durante la validaci√≥n cruzada (~0.845). Un valor de ~0.85 es **muy bueno** y confirma que el modelo tiene un poder discriminatorio fuerte, siendo muy superior a adivinar al azar para diferenciar entre clientes que cancelar√°n y los que no.

* **Accuracy (77%):** La exactitud general tambi√©n se alinea perfectamente con los resultados de la validaci√≥n (~77.4%). Esto nos da una gran confianza en que nuestro proceso de prueba fue un predictor fiable del rendimiento en el mundo real.

---

### **2. El √âxito Principal: Identificaci√≥n de Clientes en Riesgo (An√°lisis de la Clase "Churn")**

Esta es la parte m√°s importante del informe, ya que eval√∫a el rendimiento del modelo en su objetivo principal: encontrar a los clientes que est√°n a punto de irse.

* ‚úÖ **Recall (Sensibilidad) del 77%:** Este es el **gran √©xito del modelo**. Significa que **logra identificar correctamente a 77 de cada 100 clientes que realmente iban a cancelar su servicio**. Para un equipo de retenci√≥n, esta es una herramienta proactiva extremadamente poderosa, ya que les permite enfocar sus esfuerzos en m√°s de tres cuartas partes de la base de clientes en riesgo.

* ‚ö†Ô∏è **Precision (Precisi√≥n) del 54%:** Este es el **principal costo operativo del modelo**. Significa que cuando el modelo levanta una bandera roja y dice "este cliente va a cancelar", solo acierta el 54% de las veces. El 46% restante son **falsas alarmas**: clientes que fueron marcados como en riesgo pero que en realidad no planeaban irse.

#### **El Veredicto del Intercambio (Trade-Off):**

En un contexto de negocio, este intercambio entre un Recall alto y una Precisi√≥n m√°s baja es **generalmente aceptable y deseable**. El costo de una "falsa alarma" (por ejemplo, ofrecer un peque√±o descuento a un cliente que de todos modos se iba a quedar) es casi siempre **mucho menor** que el costo de no identificar a un cliente que se va (un cliente perdido para siempre). El modelo est√° optimizado para minimizar las "oportunidades perdidas", lo cual es estrat√©gicamente correcto.

---

### **3. Rendimiento con la Mayor√≠a Satisfecha (An√°lisis de la Clase "No Churn")**

El modelo tambi√©n se comporta de manera excelente al identificar a los clientes leales.

* **Precision del 90%:** El modelo demuestra una **alta confianza** en sus predicciones de lealtad. Cuando predice que un cliente **no cancelar√°**, est√° en lo correcto 9 de cada 10 veces. Esto es √∫til para evitar dirigir campa√±as de retenci√≥n masivas a clientes que no las necesitan.

### **Conclusi√≥n y Veredicto Final**

**El modelo es un √©xito y est√° listo para ser considerado para su implementaci√≥n.**

Ha demostrado ser robusto, estable y, lo m√°s importante, **eficaz en su prop√≥sito principal**: identificar proactivamente a una gran mayor√≠a de los clientes en riesgo de cancelaci√≥n. Si bien genera un n√∫mero significativo de falsas alarmas, este es un costo operativo manejable a cambio del inmenso valor de retener a m√°s del 77% de los clientes que de otro modo se habr√≠an perdido en silencio.

El modelo proporciona al negocio una ventaja estrat√©gica clara, permitiendo pasar de una estrategia reactiva a una **proactiva en la lucha contra la p√©rdida de clientes**.


---

14. [Secci√≥n 14](#ch14)


<a id='ch14'></a>

----
### **El Informe Ejecutivo ‚Äî Un Veredicto Visual Comparativo** üìä

Hemos llegado al final de nuestra fase de pruebas. Ejecutamos m√∫ltiples "protocolos de estr√©s" (`K-Fold`, `Stratified K-Fold`, etc.) y cada uno nos gener√≥ un informe t√©cnico detallado. Este c√≥digo final act√∫a como el **analista senior que prepara el informe ejecutivo para la direcci√≥n**.

Su objetivo es tomar todos esos datos num√©ricos complejos de los diferentes informes y consolidarlos en **un √∫nico gr√°fico, claro y comparativo**. La meta es poder ver, de un solo vistazo, el rendimiento y la estabilidad de cada t√©cnica de prueba, permitiendo una toma de decisiones r√°pida e informada. Es el paso que transforma tablas de n√∫meros en una historia visual e intuitiva.

* * *

### **Paso 1: La Consolidaci√≥n de los Informes**

La primera tarea es puramente administrativa: antes de poder graficar, necesitamos que todos los datos de los diferentes informes est√©n en un √∫nico lugar y en un formato est√°ndar.

1.  **Recopilaci√≥n de Datos:** El c√≥digo revisa nuestro registro de resultados (`all_cv_results`), donde guardamos los informes detallados de cada prueba.
2.  **Estandarizaci√≥n del Formato (`melt`):** Cada informe individual tiene un formato de tabla ancha (una columna para "Accuracy", otra para "Precision", etc.). El c√≥digo reestructura inteligentemente cada una de estas tablas a un **formato de lista larga**. Imagina que en lugar de una tabla, ahora tienes una lista de entradas, donde cada entrada te dice tres cosas:
    *   La t√©cnica de prueba utilizada (ej: "Stratified K-Fold").
    *   La m√©trica que se midi√≥ (ej: "Recall").
    *   El resultado obtenido en esa ronda espec√≠fica (ej: 0.78).
3.  **Creaci√≥n de la Tabla Maestra:** Finalmente, todas estas listas estandarizadas se unen en una √∫nica y gran tabla maestra. Ahora tenemos un solo archivo que contiene todos los resultados de todas las pruebas, perfectamente organizado y listo para ser visualizado.

### **Paso 2: La Creaci√≥n del Gr√°fico Comparativo (`Boxplot`)**

Con los datos ya preparados, el c√≥digo utiliza una herramienta de visualizaci√≥n para crear un **gr√°fico de cajas y bigotes (boxplot)**. Este tipo de gr√°fico es una elecci√≥n experta porque no solo muestra el promedio, sino que revela la **distribuci√≥n completa y la consistencia** de los resultados de cada prueba.

As√≠ es como se debe interpretar el gr√°fico final:

*   **En el eje horizontal**, ver√°s las diferentes m√©tricas que conformaban nuestra "hoja de puntuaci√≥n" (Accuracy, Precision, Recall, etc.).
*   **Para cada m√©trica**, aparecer√°n **dos cajas de colores lado a lado**: una representando los resultados de la prueba `K-Fold` y la otra los de `Stratified K-Fold`.
*   **Cada caja te cuenta una historia detallada sobre el rendimiento en las 5 rondas de prueba:**
    *   La **l√≠nea dentro de la caja** es la mediana, que representa el resultado "t√≠pico" o central.
    *   La **altura de la caja** en s√≠ muestra el rango donde se ubicaron el 50% de los resultados. Una **caja m√°s peque√±a y compacta es mejor**, ya que indica que los resultados fueron muy consistentes y estables.
    *   Los **"bigotes" (las l√≠neas que se extienden desde la caja)** muestran el rango completo de los resultados, del mejor al peor. Bigotes cortos tambi√©n son se√±al de estabilidad.

El c√≥digo finaliza a√±adiendo toques profesionales al gr√°fico: un t√≠tulo claro, etiquetas en los ejes para que no haya ambig√ºedad, una leyenda que explique los colores y una cuadr√≠cula de fondo para facilitar la lectura de los valores.

* * *

### **Nota sobre la Exclusi√≥n de Leave-One-Out (LOO) del Gr√°fico Comparativo**

Aunque exploramos la metodolog√≠a `Leave-One-Out` (LOO) en la secci√≥n anterior y analizamos sus resultados, no se incluy√≥ en este gr√°fico comparativo junto a K-Fold y Stratified K-Fold. Las razones principales son:

1.  **Costo Computacional:** LOO es extremadamente costosa en t√©rminos de tiempo y recursos para datasets de tama√±o moderado a grande, lo que la hace impr√°ctica para una evaluaci√≥n rutinaria. Este gr√°fico se centra en t√©cnicas m√°s escalables.
2.  **Diferencias en Propiedades Estad√≠sticas:** La forma en que LOO calcula las m√©tricas (evaluando un solo punto en cada "pliegue") resulta en una desviaci√≥n est√°ndar inherentemente muy alta en las m√©tricas como el F1-Score. Incluir esto en el mismo gr√°fico que t√©cnicas con desviaciones est√°ndar comparativamente bajas (K-Fold, Stratified K-Fold) distorsionar√≠a la visualizaci√≥n y dificultar√≠a la comparaci√≥n efectiva de la estabilidad entre estas √∫ltimas.

Por lo tanto, mientras que LOO es una t√©cnica te√≥ricamente interesante para ciertos an√°lisis de granularidad fina, no es la herramienta est√°ndar para visualizar y comparar la estabilidad general del modelo en la forma que este boxplot permite.

* * *

### **Una Historia Contada con Datos**

El resultado final de este c√≥digo es una √∫nica imagen que responde preguntas complejas de forma sencilla. Al mirar el gr√°fico, podemos concluir instant√°neamente:

*   ¬øCu√°l fue el rendimiento general de nuestro `pipeline` en las diferentes m√©tricas?
*   ¬øHubo alguna diferencia significativa en el rendimiento promedio entre los dos protocolos de prueba?
*   **Y lo m√°s importante:** ¬øQu√© protocolo de prueba fue m√°s estable y consistente (es decir, cu√°l tiene las cajas m√°s peque√±as y los bigotes m√°s cortos)?

Este gr√°fico sirve como la evidencia final para justificar por qu√© `Stratified K-Fold` es la metodolog√≠a superior para este problema, transformando una serie de an√°lisis num√©ricos en una conclusi√≥n visual, poderosa y f√°cil de comunicar.


---

```python
# Preparar los datos para la visualizaci√≥n
cv_comparison_data = []
for name, df_result in all_cv_results.items():
    df_melted = df_result.melt(id_vars='Fold', var_name='Metric', value_name='Score')
    df_melted['Technique'] = name
    cv_comparison_data.append(df_melted)

cv_comparison_df = pd.concat(cv_comparison_data)

# Crear el gr√°fico
plt.figure(figsize=(15, 8))
sns.boxplot(data=cv_comparison_df, x='Metric', y='Score', hue='Technique', palette='viridis')
plt.title('Comparaci√≥n del Rendimiento de T√©cnicas de Validaci√≥n Cruzada', fontsize=16, fontweight='bold')
plt.ylabel('Puntuaci√≥n de la M√©trica')
plt.xlabel('M√©trica de Evaluaci√≥n')
plt.xticks(rotation=10)
plt.legend(title='T√©cnica de CV')
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.show()
```

![Generated Image](image_placeholder.png)


---

15. [Secci√≥n 15](#ch15)


<a id='ch15'></a>

### **Interpretaci√≥n del Gr√°fico Comparativo de Validaci√≥n Cruzada**

Este gr√°fico comparativo ofrece una visi√≥n clara y contundente sobre el rendimiento del modelo y la fiabilidad de las t√©cnicas de prueba. La conclusi√≥n principal es doble: primero, el **rendimiento del modelo es consistente y robusto**, y segundo, la t√©cnica de **`Stratified K-Fold` (verde) es demostrablemente superior a la `K-Fold` est√°ndar (azul)** en t√©rminos de estabilidad y fiabilidad de la evaluaci√≥n. La visualizaci√≥n confirma de manera pr√°ctica la recomendaci√≥n te√≥rica de usar la estratificaci√≥n para problemas de clasificaci√≥n.

---

### **1. El Veredicto sobre el Rendimiento del Modelo (An√°lisis de las Medianas)**

Si nos fijamos en la **l√≠nea horizontal dentro de cada caja**, que representa el rendimiento mediano o "t√≠pico" en las 5 rondas de prueba, podemos observar que **son casi id√©nticas para ambas t√©cnicas** a lo largo de todas las m√©tricas.

* **¬øQu√© significa esto?** Esto es una excelente noticia. Confirma lo que vimos en los resultados num√©ricos: el rendimiento promedio de nuestro modelo es estable y no depende de la metodolog√≠a exacta de divisi√≥n de datos. Ya sea con una divisi√≥n puramente aleatoria o una estratificada, el modelo consistentemente alcanza un F1-Score de ~0.74 y un ROC-AUC de ~0.85. Esto nos da una gran confianza en que el modelo es genuinamente bueno y su rendimiento no es una casualidad.

---

### **2. El Veredicto sobre la Metodolog√≠a de Prueba (An√°lisis de la Dispersi√≥n y Estabilidad)**

Aqu√≠ es donde el gr√°fico cuenta su historia m√°s importante. Al comparar el tama√±o y la forma de las cajas azules (`K-Fold`) con las cajas verdes (`Stratified K-Fold`), la diferencia es clara.

* **¬øC√≥mo leer las cajas?** Una caja m√°s **peque√±a y compacta** indica que los resultados de las 5 rondas de prueba fueron muy similares entre s√≠, lo que se traduce en una **mayor estabilidad y consistencia**. Una caja m√°s grande y alargada, junto con "bigotes" m√°s largos o la presencia de puntos (valores at√≠picos), indica mayor variabilidad y, por lo tanto, una menor fiabilidad en la estimaci√≥n del rendimiento.

* **La Evidencia Visual:**
    * **Precisi√≥n, F1-Score y ROC-AUC:** En estas m√©tricas clave, las cajas verdes (`Stratified K-Fold`) son visiblemente **m√°s peque√±as y compactas** que las azules. Esto muestra que la estratificaci√≥n produjo una estimaci√≥n del rendimiento mucho m√°s consistente.
    * **Valores At√≠picos (los puntos):** Es notable que la t√©cnica `K-Fold` (azul) gener√≥ varios **valores at√≠picos** (los c√≠rculos fuera de los "bigotes"). Esto significa que en algunas de las rondas de prueba, por pura casualidad, la divisi√≥n aleatoria cre√≥ un pliegue de prueba poco representativo que llev√≥ a un resultado de rendimiento inusualmente alto o bajo. `Stratified K-Fold`, al forzar una representaci√≥n equitativa, no gener√≥ estos resultados extremos.


El gr√°fico es la prueba visual de por qu√© `Stratified K-Fold` es el est√°ndar de oro para la clasificaci√≥n. Al garantizar que cada "pliegue" de prueba sea un microcosmos del desbalance de clases original, elimina la aleatoriedad que puede sesgar los resultados. Nos da una estimaci√≥n del rendimiento del modelo en la que podemos confiar m√°s, no porque el promedio sea diferente, sino porque la **variabilidad de esa estimaci√≥n es menor**.

---

### **Veredicto Final**

Este gr√°fico confirma de manera concluyente que, aunque nuestro modelo tiene un rendimiento s√≥lido independientemente de c√≥mo se le ponga a prueba, la evaluaci√≥n realizada con **`Stratified K-Fold` es m√°s rigurosa, estable y profesional**. Proporciona una imagen m√°s fidedigna del verdadero rendimiento del modelo, libre de la variabilidad introducida por divisiones puramente aleatorias.


---

16. [Secci√≥n 16](#ch16)


<a id='ch16'></a>

---

### **Crear el "Informe de Diagn√≥stico" Visual del Modelo**

Este c√≥digo tiene un √∫nico y muy importante objetivo: generar una de las visualizaciones m√°s fundamentales en la evaluaci√≥n de un modelo de clasificaci√≥n, la **Matriz de Confusi√≥n**.

Piensa en esta matriz como el **informe de diagn√≥stico detallado** o la **hoja de recuento de un inspector de calidad**. Mientras que m√©tricas como la exactitud nos dan un resumen general ("el 77% de las predicciones fueron correctas"), la matriz de confusi√≥n nos muestra el panorama completo. Nos dice no solo cu√°ntas veces acert√≥ el modelo, sino, lo que es m√°s importante, **c√≥mo se equivoc√≥ exactamente**. Este nivel de detalle es crucial para entender el comportamiento real del modelo y sus implicaciones en un contexto de negocio.

---

### **Paso 1: Preparaci√≥n del Lienzo**

La primera acci√≥n del c√≥digo es preparar el espacio de trabajo para la visualizaci√≥n. Es como si un artista preparara un lienzo en blanco de un tama√±o espec√≠fico antes de empezar a pintar. Este paso crea una figura y un conjunto de ejes, d√°ndonos un control total sobre el tama√±o y la apariencia final del gr√°fico.

---

### **Paso 2: El C√°lculo Central ‚Äî El Conteo de Aciertos y Errores**

Aqu√≠ es donde ocurre la magia. El c√≥digo utiliza los resultados del "examen final" del modelo: la lista de las respuestas correctas (qui√©nes cancelaron realmente, `y_test`) y la lista de las predicciones que hizo el modelo (`y_pred`).

Luego, realiza un conteo sistem√°tico, clasificando cada una de las predicciones en una de cuatro categor√≠as posibles:

1.  **Verdaderos Negativos (TN - True Negatives):** El modelo predijo "No Cancela" y, en efecto, el cliente no cancel√≥. **(Acierto)**. Son los clientes leales que el modelo identific√≥ correctamente.

2.  **Verdaderos Positivos (TP - True Positives):** El modelo predijo "S√≠ Cancela" y, en efecto, el cliente cancel√≥. **(Acierto)**. Son los clientes en riesgo que el modelo identific√≥ correctamente.

3.  **Falsos Positivos (FP - False Positives):** El modelo predijo "S√≠ Cancela", pero en realidad el cliente **no** cancel√≥. **(Error Tipo I)**. Estas son las "falsas alarmas", clientes leales que fueron incorrectamente etiquetados como en riesgo.

4.  **Falsos Negativos (FN - False Negatives):** El modelo predijo "No Cancela", pero en realidad el cliente **s√≠** cancel√≥. **(Error Tipo II)**. Estos son los errores m√°s peligrosos, las "oportunidades perdidas", clientes en riesgo que el modelo no logr√≥ detectar.

El resultado de este paso es una simple tabla de 2x2 que contiene el n√∫mero total de casos en cada una de estas cuatro categor√≠as.

---

### **Paso 3: La Creaci√≥n de la Visualizaci√≥n Profesional**

Finalmente, el c√≥digo toma esta tabla num√©rica y la transforma en un gr√°fico claro, profesional y f√°cil de interpretar.

* Utiliza una herramienta especializada (`ConfusionMatrixDisplay`) que est√° dise√±ada para presentar estos resultados de la mejor manera posible.
* Dibuja la matriz en el lienzo que preparamos al principio.
* **Asigna colores** a las celdas de la matriz (usando la paleta de colores "viridis"). Generalmente, los n√∫meros m√°s altos (m√°s predicciones en esa categor√≠a) tendr√°n un color m√°s intenso, lo que permite identificar r√°pidamente los resultados m√°s comunes.
* **Formatea los n√∫meros** para que se muestren como enteros claros dentro de cada celda.
* A√±ade un **t√≠tulo descriptivo** y, finalmente, muestra el gr√°fico completo al usuario.

### **Un Diagn√≥stico Completo**

Al final, no obtenemos solo una imagen, sino un diagn√≥stico visual completo. Mirando la matriz, un analista puede ver inmediatamente la diagonal de los aciertos (de arriba a la izquierda a abajo a la derecha) y, lo que es m√°s importante, analizar la naturaleza de los errores en las otras dos celdas. Esto permite responder preguntas cr√≠ticas como: "¬øEstamos generando demasiadas falsas alarmas?" o "¬øSe nos est√°n escapando demasiados clientes en riesgo?". Es una herramienta indispensable para evaluar verdaderamente el rendimiento de un modelo de clasificaci√≥n.


---

```python
fig, ax = plt.subplots(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Churn', 'Churn'])
disp.plot(ax=ax, cmap='viridis', values_format='d')
ax.set_title('Matriz de Confusi√≥n - Conjunto de Prueba', fontweight='bold', fontsize=14)
plt.show()
```

![Generated Image](image_placeholder.png)


---

17. [Secci√≥n 17](#ch17)


<a id='ch17'></a>

### **Interpretaci√≥n de la Matriz de Confusi√≥n**

La matriz de confusi√≥n ofrece un diagn√≥stico visual claro y directo del rendimiento del modelo en el conjunto de prueba. Confirma de manera contundente las conclusiones del informe de clasificaci√≥n: el modelo es **muy eficaz para su prop√≥sito principal de identificar a los clientes en riesgo de cancelaci√≥n**, aunque lo hace a costa de generar un n√∫mero considerable de "falsas alarmas". El bajo n√∫mero de clientes en riesgo que no fueron detectados es el indicador m√°s fuerte del √©xito y el valor comercial del modelo.

---

### **An√°lisis Detallado de los Cuatro Cuadrantes**

La matriz se divide en cuatro cuadrantes que nos muestran el desglose exacto de los aciertos y errores del modelo sobre los 1,409 clientes del conjunto de prueba.

#### **Los Aciertos del Modelo (La Diagonal Principal)**

Estos son los casos en los que el modelo predijo correctamente.

* **Verdaderos Negativos (Celda Superior Izquierda): 790**
    * **Qu√© significa:** El modelo predijo correctamente que **790 clientes no cancelar√≠an** su servicio.
    * **Implicancia de negocio:** Estos son los clientes leales que el modelo correctamente identific√≥ como de bajo riesgo. El negocio puede confiar en que no necesita gastar recursos de retenci√≥n en este grupo masivo.

* **Verdaderos Positivos (Celda Inferior Derecha): 288**
    * **Qu√© significa:** El modelo predijo correctamente que **288 clientes s√≠ cancelar√≠an** su servicio.
    * **Implicancia de negocio:** ¬°Este es el mayor √©xito y el principal valor del modelo! Estos 288 casos son **oportunidades de retenci√≥n directas y accionables**. El equipo de marketing o retenci√≥n puede ahora contactar proactivamente a este grupo para intentar salvarlos, generando un retorno de la inversi√≥n directo.

#### **Los Errores del Modelo (La Diagonal Secundaria)**

Estos son los casos donde el modelo se equivoc√≥, y entenderlos es clave para medir el impacto real.

* **Falsos Positivos (Celda Superior Derecha): 245**
    * **Qu√© significa:** El modelo predijo que 245 clientes cancelar√≠an, pero en realidad **no lo hicieron**.
    * **Implicancia de negocio:** Estas son las **"falsas alarmas"**. Representan el principal **costo operativo** del modelo. El equipo de retenci√≥n podr√≠a invertir tiempo y dinero (ofreciendo descuentos, por ejemplo) en 245 clientes que no ten√≠an intenci√≥n de irse. Si bien es un costo, a menudo se considera el "error preferible".

* **Falsos Negativos (Celda Inferior Izquierda): 86**
    * **Qu√© significa:** El modelo predijo que 86 clientes no cancelar√≠an, pero en realidad **s√≠ terminaron y√©ndose**.
    * **Implicancia de negocio:** Estos son los errores m√°s costosos en t√©rminos de ingresos perdidos, las **"oportunidades perdidas"**. Son 86 clientes en riesgo que el modelo **no logr√≥ detectar**, y que por lo tanto se perdieron sin que se pudiera realizar ninguna acci√≥n de retenci√≥n.

En conclusi√≥n la matriz de confusi√≥n nos muestra visualmente el intercambio estrat√©gico que el modelo est√° haciendo.

Al comparar los **288 clientes en riesgo que s√≠ detect√≥** (Verdaderos Positivos) con los **86 que no detect√≥** (Falsos Negativos), vemos que el modelo **captura a la gran mayor√≠a de los "churners" (288 de 374, que es el 77% de Recall)**.

Para lograr esta alta tasa de detecci√≥n, el modelo acepta un riesgo mayor de generar falsas alarmas (245 Falsos Positivos). Esta es una estrategia deliberada y com√∫n en problemas de negocio como este, donde la filosof√≠a es:

> **"Es preferible y menos costoso molestar a algunos clientes felices por error que dejar que los clientes infelices se vayan sin ser detectados".**

El gr√°fico confirma que el modelo est√° alineado con esta estrategia y funciona como se esperaba, proporcionando una herramienta de inteligencia de negocio muy valiosa.


---

18. [Secci√≥n 18](#ch18)


<a id='ch18'></a>

---
### **Diagn√≥stico Avanzado del Rendimiento del Modelo**

Este c√≥digo genera un **panel de control de diagn√≥stico avanzado** con dos de las visualizaciones m√°s importantes y reveladoras para un modelo de clasificaci√≥n: la **Curva ROC** y la **Curva de Precisi√≥n-Recall**.

El objetivo de estos gr√°ficos es ir m√°s all√° de las m√©tricas √∫nicas (como la exactitud o el F1-Score) y entender el **comportamiento din√°mico del modelo**. Nos muestran el **intercambio (trade-off)** entre los beneficios (capturar correctamente los casos de inter√©s) y los costos (cometer errores) a lo largo de *todos los posibles niveles de confianza* del modelo. Es como analizar el rendimiento de un motor no solo a una velocidad fija, sino a lo largo de todo su rango de revoluciones.

---

### **Paso 1: Preparaci√≥n del Panel de Control**

El primer paso del c√≥digo es crear una figura que contendr√° dos paneles (gr√°ficos) uno al lado del otro. Esto permite una comparaci√≥n visual directa y simult√°nea de las dos curvas, proporcionando una visi√≥n completa en un solo lugar.

---

### **Paso 2: El Primer Panel ‚Äî La Curva ROC (Receiver Operating Characteristic)**

Esta curva es el est√°ndar de la industria para evaluar la **capacidad de discriminaci√≥n** de un modelo. Responde a una pregunta fundamental: ¬øQu√© tan bueno es el modelo para distinguir entre un cliente que cancelar√° y uno que no?

* **C√≥mo Leer el Gr√°fico:**
    * **Eje Vertical (Tasa de Verdaderos Positivos o Recall):** Representa el **BENEFICIO**. Nos dice qu√© proporci√≥n de los clientes que *realmente cancelaron* fueron correctamente identificados por el modelo. Un valor m√°s alto es mejor.
    * **Eje Horizontal (Tasa de Falsos Positivos):** Representa el **COSTO**. Nos dice qu√© proporci√≥n de los clientes *leales* fueron incorrectamente etiquetados como en riesgo (falsas alarmas). Un valor m√°s bajo es mejor.
* **La Curva Naranja (Nuestro Modelo):** Esta l√≠nea muestra el rendimiento de nuestro modelo. El objetivo es que esta curva se **aleje lo m√°s posible hacia la esquina superior izquierda**. Una curva que se pega a esa esquina representa un modelo casi perfecto: uno que logra identificar a casi todos los que cancelan (Recall alto) con un costo muy bajo de falsas alarmas.
* **La L√≠nea Punteada Azul (Clasificador Aleatorio):** Esta l√≠nea diagonal representa un modelo sin ninguna habilidad, como lanzar una moneda al aire. Nuestro modelo debe estar siempre significativamente por encima de esta l√≠nea.
* **El Valor AUC (√Årea Bajo la Curva):** El n√∫mero `AUC = 0.846` es la calificaci√≥n final. Mide toda el √°rea bajo la curva naranja. Un 1.0 ser√≠a una puntuaci√≥n perfecta y 0.5 ser√≠a un modelo in√∫til. Un valor de **0.846 es excelente** y confirma que nuestro modelo tiene un fuerte poder para diferenciar entre las dos clases de clientes.

---

### **Paso 3: El Segundo Panel ‚Äî La Curva de Precisi√≥n-Recall (PR)**

Esta curva es especialmente importante para problemas con **datos desbalanceados**, como el nuestro, donde la clase que nos interesa (clientes que cancelan) es mucho m√°s peque√±a que la otra. Se enfoca directamente en el rendimiento sobre esa clase minoritaria.

* **C√≥mo Leer el Gr√°fico:**
    * **Eje Vertical (Precisi√≥n):** Representa la **CALIDAD** de las predicciones. Cuando el modelo dice que un cliente va a cancelar, ¬øqu√© porcentaje de las veces acierta?
    * **Eje Horizontal (Recall):** Representa la **CANTIDAD** de detecciones. ¬øQu√© porcentaje de todos los clientes que realmente cancelaron logramos encontrar?
* **La Curva Azul (Nuestro Modelo):** Muestra la relaci√≥n entre estas dos m√©tricas. Generalmente, para capturar m√°s casos (aumentar el Recall), debemos sacrificar algo de precisi√≥n. El objetivo es que la curva se mantenga **lo m√°s alta y a la derecha posible**, idealmente cerca de la esquina superior derecha. Esto indicar√≠a un modelo que puede encontrar a muchos de los que cancelan sin que la calidad de sus predicciones se desplome.
* **La L√≠nea Roja Punteada (L√≠nea Base):** Este es el punto de referencia de un modelo sin habilidad en este contexto. Representa la precisi√≥n que obtendr√≠amos si simplemente etiquet√°ramos a todos los clientes como "cancelar√°n" (que ser√≠a igual al porcentaje de clientes que cancelan en los datos, por ejemplo, 27%). Nuestro modelo debe estar siempre muy por encima de esta l√≠nea.

### **Un Diagn√≥stico Completo**

Estos dos gr√°ficos juntos nos ofrecen un diagn√≥stico exhaustivo. La **Curva ROC** nos confirma que el modelo tiene una base s√≥lida y una excelente capacidad de discriminaci√≥n general. La **Curva de Precisi√≥n-Recall**, por su parte, nos da una visi√≥n m√°s pr√°ctica y enfocada en el negocio sobre el rendimiento real en la tarea de encontrar a los pocos clientes en riesgo dentro de un mar de clientes leales, y el "costo" en t√©rminos de falsas alarmas que debemos pagar a medida que intentamos ser m√°s exhaustivos en nuestra b√∫squeda.


---

```python
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# --- Curva ROC ---
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.3f})')
axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Clasificador Aleatorio')
axes[0].set_xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
axes[0].set_ylabel('Tasa de Verdaderos Positivos (Sensibilidad/Recall)')
axes[0].set_title('Curva ROC', fontweight='bold', fontsize=14)
axes[0].legend(loc="lower right")

# --- Curva Precision-Recall ---
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
baseline = y_test.mean()
axes[1].plot(recall, precision, color='blue', lw=2, label='Curva Precision-Recall')
axes[1].axhline(y=baseline, color='red', linestyle='--', label=f'L√≠nea Base (Azar) ({baseline:.2f})')
axes[1].set_xlabel('Recall (Sensibilidad)')
axes[1].set_ylabel('Precision')
axes[1].set_title('Curva Precision-Recall', fontweight='bold', fontsize=14)
axes[1].legend(loc="lower left")

plt.tight_layout()
plt.show()
```

![Generated Image](image_placeholder.png)


---

19. [Secci√≥n 19](#ch19)


<a id='ch19'></a>

### **Interpretaci√≥n del Panel de Diagn√≥stico del Modelo**

Este panel de control visual ofrece un veredicto final y contundente sobre el rendimiento del modelo. Los gr√°ficos confirman que el modelo no solo es **estad√≠sticamente robusto**, sino tambi√©n **comercialmente viable y √∫til**. La Curva ROC valida su excelente capacidad para diferenciar entre clientes en riesgo y clientes leales, mientras que la Curva de Precisi√≥n-Recall ilustra claramente los intercambios estrat√©gicos que el negocio puede hacer al implementar una campa√±a de retenci√≥n. En conjunto, estas visualizaciones demuestran que el modelo es una herramienta de inteligencia de negocio eficaz.

---

### **An√°lisis de la Curva ROC (Gr√°fico de la Izquierda)**

Este gr√°fico eval√∫a la capacidad fundamental del modelo para **discriminar** entre las dos clases.

* **Veredicto Principal:** El rendimiento es **excelente**. La curva naranja est√° muy arqueada hacia la esquina superior izquierda, muy por encima de la l√≠nea punteada azul que representa el azar. Esto indica que el modelo tiene una alta sensibilidad (capta a los que cancelan) sin tener que pagar un alto costo en falsas alarmas.

* **El √Årea Bajo la Curva (AUC = 0.846):** Este n√∫mero cuantifica el rendimiento. Una puntuaci√≥n de **0.846** (donde 1.0 es perfecto y 0.5 es in√∫til) es considerada muy buena en la mayor√≠a de las aplicaciones comerciales. Confirma de manera s√≥lida que el modelo posee un alto poder predictivo y es fiable en su capacidad para clasificar a los clientes. Desde una perspectiva t√©cnica, el modelo est√° bien construido.
---

### **An√°lisis de la Curva de Precisi√≥n-Recall (Gr√°fico de la Derecha)**

Este gr√°fico es, posiblemente, el m√°s importante desde una **perspectiva de negocio**, ya que se enfoca en el rendimiento de la tarea clave: encontrar a los clientes que cancelan (la clase minoritaria).

* **Veredicto Principal:** El modelo es **muy superior a la l√≠nea de base**. La curva azul se mantiene consistentemente muy por encima de la l√≠nea roja punteada. Esto significa que usar el modelo para encontrar clientes en riesgo es significativamente m√°s eficaz que seleccionarlos al azar o que cualquier estrategia que no utilice datos.

* **Interpretaci√≥n del Trade-Off (Intercambio):** La curva ilustra perfectamente el costo de ser m√°s exhaustivo.
    * **A la izquierda del gr√°fico (Recall bajo):** Cuando el modelo es muy "exigente" y solo se√±ala a los clientes de los que est√° casi seguro, su **Precisi√≥n es alt√≠sima (cercana al 100%)**. Los pocos clientes que identifica son casi con toda seguridad futuros "churners".
    * **Movi√©ndose hacia la derecha (aumentando el Recall):** A medida que le pedimos al modelo que encuentre a *m√°s* clientes en riesgo (aumentando el Recall), la Precisi√≥n comienza a disminuir. Por ejemplo, para capturar al **80% de todos los clientes que realmente cancelar√°n (Recall = 0.8)**, la Precisi√≥n del modelo cae a aproximadamente **0.5 (o 50%)**.

#### **Implicancia Estrat√©gica:**

Esta curva es una herramienta para la toma de decisiones. Un gerente de marketing puede usarla para definir una estrategia:
> "Si queremos lanzar una campa√±a de retenci√≥n agresiva para contactar al 80% de los clientes en riesgo, este gr√°fico nos dice que debemos estar preparados para que aproximadamente la mitad de nuestros esfuerzos (una precisi√≥n del 50%) se dirijan a clientes que no iban a cancelar. Si nuestro presupuesto es m√°s limitado, podr√≠amos decidir contactar solo al 60% de los clientes en riesgo, lo que nos dar√≠a una precisi√≥n mayor, de alrededor del 60%, optimizando nuestros recursos".

---

Los dos gr√°ficos se complementan perfectamente para contar una historia completa y positiva:

* La **Curva ROC** nos da la **confianza acad√©mica** de que tenemos un modelo estad√≠sticamente s√≥lido y con un gran poder de discriminaci√≥n.
* La **Curva de Precisi√≥n-Recall** nos da la **gu√≠a pr√°ctica de negocio**, visualizando los costos y beneficios de diferentes estrategias de retenci√≥n.

En conjunto, demuestran que el modelo es una herramienta eficaz y lista para ser utilizada para impulsar decisiones de negocio proactivas y basadas en datos.


---

20. [Secci√≥n 20](#ch20)


<a id='ch20'></a>

---

### **Conclusiones Finales del Proyecto de Predicci√≥n de Churn**

#### **Resumen Ejecutivo**

El proyecto ha culminado con el desarrollo exitoso de un **modelo de machine learning robusto, fiable y comercialmente viable** para la predicci√≥n de la cancelaci√≥n de clientes (churn). Las rigurosas pruebas de validaci√≥n y la evaluaci√≥n final sobre datos no vistos confirman que el modelo posee un fuerte poder predictivo, superando significativamente las estrategias de referencia.

El principal valor del modelo radica en su capacidad para **identificar proactivamente al 77% de los clientes que est√°n en riesgo real de abandonar la empresa**, proporcionando una herramienta de inteligencia de negocio que permite pasar de una estrategia reactiva a una proactiva. Aunque el modelo genera un n√∫mero considerable de falsas alarmas, este es un intercambio estrat√©gico favorable que maximiza las oportunidades de retenci√≥n. Se recomienda proceder con una implementaci√≥n piloto para validar su impacto en el mundo real.

***

### **1. Hallazgos Clave del Modelo**

El an√°lisis exhaustivo, desde la exploraci√≥n de datos hasta la evaluaci√≥n final, nos ha proporcionado una comprensi√≥n clara del rendimiento y el comportamiento del modelo.

#### **A. Rendimiento Predictivo Cuantificado**

El rendimiento del modelo en el conjunto de prueba final, que representa su comportamiento esperado en producci√≥n, fue excelente y consistente con las estimaciones de la validaci√≥n cruzada:

* **Capacidad de Discriminaci√≥n (ROC-AUC): 0.846**
    * El modelo es muy eficaz para diferenciar entre clientes propensos a cancelar y clientes leales.
* **Capacidad de Detecci√≥n de Churn (Recall): 77%**
    * El modelo **logra identificar a 77 de cada 100 clientes que realmente cancelar√°n**, su principal objetivo de negocio.
* **Precisi√≥n en la Detecci√≥n de Churn (Precision): 54%**
    * Cuando el modelo alerta sobre un cliente, acierta en el 54% de los casos. Este es el principal costo operativo a considerar.
* **Equilibrio General (F1-Score): 64%**
    * Una puntuaci√≥n balanceada que confirma un rendimiento s√≥lido en la clase minoritaria ("Churn").

#### **B. El Intercambio Estrat√©gico: Maximizar la Detecci√≥n**

La **Matriz de Confusi√≥n** y la **Curva de Precisi√≥n-Recall** confirmaron visualmente que el modelo est√° optimizado para maximizar la **sensibilidad (Recall)**.  Esto significa que fue dise√±ado para minimizar las "oportunidades perdidas" (Falsos Negativos), aceptando a cambio un mayor n√∫mero de "falsas alarmas" (Falsos Positivos). Esta es la estrategia correcta cuando el costo de perder un cliente es significativamente mayor que el costo de una interacci√≥n de retenci√≥n innecesaria.

#### **C. Robustez Metodol√≥gica**

El proceso de desarrollo garantiz√≥ la fiabilidad del resultado final:
* El uso de **Pipelines** asegur√≥ que todo el preprocesamiento de datos se aplicara de manera consistente y sin fugas de informaci√≥n.
* La comparaci√≥n de t√©cnicas de validaci√≥n cruzada, visualizada en el **gr√°fico de Boxplot**, demostr√≥ que **Stratified K-Fold** era la metodolog√≠a m√°s estable, d√°ndonos una alta confianza en nuestras estimaciones de rendimiento.

***

### **2. Implicaciones para el Negocio**

La implementaci√≥n de este modelo puede generar un impacto directo y medible en el negocio.

* **Transici√≥n a una Estrategia Proactiva:** En lugar de reaccionar a las cancelaciones, el negocio puede anticiparse a ellas, contactando a los clientes de alto riesgo identificados por el modelo *antes* de que tomen la decisi√≥n de irse.
* **Optimizaci√≥n de Recursos:** Las campa√±as de retenci√≥n pueden ser dirigidas de manera inteligente al segmento de clientes con mayor probabilidad de cancelaci√≥n, optimizando el presupuesto de marketing y el tiempo del personal.
* **Toma de Decisiones Basada en Datos:** La **Curva de Precusi√≥n-Recall** puede ser utilizada como una herramienta estrat√©gica para ajustar el "nivel de agresividad" de las campa√±as. Dependiendo del presupuesto, se puede elegir un umbral de probabilidad que ofrezca el equilibrio deseado entre el n√∫mero de clientes contactados y la precisi√≥n de la campa√±a.

***

### **3. Recomendaciones y Pr√≥ximos Pasos**

Basado en los s√≥lidos resultados, se recomienda lo siguiente:

1.  **Implementaci√≥n Piloto:** Desplegar el modelo en un entorno controlado. Aplicar las predicciones a un segmento de clientes y medir el impacto real en la tasa de retenci√≥n en comparaci√≥n con un grupo de control. Esto permitir√° calcular el Retorno de la Inversi√≥n (ROI) del proyecto.
2.  **Optimizaci√≥n de Hiperpar√°metros:** Aunque el modelo base es fuerte, se puede realizar un proceso de "tuning" o ajuste fino de sus par√°metros para intentar mejorar a√∫n m√°s el equilibrio entre precisi√≥n y sensibilidad.
3.  **Monitoreo Continuo:** Una vez implementado, el rendimiento del modelo debe ser monitoreado a lo largo del tiempo para detectar cualquier degradaci√≥n (model drift). Se debe establecer un plan para re-entrenar el modelo peri√≥dicamente con datos nuevos y frescos.

En definitiva, el proyecto ha producido con √©xito una herramienta de an√°lisis predictivo que est√° lista para generar un valor tangible para el negocio. ‚úÖ


---

[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos Avanzados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_5_Regularizacion/README.md)
