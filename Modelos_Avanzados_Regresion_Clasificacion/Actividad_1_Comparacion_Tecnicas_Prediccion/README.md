# Comparaci贸n de T茅cnicas Avanzadas para Predicci贸n de Ingresos

Este proyecto aplica y compara modelos avanzados de regresi贸n y clasificaci贸n (Elastic Net, Regresi贸n Cuant铆lica, Random Forest y XGBoost) para resolver un problema de clasificaci贸n binaria: predecir si una persona ganar谩 m谩s de $50,000 al a帽o bas谩ndose en datos demogr谩ficos.

# Table of Contents
1. [Resumen del Proyecto](#ch1)
2. [Paso 1: Carga y Preprocesamiento de Datos](#ch2)
3. [Paso 2: Entrenamiento de los Modelos](#ch3)
4. [Paso 3: Evaluaci贸n de Desempe帽o](#ch4)
5. [Paso 4: An谩lisis de Importancia de Variables](#ch5)
6. [An谩lisis de Resultados](#ch6)
7. [Conclusi贸n Final y Recomendaci贸n](#ch7)

<a id="ch1"></a>
# Resumen del Proyecto

Una empresa desea construir un modelo robusto que le permita predecir con precisi贸n si una persona ganar谩 m谩s de $50,000 al a帽o, en base a sus caracter铆sticas demogr谩ficas y laborales. El objetivo es identificar qu茅 modelo se adapta mejor al problema, considerando precisi贸n, estabilidad e interpretabilidad.

Aunque el objetivo es de **clasificaci贸n binaria** (ingresos `>50K` o `<=50K`), este ejercicio explora un enfoque h铆brido:
- **Modelos de Clasificaci贸n Nativos**: Se utilizan Random Forest y XGBoost, dise帽ados espec铆ficamente para esta tarea.
- **Modelos de Regresi贸n Adaptados**: Se "fuerza" a modelos de regresi贸n como Elastic Net y Regresi贸n Cuant铆lica a resolver el problema. Para ello, las etiquetas (`'<=50K'`, `'>50K'`) se convierten en valores num茅ricos (`0`, `1`). Las salidas continuas de estos modelos se convierten de nuevo a clases aplicando un umbral de decisi贸n (0.5).

El objetivo es comparar estos dos enfoques y determinar cu谩l es superior en este contexto.

<a id="ch2"></a>
# Paso 1: Carga y Preprocesamiento de Datos

## 1.1 Importaci贸n de Librer铆as y Carga de Datos
En esta primera secci贸n, preparamos el entorno de trabajo importando las librer铆as necesarias para la manipulaci贸n de datos (`pandas`, `numpy`), visualizaci贸n (`matplotlib`, `seaborn`), preprocesamiento y modelado (`scikit-learn`, `xgboost`). Finalmente, cargamos el dataset "Adult Income" desde OpenML.

```python
# --- Librer铆as para manipulaci贸n de datos ---
import pandas as pd
import numpy as np

# --- Librer铆as para visualizaci贸n ---
import matplotlib.pyplot as plt
import seaborn as sns

# --- Funciones de Scikit-learn para carga de datos ---
from sklearn.datasets import fetch_openml

# --- Funciones de Scikit-learn para preprocesamiento y pipelines ---
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# --- Modelos de Scikit-learn y XGBoost ---
from sklearn.linear_model import ElasticNet, QuantileRegressor
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

# --- M茅tricas de evaluaci贸n de Scikit-learn ---
from sklearn.metrics import mean_squared_error, mean_pinball_loss
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay

# --- Carga del dataset ---
print("Cargando dataset 'adult'...")
adult_data = fetch_openml(name="adult", version=2, as_frame=True, parser='auto')
df = adult_data.frame
print("Dataset cargado exitosamente.")
df.head()
````

**Salida:**

```
Cargando dataset 'adult'...
Dataset cargado exitosamente.
```

## 1.2 Preprocesamiento y Limpieza de Datos

El preprocesamiento es un paso cr铆tico. En esta secci贸n, realizamos las siguientes tareas:

1.  **Limpieza de Valores Faltantes**: Reemplazamos el car谩cter `'?'` por `np.nan` para un manejo est谩ndar de nulos.
2.  **Codificaci贸n de la Variable Objetivo**: Convertimos la variable objetivo `class` de `['<=50K', '>50K']` a `[0, 1]`.
3.  **Divisi贸n de Datos**: Separamos los datos en conjuntos de entrenamiento (80%) y prueba (20%), usando estratificaci贸n para mantener la proporci贸n de clases.
4.  **Creaci贸n de Pipelines de Transformaci贸n**:
      * **Num茅ricas**: Imputamos los valores faltantes con la **mediana** y luego aplicamos **escalado est谩ndar** (`StandardScaler`).
      * **Categ贸ricas**: Imputamos los valores faltantes con la **moda** y aplicamos **One-Hot Encoding**.
5.  **`ColumnTransformer`**: Combinamos los pipelines para aplicar las transformaciones correctas a cada tipo de columna de forma eficiente y robusta.

<!-- end list -->

```python
print("Iniciando preprocesamiento de datos...")

# --- Definici贸n y limpieza de la variable objetivo ---
TARGET_NAME = 'class'
df.replace('?', np.nan, inplace=True)

# --- Separaci贸n de caracter铆sticas (X) y objetivo (y) ---
X = df.drop(TARGET_NAME, axis=1)
y = df[TARGET_NAME]

# --- Codificaci贸n de la variable objetivo a formato binario ---
y = y.apply(lambda x: 1 if x == '>50K' else 0)

# --- Identificaci贸n autom谩tica de tipos de columnas ---
numerical_features = X.select_dtypes(include=np.number).columns.tolist()
categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()

# --- Divisi贸n en conjuntos de entrenamiento y prueba ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

# --- Creaci贸n de pipelines de preprocesamiento ---
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# --- Combinaci贸n de pipelines con ColumnTransformer ---
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='passthrough'
)

print("Preprocesamiento completado.")
```

<a id="ch3"></a>

# Paso 2: Entrenamiento de los Modelos

Con los pipelines listos, entrenamos los cuatro modelos. Cada modelo se encapsula en un pipeline principal que primero aplica el preprocesador y luego entrena el modelo de Machine Learning.

Los modelos entrenados son:

  - **Elastic Net**: Un modelo de regresi贸n lineal adaptado para clasificaci贸n.
  - **Regresi贸n Cuant铆lica**: Predice un cuantil espec铆fico. Se entrenan tres modelos para los cuantiles 0.1, 0.5 y 0.9.
  - **Random Forest**: Un modelo de ensamble de 谩rboles de decisi贸n (clasificaci贸n nativa).
  - **XGBoost (Extreme Gradient Boosting)**: Un modelo de ensamble basado en 谩rboles de alto rendimiento (clasificaci贸n nativa).

<!-- end list -->

```python
print("Entrenando modelos...")

# --- Modelo 1: Elastic Net ---
elastic_net_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', ElasticNet(random_state=42))
])
elastic_net_pipeline.fit(X_train, y_train)

# --- Modelo 2: Regresi贸n Cuant铆lica ---
quantile_50_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', QuantileRegressor(quantile=0.5, solver='highs'))
])
quantile_50_pipeline.fit(X_train, y_train)

# (Se omiten los pipelines para cuantiles 0.1 y 0.9 por brevedad)

# --- Modelo 3: Random Forest ---
random_forest_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))
])
random_forest_pipeline.fit(X_train, y_train)

# --- Modelo 4: XGBoost ---
xgboost_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', xgb.XGBClassifier(eval_metric='logloss', random_state=42, n_jobs=-1))
])
xgboost_pipeline.fit(X_train, y_train)

print("Entrenamiento completado.")
```

<a id="ch4"></a>

# Paso 3: Evaluaci贸n de Desempe帽o

Una vez entrenados, medimos el rendimiento de los modelos.

  - **M茅tricas de Regresi贸n**: Para Elastic Net y Regresi贸n Cuant铆lica, evaluamos sus salidas num茅ricas directas con **RMSE** y **Pinball Loss**.
  - **M茅tricas de Clasificaci贸n**: Para todos los modelos, evaluamos su capacidad de clasificaci贸n con **Accuracy**, **Matriz de Confusi贸n** y la **Curva ROC / AUC**, que es una de las m茅tricas m谩s importantes para comparar clasificadores.

<!-- end list -->

```python
# --- Generaci贸n de predicciones ---
y_pred_elastic_net_reg = elastic_net_pipeline.predict(X_test)
y_pred_q50_reg = quantile_50_pipeline.predict(X_test)
y_pred_elastic_net_class = (y_pred_elastic_net_reg > 0.5).astype(int)
y_pred_q50_class = (y_pred_q50_reg > 0.5).astype(int)
y_pred_rf_class = random_forest_pipeline.predict(X_test)
y_pred_xgb_class = xgboost_pipeline.predict(X_test)
y_prob_rf = random_forest_pipeline.predict_proba(X_test)[:, 1]
y_prob_xgb = xgboost_pipeline.predict_proba(X_test)[:, 1]

# --- Diccionario de resultados para iteraci贸n ---
results = {
    "Elastic Net": {"pred_class": y_pred_elastic_net_class, "score": y_pred_elastic_net_reg},
    "Quantile Reg. p50": {"pred_class": y_pred_q50_class, "score": y_pred_q50_reg},
    "Random Forest": {"pred_class": y_pred_rf_class, "score": y_prob_rf},
    "XGBoost": {"pred_class": y_pred_xgb_class, "score": y_prob_xgb}
}

# --- Evaluaci贸n de Clasificaci贸n ---
print("\n--- MTRICAS DE CLASIFICACIN (PRINCIPALES) ---")
for name, res in results.items():
    accuracy = accuracy_score(y_test, res["pred_class"])
    auc = roc_auc_score(y_test, res["score"])
    print(f"\n--- {name} ---")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"ROC AUC Score: {auc:.4f}")

# --- Visualizaci贸n de Matrices de Confusi贸n ---
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.ravel()
for i, (name, res) in enumerate(results.items()):
    cm = confusion_matrix(y_test, res["pred_class"])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(ax=axes[i], cmap='Blues')
    axes[i].set_title(f"Matriz de Confusi贸n - {name}")
plt.tight_layout()
plt.show()

# --- Visualizaci贸n de Curvas ROC ---
plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')
for name, res in enumerate(results.items()):
    fpr, tpr, _ = roc_curve(y_test, res["score"])
    auc = roc_auc_score(y_test, res["score"])
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Comparaci贸n de Curvas ROC')
plt.legend()
plt.grid()
plt.show()
```

**Salida (M茅tricas):**

```
--- MTRICAS DE CLASIFICACIN (PRINCIPALES) ---

--- Elastic Net ---
Accuracy: 0.7607
ROC AUC Score: 0.5000

--- Quantile Reg. p50 ---
Accuracy: 0.7607
ROC AUC Score: 0.5000

--- Random Forest ---
Accuracy: 0.8602
ROC AUC Score: 0.904

--- XGBoost ---
Accuracy: 0.8741
ROC AUC Score: 0.929
```

<a id="ch5"></a>

# Paso 4: An谩lisis de Importancia de Variables

Para interpretar los modelos, analizamos qu茅 caracter铆sticas consideraron m谩s importantes.

  - **Elastic Net**: Se analizan los **coeficientes** (`.coef_`).
  - **Random Forest y XGBoost**: Se analiza el atributo `.feature_importances_`, que mide cu谩n 煤til fue cada variable para el modelo.

<!-- end list -->

```python
# --- Obtenci贸n de los nombres de las caracter铆sticas ---
cat_feature_names = xgboost_pipeline.named_steps['preprocessor'].named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()
all_feature_names = numerical_features + cat_feature_names

# --- An谩lisis para Elastic Net ---
elastic_net_coefs = pd.Series(
    elastic_net_pipeline.named_steps['regressor'].coef_,
    index=all_feature_names
).sort_values(ascending=False)
print("\nTop 10 variables m谩s influyentes (Elastic Net):")
print(elastic_net_coefs.head(10))

# --- An谩lisis para Random Forest y XGBoost ---
rf_importances = pd.Series(
    random_forest_pipeline.named_steps['classifier'].feature_importances_,
    index=all_feature_names
).sort_values(ascending=False)

xgb_importances = pd.Series(
    xgboost_pipeline.named_steps['classifier'].feature_importances_,
    index=all_feature_names
).sort_values(ascending=False)

# --- Visualizaci贸n de la importancia de variables ---
fig, axes = plt.subplots(1, 2, figsize=(18, 8))
rf_importances.head(15).sort_values().plot(kind='barh', ax=axes[0], title='Importancia de Variables - Random Forest')
xgb_importances.head(15).sort_values().plot(kind='barh', ax=axes[1], title='Importancia de Variables - XGBoost')
plt.tight_layout()
plt.show()
```

**Salida (Elastic Net):**

```
Top 10 variables m谩s influyentes (Elastic Net):
age                       0.0
fnlwgt                   -0.0
education-num             0.0
capital-gain              0.0
...
```

<a id="ch6"></a>

# An谩lisis de Resultados

### Conclusi贸n Ejecutiva

Los resultados demuestran una clara superioridad de los modelos basados en 谩rboles. **XGBoost es el modelo ganador **, con el mejor rendimiento en todas las m茅tricas relevantes (**ROC AUC de 0.929**). Por el contrario, los modelos de regresi贸n adaptados (**Elastic Net y Regresi贸n Cuant铆lica**) **fracasaron completamente**, sin capacidad predictiva alguna.

### An谩lisis Detallado

#### 1\. Modelos de Regresi贸n: Un Fracaso Predictivo 

Ambos modelos obtuvieron un **ROC AUC Score de 0.5000**, equivalente a una predicci贸n al azar. Las matrices de confusi贸n revelan que clasificaron a **todos** los individuos en la clase 0 (ingresos \<=$50K), fallando en identificar a una sola persona con ingresos altos. El an谩lisis de importancia de variables para Elastic Net confirma esto, ya que **todos los coeficientes fueron cero**, indicando que el modelo no utiliz贸 ninguna informaci贸n para predecir.

#### 2\. Modelos de Clasificaci贸n: Alto Rendimiento y Coherencia 

Estos modelos fueron altamente efectivos.

  * **Random Forest (Subcampe贸n )**: Con un **ROC AUC de 0.904** y un **Accuracy del 86.02%**, demostr贸 ser un modelo muy s贸lido. Su an谩lisis de importancia de variables revel贸 que `fnlwgt` (un peso estad铆stico), `age` (edad) y `capital-gain` (ganancias de capital) fueron sus principales predictores.

  * **XGBoost (Campe贸n )**: Super贸 a todos con un **ROC AUC de 0.929** y un **Accuracy del 87.41%**. Fue notablemente mejor en identificar correctamente a las personas con ingresos altos. Su an谩lisis de importancia mostr贸 un enfoque de "ancla", atribuyendo una importancia dominante a `marital-status_Married-civ-spouse` (estar casado), seguido de `education-num` (a帽os de educaci贸n) y `capital-gain`.

### Interpretaci贸n Visual: Curvas ROC

La gr谩fica de Curvas ROC confirma visualmente estos hallazgos:

  - Las curvas de **XGBoost** y **Random Forest** se elevan r谩pidamente, demostrando su excelente capacidad predictiva.
  - Las curvas de **Elastic Net y Regresi贸n Cuant铆lica** son una l铆nea diagonal, la firma visual de un clasificador sin poder predictivo.

<a id="ch7"></a>

# Conclusi贸n Final y Recomendaci贸n

Se recomienda **implementar el modelo XGBoost** para la predicci贸n de ingresos.

**Justificaci贸n:**

1.  **Precisi贸n Superior**: Cumple el objetivo de "predecir con precisi贸n" de manera sobresaliente, liderando en la m茅trica m谩s robusta (ROC AUC) y en la capacidad de identificar la clase de inter茅s (ingresos altos).
2.  **Insights Accionables**: A pesar de su complejidad, el modelo proporciona un insight de negocio claro y potente: el **estado civil** es el factor m谩s determinante, seguido de la educaci贸n y las ganancias de capital.
3.  **Est谩ndar de la Industria**: XGBoost es una herramienta probada, optimizada y escalable, ideal para ser desplegada en un entorno de producci贸n.

**Random Forest** se considera una excelente segunda opci贸n si la simplicidad o la velocidad de entrenamiento fueran factores prioritarios por encima del rendimiento m谩ximo.


