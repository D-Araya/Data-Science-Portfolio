# Comparaci√≥n de t√©cnicas avanzadas para predicci√≥n de ingresos, un problema de Regresi√≥n o Clasificaci√≥n?

Este proyecto explora y compara el rendimiento de modelos de regresi√≥n y clasificaci√≥n para predecir si un individuo gana m√°s de $50,000 al a√±o. El notebook demuestra un flujo de trabajo robusto utilizando `Pipelines` y `ColumnTransformer` de scikit-learn.

---

### üéØ **Objetivo Principal**
- **Prop√≥sito:** Aplicar y comparar cuatro modelos avanzados (dos de regresi√≥n adaptados y dos de clasificaci√≥n nativos) sobre un mismo problema para evaluar su rendimiento, adecuaci√≥n e interpretabilidad.
- **Problema de Negocio:** Determinar el modelo m√°s preciso y fiable para predecir la categor√≠a de ingresos de una persona bas√°ndose en sus caracter√≠sticas demogr√°ficas y laborales.

### üìä **Dataset Utilizado**
- **Nombre:** Adult Income
- **Fuente:** Repositorio de OpenML, cargado a trav√©s de `scikit-learn`.

### üõ†Ô∏è **Metodolog√≠a y Modelos Aplicados**
El proyecto sigue un flujo de trabajo estructurado que incluye:
1.  **Preprocesamiento Robusto:** Uso de `Pipelines` para imputar valores faltantes (mediana/moda) y escalar/codificar variables num√©ricas y categ√≥ricas.
2.  **Entrenamiento de Modelos:** Se implementaron y compararon cuatro enfoques:
    - **Regresi√≥n (Adaptada a Clasificaci√≥n):**
        - `ElasticNet`
        - `QuantileRegressor`
    - **Clasificaci√≥n (Nativos):**
        - `RandomForestClassifier`
        - `XGBoostClassifier`
3.  **Evaluaci√≥n Comparativa:** El rendimiento se midi√≥ con m√©tricas clave como **Accuracy**, **Matriz de Confusi√≥n** y, fundamentalmente, el **√Årea Bajo la Curva ROC (AUC)**.

### üöÄ **Resultados y Hallazgos Principales**
- **Fracaso de los Modelos de Regresi√≥n:** Los modelos `Elastic Net` y `Regresi√≥n Cuant√≠lica`, al ser adaptados para clasificaci√≥n con un umbral de 0.5, **fallaron completamente** (ROC AUC de 0.50), demostrando no tener ninguna capacidad predictiva para este problema.
- **Superioridad de los Modelos de √Årboles:** `Random Forest` y `XGBoost` demostraron ser altamente efectivos, logrando excelentes resultados.
- **Modelo Ganador üèÜ:** **XGBoost** fue el modelo con mejor rendimiento, alcanzando la mayor precisi√≥n y un **ROC AUC de 0.929**.
- **Variables M√°s Predictivas:** Los modelos exitosos identificaron consistentemente el **estado civil**, las **ganancias de capital** y el **nivel educativo** como los factores de mayor impacto en la predicci√≥n de ingresos.

### üèÜ **Recomendaci√≥n Final**
Se recomienda implementar el **modelo XGBoost** para la tarea de predicci√≥n de ingresos, debido a su superioridad demostrada en todas las m√©tricas de clasificaci√≥n y su capacidad para generar insights de negocio claros y accionables.

# [**Ir al Proyecto**](../Actividad_1_Comparacion_Tecnicas_Prediccion/Actividad_1_Modulo_5_Comp_t√©cnicas_avanzadas_predicci√≥n_ingresos.ipynb)

---

## ‚öôÔ∏è **C√≥mo Ejecutar el Notebook**

Para correr este proyecto en tu entorno local, sigue estos pasos:

1.  **Aseg√∫rate de tener Python 3.8 o superior.**

2.  **Clona o descarga este repositorio.**

3.  **Instala las librer√≠as necesarias:**
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn xgboost
    ```

4.  **Ejecuta el notebook de Jupyter:**
    `Actividad_1_Modulo_5_Comp_t√©cnicas_avanzadas_predicci√≥n_ingresos.ipynb`

---
[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos Avanzados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_2_Comparativa_Regresion/README.md)

