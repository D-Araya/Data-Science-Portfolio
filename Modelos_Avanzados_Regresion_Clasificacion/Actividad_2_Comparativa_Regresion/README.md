# Table of Contents

<a id='ch1'></a>

# Aplicaci√≥n Comparativa de T√©cnicas Avanzadas de Regresi√≥n

**Objetivo:** Este notebook presenta una soluci√≥n integral y robusta para el an√°lisis comparativo de t√©cnicas de regresi√≥n. Se fusionan dos enfoques: la claridad narrativa de un Jupyter Notebook con el rigor t√©cnico de un script de producci√≥n, incluyendo manejo de errores, evaluaci√≥n exhaustiva y visualizaciones avanzadas.

### Estructura del An√°lisis:

1.  **Predicci√≥n de Precios de Viviendas con Elastic Net:** Con evaluaci√≥n multi-m√©trica y visualizaci√≥n de coeficientes mejorada.
2.  **Estimaci√≥n de Percentiles con Regresi√≥n Cuant√≠lica:** Con carga de datos robusta (a prueba de fallos) y gr√°ficos explicativos.
3.  **Proyecci√≥n de Indicadores Macroecon√≥micos con VAR:** Con un enfoque metodol√≥gico riguroso de entrenamiento/prueba y evaluaci√≥n cuantitativa.

-----

## 0\. Preparaci√≥n del Entorno e Importaci√≥n de Librer√≠as

### Explicaci√≥n Profesional y Minuciosa:

Antes de cualquier an√°lisis, es imperativo establecer un entorno de trabajo reproducible y completo. La siguiente celda de c√≥digo se encarga de importar todas las librer√≠as necesarias, agrupadas por su funcionalidad principal:

  * **Manipulaci√≥n de Datos (`pandas`, `numpy`):** Son el pilar del ecosistema de ciencia de datos en Python. `pandas` proporciona estructuras de datos de alto rendimiento (como el DataFrame), mientras que `numpy` ofrece soporte para operaciones matriciales y num√©ricas eficientes.
  * **Visualizaci√≥n (`matplotlib`, `seaborn`):** Son esenciales para la exploraci√≥n de datos y la comunicaci√≥n de resultados. `matplotlib` es la librer√≠a fundamental, y `seaborn` es una capa de abstracci√≥n sobre ella que permite crear gr√°ficos estad√≠sticos m√°s atractivos y complejos con mayor facilidad.
  * **Modelado y Evaluaci√≥n (`sklearn`):** Scikit-learn es la librer√≠a est√°ndar para el aprendizaje autom√°tico en Python. Importamos m√≥dulos espec√≠ficos para la divisi√≥n de datos (`train_test_split`), preprocesamiento (`StandardScaler`), los propios modelos de regresi√≥n (`ElasticNetCV`, `QuantileRegressor`) y un conjunto completo de m√©tricas de evaluaci√≥n (`mean_squared_error`, `r2_score`, etc.).
  * **An√°lisis de Series de Tiempo (`statsmodels`):** Es la librer√≠a de referencia en Python para la econometr√≠a y el an√°lisis estad√≠stico avanzado, proporcionando herramientas robustas para modelos como VAR y tests de diagn√≥stico como el de Dickey-Fuller Aumentado (`adfuller`).

Finalmente, se establece un **estilo visual** consistente para todos los gr√°ficos.


---

```python
# --- Manipulaci√≥n y An√°lisis de Datos ---
import pandas as pd
import numpy as np

# --- Visualizaci√≥n de Datos ---
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# --- Modelos, M√©tricas y Preprocesamiento ---
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_pinball_loss, mean_absolute_error, r2_score
from sklearn.linear_model import ElasticNet, ElasticNetCV, QuantileRegressor

# --- Carga de Datasets ---
from sklearn.datasets import fetch_california_housing, fetch_openml

# --- Herramientas para Series de Tiempo ---
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import adfuller
from statsmodels.datasets import macrodata

# --- Configuraciones Adicionales ---
# Establecer un estilo visual atractivo y profesional para los gr√°ficos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
# Ignorar advertencias menores para una salida m√°s limpia
# warnings.filterwarnings('ignore')

print("‚úÖ Librer√≠as importadas y entorno configurado correctamente.")
```

```
‚úÖ Librer√≠as importadas y entorno configurado correctamente.

```


---

<a id='ch2'></a>

-----

## 1\. Predicci√≥n de Precios de Viviendas con Elastic Net

**Contexto:** El objetivo es predecir el valor mediano de las viviendas en California. Este problema es ideal para Elastic Net debido a la potencial correlaci√≥n entre las caracter√≠sticas geogr√°ficas y estructurales.

### 1.1 Carga y Preparaci√≥n de Datos

El preprocesamiento de datos es un paso fundamental que impacta directamente en el rendimiento del modelo. En la celda siguiente, ejecutaremos tres pasos cr√≠ticos:

1.  **Carga y Estructuraci√≥n:** Cargamos el conjunto de datos desde `sklearn`. Este objeto contiene tanto las caracter√≠sticas como el objetivo. Para facilitar su manipulaci√≥n y an√°lisis, los estructuramos en un **DataFrame** de `pandas` para las variables independientes (`X`) y una **Serie** para la variable dependiente (`y`).
2.  **Divisi√≥n de Datos (Entrenamiento y Prueba):** Dividimos el dataset en dos subconjuntos: uno de **entrenamiento** (generalmente el 80%) y uno de **prueba** (el 20% restante). Esta partici√≥n es crucial para una evaluaci√≥n honesta del modelo. El modelo "aprende" patrones √∫nicamente del conjunto de entrenamiento. Luego, su capacidad para **generalizar** a datos nuevos y no vistos se mide en el conjunto de prueba. El uso de `random_state` garantiza que esta divisi√≥n sea siempre la misma, asegurando la **reproducibilidad** de nuestros resultados.
3.  **Escalado de Caracter√≠sticas:** La regresi√≥n Elastic Net aplica una penalizaci√≥n a la magnitud de los coeficientes del modelo. Si las caracter√≠sticas tienen escalas muy diferentes (ej., ingresos en decenas de miles vs. n√∫mero de habitaciones de 1 a 5), el modelo penalizar√≠a injustamente a las caracter√≠sticas con magnitudes num√©ricas m√°s grandes. Para evitar esto, utilizamos `StandardScaler`, que transforma cada caracter√≠stica para que tenga una **media de 0 y una desviaci√≥n est√°ndar de 1**. Es vital ajustar (`fit`) el escalador **solo con los datos de entrenamiento** y luego aplicar la misma transformaci√≥n (`transform`) a ambos conjuntos para evitar la fuga de informaci√≥n (data leakage) del conjunto de prueba al de entrenamiento.

<!-- end list -->


---

```python
# Cargar el dataset de California Housing
print("üìä Cargando y preparando el dataset California Housing...")
housing = fetch_california_housing()
X_housing = pd.DataFrame(housing.data, columns=housing.feature_names)
y_housing = pd.Series(housing.target, name='MedHouseVal')

# Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)
X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(
    X_housing, y_housing, test_size=0.2, random_state=42
)

# Escalar las caracter√≠sticas num√©ricas
scaler_h = StandardScaler()
X_train_h_scaled = scaler_h.fit_transform(X_train_h)
X_test_h_scaled = scaler_h.transform(X_test_h)

print(f"Shape del dataset de entrenamiento: {X_train_h_scaled.shape}")
print(f"Shape del dataset de prueba: {X_test_h_scaled.shape}")
```

```
üìä Cargando y preparando el dataset California Housing...
Shape del dataset de entrenamiento: (16512, 8)
Shape del dataset de prueba: (4128, 8)

```


---

<a id='ch3'></a>

### 1.2 Ajuste del Modelo con Validaci√≥n Cruzada

La efectividad de Elastic Net depende de dos hiperpar√°metros clave: `alpha`, que controla la magnitud total de la regularizaci√≥n, y `l1_ratio`, que determina la mezcla entre la penalizaci√≥n L1 (Lasso) y L2 (Ridge). En lugar de elegirlos manualmente (lo que ser√≠a propenso a errores y sesgos), empleamos `ElasticNetCV`.

Esta t√©cnica automatiza la b√∫squeda de los mejores hiperpar√°metros mediante **validaci√≥n cruzada (CV)**. El proceso es el siguiente:

1.  Se define una parrilla de posibles valores para `l1_ratio`.
2.  Para cada valor de `l1_ratio`, `ElasticNetCV` busca autom√°ticamente el mejor `alpha`.
3.  El rendimiento se eval√∫a dividiendo el conjunto de entrenamiento en `k` pliegues (en este caso, `cv=5`). El modelo se entrena en `k-1` pliegues y se valida en el pliegue restante, rotando este proceso `k` veces.
4.  El par de hiperpar√°metros que produce el mejor rendimiento promedio a trav√©s de todos los pliegues se selecciona como el √≥ptimo.

Este enfoque es robusto porque reduce la varianza de la estimaci√≥n del rendimiento y protege contra el sobreajuste, dando como resultado un modelo con mejor capacidad de generalizaci√≥n. El par√°metro `n_jobs=-1` instruye al modelo a usar todos los n√∫cleos de CPU disponibles, acelerando el proceso de c√°lculo.


---

```python
# Entrenar el modelo Elastic Net buscando los mejores hiperpar√°metros
print("\nüîß Entrenando modelo Elastic Net con ElasticNetCV...")
elastic_cv = ElasticNetCV(
    l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99],
    cv=5,
    random_state=42,
    n_jobs=-1,
    max_iter=2000 # Aumentar iteraciones para asegurar convergencia
)
elastic_cv.fit(X_train_h_scaled, y_train_h)

print(f"‚úÖ Mejor alpha encontrado: {elastic_cv.alpha_:.4f}")
print(f"‚úÖ Mejor l1_ratio encontrado: {elastic_cv.l1_ratio_:.2f}")
```

```

üîß Entrenando modelo Elastic Net con ElasticNetCV...
‚úÖ Mejor alpha encontrado: 0.0008
‚úÖ Mejor l1_ratio encontrado: 0.99

```


---

<a id='ch4'></a>

### 1.3 Evaluaci√≥n Exhaustiva del Modelo

Una vez entrenado el modelo, es crucial evaluar su rendimiento en el conjunto de prueba (datos que nunca ha visto). Utilizar una sola m√©trica puede dar una visi√≥n incompleta; por ello, calculamos un conjunto de tres indicadores est√°ndar para la regresi√≥n:

  * **RMSE (Root Mean Squared Error):** Es la ra√≠z cuadrada del promedio de los errores al cuadrado. Est√° en la misma unidad que la variable objetivo (en este caso, "cientos de miles de d√≥lares"). Su principal caracter√≠stica es que **penaliza los errores grandes de forma m√°s significativa** debido a la operaci√≥n de elevar al cuadrado.
  * **MAE (Mean Absolute Error):** Es el promedio de los errores absolutos. Tambi√©n est√° en la misma unidad que el objetivo, pero a diferencia del RMSE, **trata todos los errores por igual**, siendo menos sensible a valores at√≠picos (outliers) extremos.
  * **R¬≤ (Coeficiente de Determinaci√≥n):** Esta m√©trica mide la **proporci√≥n de la varianza** en la variable dependiente que es predecible a partir de las variables independientes. Un valor de 1.0 indica una predicci√≥n perfecta, mientras que un valor de 0.0 indica que el modelo no es mejor que simplemente predecir la media. Un R¬≤ de, por ejemplo, 0.595 significa que el modelo explica el 59.5% de la variabilidad en los precios de las viviendas.

Este conjunto de m√©tricas nos proporciona una perspectiva multidimensional de la precisi√≥n, la magnitud del error promedio y la capacidad explicativa del modelo.


---

```python
# Realizar predicciones en el conjunto de prueba
y_pred_elastic = elastic_cv.predict(X_test_h_scaled)

# Calcular un conjunto de m√©tricas de evaluaci√≥n
rmse_elastic = np.sqrt(mean_squared_error(y_test_h, y_pred_elastic))
mae_elastic = mean_absolute_error(y_test_h, y_pred_elastic)
r2_elastic = r2_score(y_test_h, y_pred_elastic)

# Imprimir los resultados de forma clara
print("\nüìà RESULTADOS DE EVALUACI√ìN (Elastic Net):")
print(f"-> RMSE (Root Mean Squared Error): {rmse_elastic:.4f}")
print(f"-> MAE (Mean Absolute Error):     {mae_elastic:.4f}")
print(f"-> R¬≤ (Coeficiente de Determinaci√≥n): {r2_elastic:.4f} (El modelo explica el {r2_elastic:.1%} de la varianza)")
```

```

üìà RESULTADOS DE EVALUACI√ìN (Elastic Net):
-> RMSE (Root Mean Squared Error): 0.7448
-> MAE (Mean Absolute Error):     0.5332
-> R¬≤ (Coeficiente de Determinaci√≥n): 0.5767 (El modelo explica el 57.7% de la varianza)

```


---

<a id='ch5'></a>

### **Interpretaci√≥n de Resultados del Modelo Elastic Net**

Estos resultados nos permiten evaluar el rendimiento del modelo de regresi√≥n Elastic Net desde distintas perspectivas: su capacidad explicativa (R¬≤), su error promedio (MAE) y su error penalizando las desviaciones m√°s grandes (RMSE).

#### **Conclusi√≥n General üéØ**

El modelo tiene una **capacidad predictiva moderada y potencialmente √∫til**. Logra explicar m√°s de la mitad de la variabilidad de los datos, pero a√∫n deja un margen de error y una porci√≥n significativa de la varianza sin explicar. No es un modelo de alta precisi√≥n, pero es considerablemente mejor que una simple suposici√≥n.

---

#### **An√°lisis Detallado por M√©trica**

* **R¬≤ (Coeficiente de Determinaci√≥n): 0.5767**
    * **Qu√© significa**: Este es quiz√°s el indicador m√°s importante aqu√≠. Un R¬≤ de 0.577 nos dice que tu modelo es capaz de **explicar el 57.7% de la variabilidad** en la variable objetivo. En otras palabras, las caracter√≠sticas que usaste para entrenar el modelo explican un poco m√°s de la mitad del comportamiento de lo que intentas predecir.
    * **Interpretaci√≥n**: Un valor de ~58% se considera **moderado**. Esto significa que el modelo ha capturado una tendencia significativa en los datos, pero todav√≠a hay un 42.3% de la varianza que no se explica por las variables del modelo. Esto puede deberse a factores aleatorios, ruido en los datos o la ausencia de otras variables predictivas importantes.

* **MAE (Mean Absolute Error): 0.5332**
    * **Qu√© significa**: Esta es la medida m√°s directa del error de predicci√≥n. Indica que, en promedio, las predicciones del modelo se desv√≠an **0.53 unidades** del valor real.
    * **Interpretaci√≥n**: Si estuvieras usando el modelo para hacer una predicci√≥n, esperar√≠as que tu predicci√≥n estuviera equivocada por aproximadamente 0.53 unidades (hacia arriba o hacia abajo). La "gravedad" de este error depende totalmente de la escala de tu variable objetivo. Si predices una calificaci√≥n del 1 al 10, un error de 0.53 es relativamente peque√±o. Si predices un valor que normalmente es 0.8, es un error considerable.

* **RMSE (Root Mean Squared Error): 0.7448**
    * **Qu√© significa**: El RMSE es similar al MAE, pero penaliza los errores m√°s grandes de forma m√°s severa porque eleva los errores al cuadrado antes de promediarlos.
    * **Interpretaci√≥n**: El hecho de que el **RMSE (0.74) sea mayor que el MAE (0.53)** es normal y esperado. Esta diferencia sugiere que el modelo comete algunos errores que son notablemente m√°s grandes que la media. Estos "outliers" en los errores inflan el valor del RMSE. Mientras que el error t√≠pico es de 0.53, existen predicciones ocasionales que est√°n bastante m√°s lejos del valor real.


El modelo Elastic Net tiene un rendimiento aceptable. Ha logrado establecer una relaci√≥n significativa entre tus variables predictoras y la variable objetivo. Sin embargo, no es lo suficientemente preciso como para confiar ciegamente en sus predicciones individuales.

* **Es √∫til para**: Entender tendencias generales, identificar la direcci√≥n de las relaciones entre variables y hacer estimaciones aproximadas.
* **No es ideal para**: Aplicaciones que requieran alta precisi√≥n, como proyecciones financieras cr√≠ticas o procesos de control de calidad muy estrictos, donde un error de 0.53 - 0.74 unidades tendr√≠a consecuencias negativas.


---

<a id='ch6'></a>

### 1.4 Visualizaci√≥n e Interpretaci√≥n de Coeficientes

M√°s all√° de la predicci√≥n, un objetivo clave del modelado es la **interpretaci√≥n**: entender qu√© factores impulsan el resultado. Los coeficientes de un modelo lineal nos indican la magnitud y direcci√≥n del efecto de cada variable.

La siguiente celda genera una visualizaci√≥n dise√±ada para maximizar la interpretabilidad:

1.  Se extraen los coeficientes finales del modelo `elastic_cv` entrenado.
2.  Se ordenan las caracter√≠sticas no por su nombre, sino por la **magnitud absoluta** de su coeficiente. Esto nos permite clasificar las variables de la menos a la m√°s influyente, independientemente de si su efecto es positivo o negativo.
3.  Se utiliza un **c√≥digo de colores condicional**: las barras se colorean de azul si el coeficiente es positivo (un aumento en la variable aumenta el precio de la vivienda) y de rojo si es negativo (un aumento en la variable disminuye el precio).

El resultado es un gr√°fico denso en informaci√≥n que comunica de manera inmediata tanto la **importancia relativa** como la **direcci√≥n del impacto** de cada predictor en el modelo.


---

```python
# Crear una serie de pandas con los coeficientes
coefficients = pd.Series(elastic_cv.coef_, index=X_housing.columns)

# Reordenar los coeficientes por su valor absoluto para mostrar importancia
coefficients_sorted = coefficients.reindex(coefficients.abs().sort_values(ascending=True).index)

# Crear colores para distinguir coeficientes positivos y negativos
colors = ['firebrick' if x < 0 else 'darkblue' for x in coefficients_sorted.values]

# Crear el gr√°fico de barras horizontal
plt.figure(figsize=(12, 8))
plt.barh(range(len(coefficients_sorted)), coefficients_sorted.values, color=colors)
plt.yticks(range(len(coefficients_sorted)), coefficients_sorted.index)
plt.xlabel('Valor del Coeficiente')
plt.title('Importancia de las Caracter√≠sticas - Elastic Net\n(Azul: Impacto Positivo, Rojo: Impacto Negativo)')
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()
```

![Generated Image](image_placeholder.png)


---

<a id='ch7'></a>

### **Importancia de Caracter√≠sticas del Modelo Elastic Net**

Esta visualizaci√≥n nos permite entender la l√≥gica interna del modelo Elastic Net al mostrar el **impacto** y la **direcci√≥n** que cada caracter√≠stica tiene sobre la predicci√≥n final. Los coeficientes de un modelo lineal como este son directamente interpretables:

* **Valor del Coeficiente**: La magnitud (valor absoluto) indica la fuerza de la influencia de la variable. Un coeficiente m√°s alejado de cero es m√°s importante.
* **Signo del Coeficiente**:
    * **Positivo (Azul)**: Un aumento en el valor de esta caracter√≠stica aumenta el valor de la predicci√≥n.
    * **Negativo (Rojo)**: Un aumento en el valor de esta caracter√≠stica disminuye el valor de la predicci√≥n.

---

### **An√°lisis de los Impulsores Clave**

El modelo ha identificado un conjunto claro de factores determinantes y ha descartado otros como menos relevantes.

#### **1. Los Factores M√°s Influyentes: Ingreso y Ubicaci√≥n Geogr√°fica**

El modelo basa sus predicciones principalmente en dos factores: el poder adquisitivo del √°rea y su ubicaci√≥n geogr√°fica.

* üîµ **`MedInc` (Ingreso Medio)**: Es, con diferencia, el **predictor positivo m√°s fuerte**. Su gran coeficiente azul indica que a medida que el ingreso medio de un bloque aumenta, el valor predicho (probablemente el precio de la vivienda) aumenta de manera significativa. Esta es una relaci√≥n l√≥gica y esperada.

* üî¥ **`Latitude` y `Longitude` (Ubicaci√≥n)**: Estas son las **variables con el impacto negativo m√°s fuerte**. Esto revela una fuerte dependencia geogr√°fica. En el contexto de datasets como el de la vivienda en California, un aumento en la longitud (moverse hacia el este) y la latitud (moverse hacia el norte) generalmente implica alejarse de los centros urbanos costeros y caros (ej. Los √Ångeles, √Årea de la Bah√≠a). El modelo ha aprendido correctamente que esta tendencia geogr√°fica se correlaciona con una disminuci√≥n en el valor.

#### **2. Caracter√≠sticas de Impacto Secundario**

Algunas caracter√≠sticas de las viviendas tienen un impacto moderado pero notable:

* üîµ **`AveBedrms` (Promedio de Dormitorios)**: Tiene un impacto positivo moderado. Como es de esperar, las viviendas con m√°s dormitorios tienden a ser m√°s valiosas.
* üî¥ **`AveRooms` (Promedio de Habitaciones)**: Curiosamente, esta variable tiene un **impacto negativo**. Esto puede parecer contraintuitivo, pero podr√≠a explicarse por:
    * **Multicolinealidad**: Su efecto podr√≠a estar solapado con `AveBedrms`. Una vez que se considera el n√∫mero de dormitorios, tener muchas "otras" habitaciones podr√≠a no a√±adir valor o incluso ser indicativo de dise√±os menos deseables (muchas habitaciones peque√±as vs. pocas pero grandes).
    * **Caracter√≠sticas del Dataset**: Podr√≠a reflejar una peculiaridad del conjunto de datos donde las propiedades con m√°s habitaciones totales no son necesariamente las de mayor valor.

#### **3. Caracter√≠sticas Descartadas por el Modelo**

Una de las principales ventajas de Elastic Net es su capacidad para realizar **selecci√≥n de caracter√≠sticas** (a trav√©s de su componente L1/Lasso), reduciendo a cero el impacto de las variables menos √∫tiles.

* **`Population` y `AveOccup` (Poblaci√≥n y Ocupaci√≥n Media)**: Estas variables tienen coeficientes muy cercanos a cero. El modelo ha determinado que, una vez que se conoce la ubicaci√≥n, el ingreso del √°rea y las caracter√≠sticas de la vivienda, la poblaci√≥n o la ocupaci√≥n media **no aportan informaci√≥n predictiva relevante**.



Finalmente, El modelo Elastic Net ha construido una narrativa clara y l√≥gica: el valor de una propiedad est√° determinado principalmente por **la riqueza de su vecindario (`MedInc`) y su ubicaci√≥n geogr√°fica (`Latitude`, `Longitude`)**. Las caracter√≠sticas f√≠sicas como el n√∫mero de habitaciones tienen un rol secundario, y otras variables demogr√°ficas como la poblaci√≥n son consideradas irrelevantes por el modelo para esta tarea.


---

<a id='ch8'></a>

-----

## 2\. Estimaci√≥n de Percentiles con Regresi√≥n Cuant√≠lica

**Contexto:** Buscamos entender c√≥mo diferentes caracter√≠sticas demogr√°ficas afectan a las horas trabajadas por semana, no solo en promedio, sino tambi√©n en los extremos (personas que trabajan muy poco o mucho).

### 2.1 Carga de Datos Robusta y Preparaci√≥n

La construcci√≥n de flujos de trabajo de datos robustos es una pr√°ctica profesional esencial. La carga de datos desde fuentes externas (`fetch_openml`) es un punto de fallo com√∫n debido a problemas de red o de servicio. Para mitigar esto, implementamos un **mecanismo de manejo de errores** con un bloque `try-except`.

  * El bloque `try` intenta ejecutar la operaci√≥n principal: cargar el conjunto de datos "Adult" real. Dentro de este bloque, se realizan las operaciones de limpieza est√°ndar: se convierte la columna objetivo a formato num√©rico (manejando posibles errores), se eliminan columnas no predictivas y se aplica **codificaci√≥n one-hot** (`get_dummies`) a las variables categ√≥ricas para convertirlas en un formato num√©rico que el modelo pueda procesar.
  * Si cualquier `Exception` ocurre durante este proceso, la ejecuci√≥n salta al bloque `except`. Este bloque act√∫a como un **plan de contingencia**: informa al usuario del error y procede a **generar un conjunto de datos sint√©tico**. Estos datos falsos se crean de manera que tengan relaciones plausibles entre las variables, permitiendo que el resto del notebook se ejecute sin problemas para fines de demostraci√≥n y prueba de la l√≥gica del modelo.

Este enfoque garantiza que el c√≥digo sea resiliente y siempre funcional, una caracter√≠stica clave del software de calidad de producci√≥n.

Finalmente, se realiza la divisi√≥n de datos en conjuntos de entrenamiento y prueba (80/20) utilizando train_test_split para evaluar la capacidad de generalizaci√≥n del modelo en datos no vistos. Posteriormente, se aplica el escalado de caracter√≠sticas con StandardScaler a ambos conjuntos (ajustado solo con datos de entrenamiento para evitar fuga de informaci√≥n) para asegurar que todas las variables tengan una escala similar, lo cual es importante para la convergencia de algunos algoritmos de regresi√≥n cuant√≠lica.


---

```python
# Cargar el dataset 'adult' con manejo de errores
print("üìä Cargando y preparando el dataset Adult Income...")
try:
    # Intenta cargar los datos desde OpenML
    adult = fetch_openml("adult", version=2, as_frame=True, parser='auto')
    df_adult = adult.frame.copy()

    # Limpieza y preparaci√≥n de los datos reales
    y_adult = pd.to_numeric(df_adult['hours-per-week'], errors='coerce')
    X_adult = df_adult.drop(['hours-per-week', 'fnlwgt'], axis=1, errors='ignore')

    # Eliminar filas con valores nulos que puedan haber surgido
    valid_idx = y_adult.notna()
    X_adult = X_adult[valid_idx]
    y_adult = y_adult[valid_idx]

    # Codificaci√≥n de variables categ√≥ricas
    X_adult = pd.get_dummies(X_adult, drop_first=True)

    print(f"‚úÖ Dataset real cargado y preparado. Shape: {X_adult.shape}")

except Exception as e:
    # Si la carga falla, crea datos sint√©ticos como alternativa
    print(f"‚ö†Ô∏è Error al cargar el dataset real: {e}. Generando datos sint√©ticos...")
    np.random.seed(42)
    n_samples = 5000
    X_adult = pd.DataFrame({
        'age': np.random.normal(40, 12, n_samples),
        'education_years': np.random.randint(8, 20, n_samples),
        'is_married': np.random.binomial(1, 0.6, n_samples),
    })
    y_adult = (20 + 0.3 * X_adult['age'] + 1.5 * X_adult['education_years'] +
               5 * X_adult['is_married'] + np.random.normal(0, 8, n_samples))
    y_adult = np.clip(y_adult, 1, 99)
    print(f"‚úÖ Dataset sint√©tico generado. Shape: {X_adult.shape}")

# Divisi√≥n y escalado de los datos (reales o sint√©ticos)
X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(
    X_adult, y_adult, test_size=0.2, random_state=42
)
scaler_a = StandardScaler()
X_train_a_scaled = scaler_a.fit_transform(X_train_a)
X_test_a_scaled = scaler_a.transform(X_test_a)
```

```
üìä Cargando y preparando el dataset Adult Income...
‚úÖ Dataset real cargado y preparado. Shape: (48842, 96)

```


---

<a id='ch9'></a>

### 2.2 Ajuste de Modelos para M√∫ltiples Cuantiles

El n√∫cleo de la regresi√≥n cuant√≠lica reside en modelar diferentes puntos de la distribuci√≥n condicional de la variable objetivo, no solo su media. Para lograr esto, es necesario **entrenar un modelo separado para cada cuantil de inter√©s**.

El siguiente c√≥digo implementa este proceso de manera eficiente:

1.  Se define una lista de `quantiles` que deseamos modelar: 0.10 (el percentil 10, representando a quienes trabajan pocas horas), 0.50 (la mediana) y 0.90 (el percentil 90, representando a quienes trabajan muchas horas).
2.  Se itera a trav√©s de esta lista. En cada iteraci√≥n:
      * Se instancia un nuevo `QuantileRegressor`, pasando el cuantil actual `q` como par√°metro principal. El par√°metro `solver='highs'` se elige por ser un optimizador moderno y eficiente para problemas de programaci√≥n lineal. El `alpha` en este contexto es un t√©rmino de regularizaci√≥n L2 para el propio modelo cuant√≠lico.
      * El modelo se entrena con los datos de entrenamiento.
      * Se realizan predicciones y se calcula la **p√©rdida pinball (pinball loss)**. Esta es la funci√≥n de p√©rdida espec√≠fica para la regresi√≥n cuant√≠lica. Es una m√©trica asim√©trica que penaliza los errores de manera diferente dependiendo de si la predicci√≥n est√° por encima o por debajo del valor real, y esta asimetr√≠a est√° controlada por el cuantil `q`.

El resultado es un conjunto de tres modelos especializados, cada uno optimizado para predecir un segmento diferente de la distribuci√≥n de horas trabajadas.


---

```python
# Definir cuantiles y entrenar un modelo para cada uno
print("\nüîß Entrenando modelos de Regresi√≥n Cuant√≠lica para los percentiles 10, 50 y 90...")
quantiles = [0.10, 0.50, 0.90]
models_qr = {}
predictions_qr = {}
pinball_losses = {}

for q in quantiles:
    print(f"  -> Entrenando para el cuantil {q}...")
    model = QuantileRegressor(quantile=q, alpha=0.01, solver='highs')
    model.fit(X_train_a_scaled, y_train_a)

    # Almacenar modelo y predicciones
    models_qr[q] = model
    predictions_qr[q] = model.predict(X_test_a_scaled)

    # Calcular la p√©rdida pinball, m√©trica clave para regresi√≥n cuant√≠lica
    pinball_losses[q] = mean_pinball_loss(y_test_a, predictions_qr[q], alpha=q)

# Mostrar resultados en una tabla
print("\nüìà RESULTADOS DE EVALUACI√ìN (Regresi√≥n Cuant√≠lica):")
results_qr = pd.DataFrame({
    'Cuantil': [f'{q:.0%}' for q in quantiles],
    'P√©rdida Pinball': [f'{loss:.4f}' for loss in pinball_losses.values()],
    'Media de Horas Predichas': [f'{pred.mean():.2f}' for pred in predictions_qr.values()]
})
print(results_qr.to_string(index=False))
```

```

üîß Entrenando modelos de Regresi√≥n Cuant√≠lica para los percentiles 10, 50 y 90...
  -> Entrenando para el cuantil 0.1...
  -> Entrenando para el cuantil 0.5...
  -> Entrenando para el cuantil 0.9...

üìà RESULTADOS DE EVALUACI√ìN (Regresi√≥n Cuant√≠lica):
Cuantil P√©rdida Pinball Media de Horas Predichas
    10%          1.9333                    28.22
    50%          3.5896                    40.25
    90%          2.0272                    51.99

```


---

<a id='ch10'></a>

### **Interpretaci√≥n de Resultados de Regresi√≥n Cuant√≠lica**

El an√°lisis de Regresi√≥n Cuant√≠lica nos proporciona una visi√≥n mucho m√°s rica y completa que una regresi√≥n est√°ndar. En lugar de predecir √∫nicamente el valor *promedio* o *central*, hemos modelado el **rango de resultados probables** para las horas trabajadas, d√°ndonos una perspectiva sobre los escenarios de pocas horas, las horas t√≠picas y las de muchas horas (ej. con sobretiempo).

#### **Conclusi√≥n General üéØ**

Los resultados demuestran que el modelo es capaz de generar un **intervalo de predicci√≥n robusto y coherente**. Para un individuo promedio, el rango de horas trabajadas probablemente se sit√∫e entre **28 y 52 horas semanales**. Esta informaci√≥n es mucho m√°s valiosa que una √∫nica predicci√≥n puntual, ya que captura la variabilidad y la incertidumbre inherentes al problema.

---

#### **An√°lisis Detallado por Cuantil**

* **P√©rdida Pinball**: Es la m√©trica de error espec√≠fica para la Regresi√≥n Cuant√≠lica. Un valor m√°s bajo indica un mejor ajuste del modelo para ese cuantil en particular. En este caso, los modelos para los percentiles 10 y 90 parecen tener un mejor ajuste que el modelo para la mediana (percentil 50), lo que podr√≠a indicar que hay m√°s "ruido" o variabilidad en el centro de la distribuci√≥n.

A continuaci√≥n, se interpreta el significado de cada modelo:

* **Modelo del Percentil 10 (El L√≠mite Inferior o "Pocas Horas")**
    * **Media de Horas Predichas: 28.22**.
    * **Interpretaci√≥n**: Este no es un promedio, sino el umbral del 10%. Significa que, para un individuo con un conjunto de caracter√≠sticas dadas, el modelo predice que hay un **10% de probabilidad de que trabaje 28.22 horas o menos**. Este valor representa un escenario realista para un trabajo a tiempo parcial o una semana de baja carga laboral.

* **Modelo del Percentil 50 (La Mediana o "Caso T√≠pico")**
    * **Media de Horas Predichas: 40.25**.
    * **Interpretaci√≥n**: Este es el punto central de la predicci√≥n. El modelo estima que un individuo t√≠pico trabajar√° **40.25 horas**. Hay un 50% de probabilidad de que trabaje m√°s de esta cantidad y un 50% de que trabaje menos. Este valor es el equivalente a la predicci√≥n de una regresi√≥n de la mediana y representa el resultado m√°s probable.

* **Modelo del Percentil 90 (El L√≠mite Superior o "Muchas Horas")**
    * **Media de Horas Predichas: 51.99**.
    * **Interpretaci√≥n**: Este es el umbral superior. El modelo predice que hay un **90% de probabilidad de que una persona trabaje 51.99 horas o menos**. De forma inversa, esto implica que hay un **10% de probabilidad de que trabaje *m√°s* de 52 horas**. Este valor captura escenarios de alta carga laboral, incluyendo sobretiempo.

---

### **La Verdadera Ventaja: El Intervalo de Predicci√≥n**

La potencia de este an√°lisis no reside en ninguna de las predicciones individuales, sino en su conjunto. En lugar de dar una respuesta √∫nica y potencialmente enga√±osa, ahora podemos ofrecer un **intervalo de confianza del 80%** para nuestras predicciones.

> **En lugar de decir:** *"Predecimos que trabajar√°s 40 horas."*
>
> **Ahora podemos decir con mayor certeza:** *"Nuestra predicci√≥n central es de 40.25 horas, pero es muy probable que el rango real de horas que trabajes se encuentre entre **28.22 y 51.99 horas** (esto representa el 80% central de los resultados m√°s probables)."*

Esta aproximaci√≥n es inmensamente m√°s √∫til para la toma de decisiones, ya que cuantifica la incertidumbre y proporciona l√≠mites realistas (inferior y superior) para la planificaci√≥n de recursos, an√°lisis de productividad o cualquier otra aplicaci√≥n de negocio.


---

<a id='ch11'></a>

### 2.3 Visualizaci√≥n Intuitiva de las Predicciones Cuant√≠licas

El prop√≥sito de esta visualizaci√≥n es traducir el concepto abstracto de "predicci√≥n de cuantiles" en una imagen concreta e interpretable. Un simple gr√°fico de coeficientes no transmite la idea de "bandas de predicci√≥n" tan eficazmente.

La construcci√≥n del gr√°fico sigue una l√≥gica cuidadosa:

1.  **Muestreo:** Para evitar un gr√°fico sobrecargado e ilegible, en lugar de graficar todo el conjunto de prueba, seleccionamos una **muestra aleatoria** de 200 puntos.
2.  **Ordenamiento:** Para darle una estructura visual coherente al gr√°fico, los puntos de la muestra se **ordenan seg√∫n su valor real** (`y_test`). Esto hace que los valores reales formen una curva ascendente, facilitando la comparaci√≥n con las predicciones.
3.  **Representaci√≥n Gr√°fica:**
      * Los valores reales de la muestra se grafican como puntos negros, formando la "verdad fundamental" que intentamos modelar.
      * Para cada uno de estos puntos, se grafican las predicciones de los tres modelos cuant√≠licos, cada uno con un color distintivo.

El resultado esperado es una clara demostraci√≥n visual del comportamiento del modelo: las predicciones del cuantil 0.10 deber√≠an formar una "banda inferior" a los datos reales, las del cuantil 0.50 deber√≠an pasar por el centro de la nube de puntos, y las del cuantil 0.90 deber√≠an formar una "banda superior". Esto ilustra de manera efectiva c√≥mo la regresi√≥n cuant√≠lica captura el rango y la dispersi√≥n de los datos, no solo su tendencia central.


---

```python
# Tomar una muestra aleatoria de 200 puntos del conjunto de prueba para visualizar
sample_idx = np.random.choice(len(y_test_a), 200, replace=False)
x_pos = np.arange(len(sample_idx))

# Ordenar los puntos por el valor real para una visualizaci√≥n m√°s clara
sorted_indices = y_test_a.iloc[sample_idx].sort_values().index
sample_idx = np.where(y_test_a.index.isin(sorted_indices))[0]
x_pos = np.arange(len(sample_idx))

# Crear el gr√°fico
plt.figure(figsize=(15, 7))
# Graficar los valores reales como puntos negros
plt.scatter(x_pos, y_test_a.iloc[sample_idx], color='black', s=30, alpha=0.6, label='Valores Reales (Muestra)')

# Graficar las predicciones de cada cuantil
colors = ['red', 'blue', 'green']
for i, q in enumerate(quantiles):
    plt.scatter(x_pos, predictions_qr[q][sample_idx], alpha=0.7,
                s=20, color=colors[i], label=f'Predicci√≥n Cuantil {q:.0%}')

plt.xlabel('Muestras del Conjunto de Prueba (ordenadas por valor real)')
plt.ylabel('Horas Trabajadas por Semana')
plt.title('Comparaci√≥n Visual: Predicciones Cuant√≠licas vs. Valores Reales')
plt.legend()
plt.grid(alpha=0.4)
plt.tight_layout()
plt.show()
```

![Generated Image](image_placeholder.png)


---

<a id='ch12'></a>

### **Interpretaci√≥n de la Visualizaci√≥n de Predicciones Cuant√≠licas**

Esta gr√°fica es una de las formas m√°s efectivas de validar y comprender el rendimiento de los modelos de Regresi√≥n Cuant√≠lica. No solo nos muestra el error, sino que nos permite visualizar si el modelo ha aprendido correctamente la **distribuci√≥n de los datos** y la **incertidumbre de sus propias predicciones**.

#### **Conclusi√≥n General üéØ**

La visualizaci√≥n confirma de manera contundente el √©xito del enfoque de Regresi√≥n Cuant√≠lica. Los modelos han logrado crear un **"canal" o "intervalo de predicci√≥n"** que se ajusta y envuelve adecuadamente a los valores reales. Esto demuestra que el sistema no solo predice un valor central, sino que tambi√©n estima de forma realista los l√≠mites inferior y superior de los resultados probables.

---

#### **An√°lisis Detallado de la Gr√°fica**

Para interpretar correctamente la gr√°fica, es clave entender sus componentes:

* **Eje X**: No representa una variable, sino una muestra de 200 individuos del conjunto de prueba, **ordenados por su valor real de horas trabajadas**. Esto crea la tendencia ascendente de los puntos negros y facilita la evaluaci√≥n visual.
* **Puntos Negros (Valores Reales)**: Son la "verdad fundamental". Representan las horas que cada individuo en la muestra realmente trabaj√≥.
* **Puntos de Colores (Predicciones)**: Para cada punto negro, el modelo genera tres predicciones:
    * üî¥ **Rojo (Percentil 10)**: La predicci√≥n del l√≠mite inferior.
    * üîµ **Azul (Percentil 50)**: La predicci√≥n central o mediana.
    * üü¢ **Verde (Percentil 90)**: La predicci√≥n del l√≠mite superior.

#### **Observaciones Clave**

1.  **El "Canal de Predicci√≥n" es Exitoso**: Se puede observar claramente c√≥mo la banda formada por los puntos rojos (l√≠mite inferior) y verdes (l√≠mite superior) **envuelve a la gran mayor√≠a de los puntos negros (valores reales)**. Esto es exactamente lo que se espera de un modelo de regresi√≥n cuant√≠lica bien calibrado. El modelo est√° diciendo: "No s√© exactamente cu√°ntas horas trabajar√°s, pero estoy 80% seguro de que ser√° entre el valor rojo y el verde", y la gr√°fica demuestra que esta afirmaci√≥n es mayormente correcta.

2.  **Seguimiento de la Tendencia Central**: La l√≠nea de puntos azules (predicci√≥n de la mediana) sigue de cerca el centro de la nube de puntos negros. Esto indica que la predicci√≥n del "caso t√≠pico" del modelo es acertada y se alinea con los valores reales m√°s comunes.

3.  **Cuantificaci√≥n de la Incertidumbre**: La distancia vertical entre los puntos rojos y verdes para cualquier individuo en el eje X representa la **incertidumbre del modelo** para esa predicci√≥n. Se puede notar que esta banda no tiene un ancho constante:
    * Para valores m√°s bajos y m√°s altos de horas trabajadas (los extremos del gr√°fico), la banda parece ensancharse. Esto se conoce como **heterocedasticidad** y es un hallazgo importante: el modelo es **m√°s inseguro en sus predicciones para personas que trabajan muy pocas o muchas horas**, lo cual es intuitivo, ya que estos casos suelen tener m√°s variabilidad.

Finalmente, Esta gr√°fica va m√°s all√° de simples m√©tricas de error y proporciona una **prueba visual y convincente** de que el modelo funciona como se esperaba. Confirma que el sistema no solo ofrece una predicci√≥n, sino que tambi√©n **comprende y comunica su propio nivel de incertidumbre**, proporcionando un rango de resultados probables que es mucho m√°s informativo y fiable para la toma de decisiones que una √∫nica predicci√≥n puntual.


---

<a id='ch13'></a>

-----

## 3\. Proyecci√≥n de Indicadores Econ√≥micos con VAR

**Contexto:** Se busca predecir simult√°neamente el PIB, el consumo y la inversi√≥n. Un modelo VAR es ideal porque trata estas variables como un sistema interconectado.

### 3.1 Carga, Preparaci√≥n y Test de Estacionariedad

El modelado de series de tiempo con VAR tiene un prerrequisito estad√≠stico fundamental: la **estacionariedad**. Una serie de tiempo es estacionaria si sus propiedades estad√≠sticas (como la media y la varianza) son constantes en el tiempo. Las series macroecon√≥micas, como el PIB, suelen mostrar tendencias crecientes, lo que las hace no estacionarias.

El procedimiento en la siguiente celda es riguroso:

1.  **Carga y Preparaci√≥n:** Se cargan los datos y se establece un √≠ndice de tiempo expl√≠cito para asegurar que `statsmodels` interprete correctamente la naturaleza temporal de los datos.
2.  **Test de Estacionariedad:** Se aplica el **Test de Dickey-Fuller Aumentado (ADF)** a cada serie. Este es un test de hip√≥tesis donde la hip√≥tesis nula ($H\_0$) es que la serie posee una ra√≠z unitaria (es decir, no es estacionaria). Buscamos un **p-valor inferior a un umbral de significancia (ej. 0.05)** para rechazar $H\_0$ y concluir que la serie es estacionaria.
3.  **Transformaci√≥n:** Como los resultados del test confirmar√°n que las series originales no son estacionarias, aplicamos una transformaci√≥n com√∫n para inducir estacionariedad: la **primera diferenciaci√≥n**. En lugar de modelar los valores absolutos (ej. el PIB), modelaremos el cambio en el valor de un trimestre al siguiente (`PIB_t - PIB_{t-1}`).
4.  **Verificaci√≥n:** Se vuelve a aplicar el test ADF a las series diferenciadas para confirmar que la transformaci√≥n ha sido exitosa y que los datos est√°n ahora listos para ser modelados con VAR.

<!-- end list -->


---

```python
# Cargar el dataset macroecon√≥mico de statsmodels
print("üìä Cargando y preparando datos macroecon√≥micos...")
df_macro = macrodata.load_pandas().data
variables = ['realgdp', 'realcons', 'realinv']
df_var = df_macro[variables].copy()

# Crear un √≠ndice de fecha adecuado
df_var.index = pd.to_datetime(df_macro['year'].astype(int).astype(str) + 'Q' + df_macro['quarter'].astype(int).astype(str))

# --- Test de Estacionariedad (Augmented Dickey-Fuller) ---
print("\nüî¨ Analizando estacionariedad de las series...")
adf_results = []
for name, series in df_var.items():
    result = adfuller(series)
    adf_results.append({'Serie': name, 'p-valor': result[1], 'Estacionaria': result[1] < 0.05})

adf_df = pd.DataFrame(adf_results)
print("Resultados del test en datos originales:")
print(adf_df.to_string(index=False))

# Aplicar diferenciaci√≥n ya que las series originales no son estacionarias
df_var_diff = df_var.diff().dropna()
print("\n-> Las series no son estacionarias. Aplicando diferenciaci√≥n...")

# Verificar estacionariedad en los datos diferenciados
adf_results_diff = []
for name, series in df_var_diff.items():
    result = adfuller(series)
    adf_results_diff.append({'Serie': name, 'p-valor': result[1]})

print("\nResultados del test en datos diferenciados (p-valor < 0.05 indica estacionariedad):")
print(pd.DataFrame(adf_results_diff).to_string(index=False))
```

```
üìä Cargando y preparando datos macroecon√≥micos...

üî¨ Analizando estacionariedad de las series...
Resultados del test en datos originales:
   Serie  p-valor  Estacionaria
 realgdp 0.998246         False
realcons 0.997699         False
 realinv 0.648496         False

-> Las series no son estacionarias. Aplicando diferenciaci√≥n...

Resultados del test en datos diferenciados (p-valor < 0.05 indica estacionariedad):
   Serie      p-valor
 realgdp 3.327882e-08
realcons 6.479282e-04
 realinv 4.297933e-06

```


---

<a id='ch14'></a>

### **Interpretaci√≥n del An√°lisis de Estacionariedad**

El an√°lisis realizado es un paso **fundamental y obligatorio** en la preparaci√≥n de datos para la modelizaci√≥n de series de tiempo, especialmente para modelos como los Vectores Autorregresivos (VAR). El objetivo es verificar si las series son **estacionarias**, una condici√≥n necesaria para garantizar que los resultados del modelo sean fiables y no espurios.

#### **Conclusi√≥n General üéØ**

El an√°lisis confirma que las series macroecon√≥micas originales (`realgdp`, `realcons`, `realinv`) **son no estacionarias**, como es t√≠pico en datos econ√≥micos que presentan tendencias a lo largo del tiempo. Sin embargo, tras aplicar una **diferenciaci√≥n de primer orden**, las tres series se transforman exitosamente en **series estacionarias**, dej√°ndolas listas para ser utilizadas en la siguiente etapa de modelizaci√≥n.

---

#### **An√°lisis Detallado de los Resultados del Test de Dickey-Fuller Aumentado (ADF)**

El Test ADF eval√∫a la siguiente hip√≥tesis:
* **Hip√≥tesis Nula (H‚ÇÄ)**: La serie tiene una ra√≠z unitaria (es **no estacionaria**).
* **Hip√≥tesis Alternativa (H‚ÇÅ)**: La serie no tiene ra√≠z unitaria (es **estacionaria**).

La regla de decisi√≥n se basa en el **p-valor**: si es inferior a un nivel de significancia (com√∫nmente 0.05), rechazamos la hip√≥tesis nula.

#### **1. Resultados de las Series Originales**

| Serie    | p-valor | Conclusi√≥n (si p > 0.05) |
| :------- | :------ | :----------------------- |
| `realgdp`  | 0.998   | **No Estacionaria** |
| `realcons` | 0.998   | **No Estacionaria** |
| `realinv`  | 0.648   | **No Estacionaria** |

* **Interpretaci√≥n**: Los p-valores para las tres series son muy altos (cercanos a 1.0 en dos casos), muy por encima del umbral de 0.05. Esto significa que **no tenemos evidencia para rechazar la hip√≥tesis nula**. Estad√≠sticamente, concluimos que las series del PIB real, consumo real e inversi√≥n real en sus niveles originales son no estacionarias.
* **Implicaci√≥n Pr√°ctica**: Las series poseen una **tendencia temporal** (probablemente de crecimiento). Modelarlas directamente conducir√≠a a resultados enga√±osos, como encontrar relaciones falsas entre variables que simplemente est√°n creciendo simult√°neamente por razones externas (una "regresi√≥n espuria").

#### **2. Resultados de las Series Diferenciadas**

Para solucionar la no estacionariedad, se aplic√≥ una **diferenciaci√≥n**. En lugar de trabajar con los niveles (ej. el valor total del PIB), ahora trabajamos con los **cambios o crecimientos de un trimestre al siguiente**.

| Serie    | p-valor    | Conclusi√≥n (si p < 0.05) |
| :------- | :--------- | :----------------------- |
| `realgdp`  | `3.3e-08`  | **Estacionaria** |
| `realcons` | `6.4e-04`  | **Estacionaria** |
| `realinv`  | `4.2e-06`  | **Estacionaria** |

* **Interpretaci√≥n**: Los p-valores para las tres series diferenciadas son extremadamente peque√±os (mucho menores que 0.05). En este caso, **rechazamos con un alto grado de confianza la hip√≥tesis nula**. La conclusi√≥n es que las series que representan el *cambio trimestral* del PIB, consumo e inversi√≥n **son estacionarias**.
* **Implicaci√≥n Pr√°ctica**: Al haber eliminado la tendencia, las series transformadas ahora tienen propiedades estad√≠sticas constantes en el tiempo. Esto cumple con el supuesto fundamental para la modelizaci√≥n y nos permite proceder a construir un modelo VAR (o similar) para analizar las interdependencias din√°micas entre estas tres variables econ√≥micas de manera robusta y estad√≠sticamente v√°lida.


---

<a id='ch15'></a>

### 3.2 Divisi√≥n Train/Test y Selecci√≥n de Lags

Una vez que tenemos datos estacionarios, procedemos a preparar el modelado. Este proceso se divide en dos pasos l√≥gicos y metodol√≥gicamente cruciales:

1.  **Divisi√≥n de Datos Cronol√≥gica:** A diferencia de los datos tabulares, las series de tiempo tienen un orden inherente que debe ser preservado. Por lo tanto, no podemos hacer una divisi√≥n aleatoria. Realizamos una **divisi√≥n cronol√≥gica**: los primeros 80% de las observaciones constituir√°n el conjunto de **entrenamiento**, y el 20% final se reservar√° como conjunto de **prueba**. Esto simula un escenario realista donde usamos el pasado para predecir el futuro.
2.  **Selecci√≥n del Orden de Lag:** El "orden de lag" es el hiperpar√°metro m√°s importante de un modelo VAR. Define cu√°ntos per√≠odos pasados de cada variable se incluir√°n en las ecuaciones de predicci√≥n. Un lag demasiado bajo puede no capturar la din√°mica completa del sistema, mientras que un lag demasiado alto puede llevar a sobreajuste. Para tomar una decisi√≥n basada en datos, utilizamos la funci√≥n `select_order`. Esta herramienta ajusta modelos VAR con diferentes n√∫meros de lags y calcula varios **criterios de informaci√≥n**. Estos criterios, como el **AIC (Akaike Information Criterion)**, equilibran el ajuste del modelo con su complejidad, penalizando los modelos con demasiados par√°metros. Seleccionamos el n√∫mero de lags que minimiza el AIC, obteniendo as√≠ un modelo parsimonioso y efectivo. Este proceso se realiza **exclusivamente sobre el conjunto de entrenamiento** para evitar cualquier fuga de informaci√≥n del futuro.

<!-- end list -->


---

```python
# Dividir los datos diferenciados en entrenamiento (80%) y prueba (20%)
train_size = int(len(df_var_diff) * 0.8)
train_data, test_data = df_var_diff.iloc[:train_size], df_var_diff.iloc[train_size:]
print(f"\nüîß Datos divididos: {len(train_data)} obs. para entrenamiento, {len(test_data)} obs. para prueba.")

# Seleccionar el orden de lag √≥ptimo USANDO SOLO DATOS DE ENTRENAMIENTO
print("\nüéØ Seleccionando n√∫mero √≥ptimo de lags usando criterio AIC...")
model_for_lags = VAR(train_data)
lag_order_selection = model_for_lags.select_order(maxlags=10)
optimal_lags = lag_order_selection.aic
print(f"‚úÖ Lags √≥ptimos seleccionados (AIC): {optimal_lags}")
```

```

üîß Datos divididos: 161 obs. para entrenamiento, 41 obs. para prueba.

üéØ Seleccionando n√∫mero √≥ptimo de lags usando criterio AIC...
‚úÖ Lags √≥ptimos seleccionados (AIC): 3

```


---

<a id='ch16'></a>

### **Interpretaci√≥n de la Selecci√≥n de Lags del Modelo VAR**

Este procedimiento es un paso metodol√≥gico crucial en la construcci√≥n de un modelo VAR (Vector Autorregresivo). Su objetivo es determinar la **"memoria" √≥ptima del sistema**, es decir, cu√°ntos per√≠odos pasados (lags) se deben incluir en el modelo para capturar adecuadamente la din√°mica entre las variables sin caer en un exceso de complejidad.

#### **Conclusi√≥n General üéØ**

El an√°lisis concluye que un **orden de lag de 3 es el √≥ptimo** para modelar las interrelaciones entre el crecimiento del PIB, el consumo y la inversi√≥n. Esto implica que el estado de la econom√≠a en un trimestre determinado est√° significativamente influenciado por el comportamiento de estas variables en los **tres trimestrales anteriores**.

---

#### **An√°lisis Detallado del Proceso y Resultados**

1.  **Divisi√≥n de Datos (Paso Metodol√≥gico Clave)**:
    * **Acci√≥n**: Los datos se dividieron en un conjunto de entrenamiento (161 observaciones) y uno de prueba (41 observaciones).
    * **Importancia**: Es fundamental realizar la selecci√≥n de lags **√∫nicamente con los datos de entrenamiento**. Esta pr√°ctica previene el "data leakage" (fuga de datos), asegurando que la estructura del modelo se decida sin tener conocimiento previo de los datos que se usar√°n para evaluarlo, lo que garantiza una evaluaci√≥n final imparcial.

2.  **El Significado del "Lag Order"**:
    * Un "lag" es simplemente un valor pasado de una serie. Un modelo VAR(p) con `p` lags predice el valor actual de cada variable bas√°ndose en los `p` valores anteriores de s√≠ misma y de todas las dem√°s variables del sistema.
    * La elecci√≥n de `p` es un **trade-off cr√≠tico**:
        * **Pocos lags**: El modelo puede ser demasiado simple y no capturar toda la din√°mica econ√≥mica (subajuste o "underfitting").
        * **Demasiados lags**: El modelo puede volverse excesivamente complejo, comenzando a modelar ruido aleatorio en lugar de la se√±al econ√≥mica real (sobreajuste o "overfitting"), lo que perjudica su capacidad de pron√≥stico.

3.  **Selecci√≥n √ìptima por Criterio AIC**:
    * **Resultado**: `Lags √≥ptimos seleccionados (AIC): 3`
    * **Interpretaci√≥n**: El Criterio de Informaci√≥n de Akaike (AIC) es una medida estad√≠stica que equilibra la bondad de ajuste del modelo con su complejidad. Al seleccionar 3 lags, el AIC indica que este es el punto √≥ptimo donde el modelo **captura la m√°xima cantidad de informaci√≥n √∫til con la menor complejidad posible**.
    * **Implicaci√≥n Pr√°ctica**: El resultado sugiere que los cambios en el PIB, consumo e inversi√≥n de hace un a√±o (lag 4), por ejemplo, ya no aportan informaci√≥n predictiva valiosa una vez que se conocen los datos de los √∫ltimos tres trimestres. Toda la "memoria" relevante del sistema est√° contenida en ese horizonte de tres per√≠odos.

---

### **Siguientes Pasos**

Con esta especificaci√≥n (`p=3`), el siguiente paso es construir y entrenar el modelo **VAR(3)** final utilizando el conjunto de entrenamiento. Posteriormente, se usar√° este modelo para realizar pron√≥sticos y se evaluar√° su rendimiento comparando esas predicciones con los datos reales del conjunto de prueba. La selecci√≥n rigurosa del orden de lag es la base que nos da confianza en la estructura del modelo que se va a evaluar.


---

<a id='ch17'></a>

### 3.3 Entrenamiento, Pron√≥stico y Evaluaci√≥n Cuantitativa

Esta celda ejecuta la secuencia central del modelado VAR y su evaluaci√≥n cuantitativa:

1.  **Entrenamiento (Ajuste):** Se instancia un nuevo objeto `VAR` con los datos de entrenamiento. Luego, se invoca el m√©todo `.fit()`, pas√°ndole el `optimal_lags` determinado en el paso anterior. En este punto, el algoritmo estima los coeficientes de las ecuaciones del VAR que mejor describen las interrelaciones din√°micas entre las series en el conjunto de entrenamiento.
2.  **Pron√≥stico (Predicci√≥n):** Se utiliza el modelo ya entrenado (`var_results`) para generar un pron√≥stico "fuera de muestra". El m√©todo `.forecast()` requiere dos argumentos clave: los **valores iniciales** (los √∫ltimos `optimal_lags` puntos del conjunto de entrenamiento) y el **horizonte de predicci√≥n** (`steps`), que establecemos para que coincida con la longitud de nuestro conjunto de prueba. El resultado es una predicci√≥n para los mismos per√≠odos de tiempo que tenemos en `test_data`.
3.  **Evaluaci√≥n Cuantitativa:** Este es el momento de la verdad. Comparamos directamente las predicciones (`forecast_df_diff`) con los valores reales y retenidos (`test_data`) para cada una de las series. Calculamos las m√©tricas **RMSE** y **MAE** para cada variable. Esto nos proporciona una medida objetiva y num√©rica de la precisi√≥n del pron√≥stico del modelo en datos que no se utilizaron durante el entrenamiento.

<!-- end list -->


---

```python
# Entrenar el modelo VAR con el n√∫mero √≥ptimo de lags
print(f"\nüöÄ Entrenando modelo VAR con {optimal_lags} lags...")
var_model = VAR(train_data)
var_results = var_model.fit(optimal_lags)

# Realizar un pron√≥stico para el mismo n√∫mero de per√≠odos que el conjunto de prueba
n_forecast = len(test_data)
print(f"-> Realizando pron√≥stico para {n_forecast} per√≠odos...")

# Usar los √∫ltimos 'lags' valores del entrenamiento como punto de partida para el pron√≥stico
lagged_values = train_data.values[-optimal_lags:]
forecast_diff = var_results.forecast(y=lagged_values, steps=n_forecast)
forecast_df_diff = pd.DataFrame(forecast_diff, index=test_data.index, columns=test_data.columns)

# Evaluar cuantitativamente el pron√≥stico contra los datos de prueba
print("\nüìà RESULTADOS DE EVALUACI√ìN (Modelo VAR sobre datos diferenciados):")
var_metrics = []
for var in variables:
    rmse = np.sqrt(mean_squared_error(test_data[var], forecast_df_diff[var]))
    mae = mean_absolute_error(test_data[var], forecast_df_diff[var])
    var_metrics.append({'Variable': var, 'RMSE': f'{rmse:.2f}', 'MAE': f'{mae:.2f}'})

print(pd.DataFrame(var_metrics).to_string(index=False))
```

```

üöÄ Entrenando modelo VAR con 3 lags...
-> Realizando pron√≥stico para 41 per√≠odos...

üìà RESULTADOS DE EVALUACI√ìN (Modelo VAR sobre datos diferenciados):
Variable  RMSE   MAE
 realgdp 83.48 59.54
realcons 41.56 31.22
 realinv 74.86 51.65

```


---

<a id='ch18'></a>

### **Interpretaci√≥n de la Evaluaci√≥n del Modelo VAR(3)**

Esta evaluaci√≥n mide la precisi√≥n del modelo VAR(3) al pronosticar los **cambios trimestrales** de las variables macroecon√≥micas (`realgdp`, `realcons`, `realinv`) en un per√≠odo de 41 trimestres (m√°s de 10 a√±os), que el modelo no hab√≠a visto previamente. Los resultados nos indican qu√© tan bien el modelo puede anticipar la din√°mica de crecimiento de la econom√≠a a corto plazo.

#### **Conclusi√≥n General üéØ**

El modelo VAR(3) demuestra un **rendimiento de pron√≥stico variable**, logrando una precisi√≥n considerablemente mayor para predecir los cambios en el consumo real (`realcons`) que para los cambios en el PIB (`realgdp`) y la inversi√≥n (`realinv`). Los resultados son coherentes con la teor√≠a econ√≥mica, que postula que el consumo es el componente m√°s estable del PIB, mientras que la inversi√≥n es el m√°s vol√°til.

---

#### **An√°lisis Detallado por M√©trica y Variable**

Las m√©tricas utilizadas son:
* **MAE (Error Absoluto Medio)**: El error promedio del pron√≥stico, en las unidades de la variable (probablemente miles de millones de d√≥lares). Nos da una idea del error t√≠pico que podemos esperar.
* **RMSE (Ra√≠z del Error Cuadr√°tico Medio)**: Similar al MAE, pero penaliza m√°s los errores grandes. Una gran diferencia entre RMSE y MAE sugiere que el modelo comete algunos errores de pron√≥stico ocasionales pero de gran magnitud.

---

#### **Desglose del Rendimiento**

* **`realcons` (Consumo Real) - El Pron√≥stico M√°s Fiable ‚úÖ**
    * **Resultados**: MAE de **31.22** y RMSE de **41.56**.
    * **Interpretaci√≥n**: El modelo es m√°s exitoso aqu√≠. En promedio, su pron√≥stico del cambio trimestral en el consumo se desv√≠a en unos 31.22 mil millones de d√≥lares. Econ√≥micamente, esto es l√≥gico. El consumo tiende a ser impulsado por h√°bitos y patrones estables, lo que lo convierte en la variable m√°s "suave" y predecible del sistema.

* **`realinv` (Inversi√≥n Real) - Alta Volatilidad y Error ‚ö†Ô∏è**
    * **Resultados**: MAE de **51.65** y RMSE de **74.86**.
    * **Interpretaci√≥n**: El error de pron√≥stico para la inversi√≥n es significativamente mayor que para el consumo. Esto es un resultado esperado, ya que la inversi√≥n es el componente m√°s vol√°til del PIB. Es altamente sensible a cambios en las tasas de inter√©s, la confianza empresarial y los ciclos econ√≥micos, lo que la hace intr√≠nsecamente dif√≠cil de predecir a corto plazo.

* **`realgdp` (PIB Real) - Rendimiento Agregado üìâ**
    * **Resultados**: MAE de **59.54** y RMSE de **83.48**.
    * **Interpretaci√≥n**: El PIB real presenta el mayor error de pron√≥stico. Como el PIB es la suma de varios componentes (incluyendo la vol√°til inversi√≥n), hereda esa dificultad predictiva. El pron√≥stico del crecimiento econ√≥mico general es, en promedio, err√≥neo por casi 60 mil millones de d√≥lares por trimestre. La notable diferencia entre su RMSE (83.48) y MAE (59.54) sugiere que los pron√≥sticos del PIB, en particular, sufren de errores ocasionales de gran magnitud, probablemente durante per√≠odos de recesi√≥n o expansi√≥n r√°pida que el modelo no anticipa bien.

Como vemos, el modelo VAR(3) sirve como un **s√≥lido punto de partida (baseline)**, capturando correctamente que el consumo es m√°s f√°cil de predecir que la inversi√≥n. Sin embargo, los errores, especialmente para `realgdp` y `realinv`, indican que hay un margen considerable para mejorar.

Para incrementar la precisi√≥n, se podr√≠an explorar los siguientes pasos:
* **Modelos VARX**: Incluir variables ex√≥genas (como tasas de inter√©s o precios del petr√≥leo) que puedan ayudar a explicar la varianza.
* **Horizontes de Pron√≥stico**: Evaluar si el modelo es m√°s preciso para pron√≥sticos a muy corto plazo (1-2 trimestres) en lugar de los 41 trimestres completos.
* **Modelos No Lineales**: Investigar modelos que puedan capturar cambios de r√©gimen o efectos no lineales (ej. modelos de Markov-switching) que son comunes en datos macroecon√≥micos.


---

<a id='ch19'></a>

### 3.4 Visualizaci√≥n del Pron√≥stico e Interpretaci√≥n Final

La comunicaci√≥n de los resultados de un modelo de series de tiempo se realiza de manera m√°s efectiva a trav√©s de la visualizaci√≥n. Aqu√≠, adoptamos una estrategia de dos pasos para satisfacer tanto al analista t√©cnico como al p√∫blico de negocio:

1.  **Gr√°fico de Diagn√≥stico (Escala Diferenciada):** El primer conjunto de gr√°ficos est√° dirigido al modelador. Compara tres series para cada variable: el historial de entrenamiento, los valores reales del conjunto de prueba y las predicciones del modelo. Todo esto se muestra en la **escala diferenciada** (escala de "cambios"). Este gr√°fico es fundamental para diagnosticar el rendimiento del modelo: ¬øcaptura la volatilidad?, ¬øsigue la direcci√≥n correcta de los cambios?, ¬øhay sesgos evidentes?
2.  **Gr√°fico de Interpretaci√≥n (Escala Original):** El segundo conjunto de gr√°ficos es para la interpretaci√≥n final y la comunicaci√≥n a los stakeholders. Los pron√≥sticos de "cambios" son poco intuitivos. Por lo tanto, realizamos una **transformaci√≥n inversa** para convertir los cambios pronosticados de nuevo a los niveles originales de las series. La l√≥gica es simple: el valor pronosticado en el tiempo `t` es el valor real en `t-1` m√°s el cambio pronosticado para `t`. Este proceso se realiza de forma acumulativa. El gr√°fico resultante muestra el historial y el pron√≥stico en sus unidades originales (ej. miles de millones de d√≥lares), permitiendo una interpretaci√≥n directa y √∫til para la toma de decisiones.

<!-- end list -->


---

```python
# Visualizaci√≥n del pron√≥stico vs. valores reales (en escala diferenciada)
fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)
for i, var in enumerate(variables):
    train_data[var].iloc[-50:].plot(ax=axes[i], label='Entrenamiento', legend=True)
    test_data[var].plot(ax=axes[i], label='Real (Prueba)', legend=True, style='--')
    forecast_df_diff[var].plot(ax=axes[i], label='Pron√≥stico VAR', legend=True, style=':')
    axes[i].set_title(f'Pron√≥stico vs. Real para {var.upper()} (Datos Diferenciados)')
    axes[i].grid(alpha=0.4)

plt.suptitle('Evaluaci√≥n del Pron√≥stico VAR', fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# --- Revertir la diferenciaci√≥n para interpretaci√≥n ---
print("\nüîÑ Revertiendo la diferenciaci√≥n para obtener el pron√≥stico en la escala original...")
forecast_original_scale = forecast_df_diff.copy()
for col in variables:
    # El valor pronosticado es el √∫ltimo valor real conocido + el cambio acumulado pronosticado
    last_known_value = df_var[col].iloc[train_size - 1]
    forecast_original_scale[col] = last_known_value + forecast_df_diff[col].cumsum()

# --- Visualizaci√≥n Final para Interpretaci√≥n de Negocio ---
fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)
for i, var in enumerate(variables):
    df_var[var].iloc[-50:].plot(ax=axes[i], label='Hist√≥rico', legend=True)
    forecast_original_scale[var].plot(ax=axes[i], label='Pron√≥stico Final', legend=True, style='--')
    axes[i].set_title(f'Pron√≥stico Final para {var.upper()} (Escala Original)')
    axes[i].grid(alpha=0.4)

plt.suptitle('Pron√≥stico Final del Modelo VAR', fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
```

![Generated Image](image_placeholder.png)

```

üîÑ Revertiendo la diferenciaci√≥n para obtener el pron√≥stico en la escala original...

```

![Generated Image](image_placeholder.png)


---

<a id='ch20'></a>

### **Interpretaci√≥n de los Pron√≥sticos del Modelo VAR**

Estas dos series de gr√°ficos nos ofrecen dos perspectivas complementarias y cruciales sobre el rendimiento del modelo VAR: una **evaluaci√≥n t√©cnica** de su capacidad para predecir la din√°mica de corto plazo y una **visualizaci√≥n de negocio** de su pron√≥stico a largo plazo.

#### **Conclusi√≥n General üéØ**

El modelo VAR(3) ha demostrado ser eficaz para capturar y proyectar la **tendencia de crecimiento promedio a largo plazo** de las variables econ√≥micas. Sin embargo, presenta una debilidad cr√≠tica: **falla por completo en predecir la volatilidad y los ciclos econ√≥micos de corto y mediano plazo**. El pron√≥stico resultante es excesivamente optimista y suave, ignorando las fluctuaciones y los puntos de inflexi√≥n que caracterizan a una econom√≠a real.

---

### 1. An√°lisis T√©cnico: Evaluaci√≥n del Pron√≥stico (Datos Diferenciados)


Esta primera gr√°fica es un diagn√≥stico t√©cnico. Compara el **cambio trimestral** pronosticado por el modelo (l√≠nea de puntos verde) con el cambio trimestral que realmente ocurri√≥ (l√≠nea discontinua marr√≥n).

* **Observaci√≥n Clave**: En los tres gr√°ficos, la l√≠nea del pron√≥stico (verde) es notablemente **m√°s plana y menos vol√°til** que la l√≠nea de los datos reales (marr√≥n).

* **Interpretaci√≥n**:
    * **Subestimaci√≥n de la Volatilidad**: El modelo VAR es un modelo lineal y, como tal, tiende a promediar el comportamiento pasado. Ha aprendido la "tasa de cambio promedio" pero es incapaz de anticipar los picos y valles (shocks) que ocurren en la realidad.
    * **Peor Rendimiento en `realinv`**: El fracaso es m√°s dram√°tico para la inversi√≥n (`realinv`). Mientras que los datos reales muestran enormes oscilaciones, el pron√≥stico del modelo es casi una l√≠nea recta. Esto confirma que el modelo no tiene capacidad para predecir la naturaleza err√°tica de la inversi√≥n empresarial.
    * **Conclusi√≥n T√©cnica**: El modelo no captura la **heterocedasticidad** (volatilidad cambiante) de las series. Sirve para entender la direcci√≥n general del crecimiento, pero no su ritmo ni sus sobresaltos.

---

### 2. An√°lisis de Negocio: Pron√≥stico Final (Escala Original)


Esta segunda gr√°fica es la m√°s importante para la toma de decisiones, ya que muestra la trayectoria proyectada de las variables en sus niveles originales (ej. miles de millones de d√≥lares).

* **Observaci√≥n Clave**: Las l√≠neas de pron√≥stico (discontinuas) proyectan un **crecimiento suave, casi lineal y constante** para las tres variables.

* **Interpretaci√≥n y Consecuencias**:
    * **Fortaleza (Limitada)**: El modelo es √∫til para visualizar una **l√≠nea de base o tendencia central a largo plazo**. Si la econom√≠a creciera siempre a su ritmo promedio hist√≥rico, se parecer√≠a a este pron√≥stico.
    * **Debilidad Cr√≠tica**: El modelo es **completamente ciego a los ciclos econ√≥micos**. No predice recesiones, desaceleraciones ni recuperaciones aceleradas. Esto es especialmente peligroso en el gr√°fico de `realinv`, donde el modelo proyecta un crecimiento estable justo cuando los datos hist√≥ricos muestran el inicio de una fuerte ca√≠da.
    * **Riesgo para el Negocio**: Utilizar este pron√≥stico para decisiones t√°cticas (ej. planificaci√≥n de inventarios para los pr√≥ximos dos a√±os, decisiones de contrataci√≥n, o estrategias de inversi√≥n) ser√≠a **extremadamente arriesgado**. Un directivo que se base en este gr√°fico concluir√≠a que la econom√≠a se expandir√° sin problemas, cuando en realidad podr√≠a estar al borde de una recesi√≥n.

---

### **Recomendaci√≥n Final**

El modelo VAR(3), en su forma actual, debe ser utilizado con extrema precauci√≥n. Es adecuado como una herramienta para **ilustrar la tendencia hist√≥rica promedio**, pero **no debe ser utilizado como una herramienta de pron√≥stico predictivo** para el mediano plazo.

Para obtener pron√≥sticos m√°s realistas, ser√≠a necesario explorar modelos m√°s sofisticados que puedan capturar la no linealidad y la volatilidad de los ciclos econ√≥micos, tales como:
* **Modelos VAR Estructurales (SVAR)** que incorporen supuestos econ√≥micos.
* **Modelos con Cambio de R√©gimen (Markov-Switching)**.
* **Modelos de Machine Learning m√°s avanzados** (como redes neuronales LSTM) si se dispone de suficientes datos.


---

<a id='ch21'></a>

-----

## 4\. Resumen Comparativo y Conclusiones

### 4.1 Tabla Resumen de Resultados

Esta secci√≥n consolida los resultados clave de los tres an√°lisis distintos en una √∫nica tabla estructurada. El uso de un DataFrame de `pandas` permite una presentaci√≥n clara y ordenada, facilitando la comparaci√≥n directa entre las diferentes t√©cnicas y sus m√©tricas de rendimiento. La tabla est√° dise√±ada para servir como un resumen ejecutivo de los hallazgos cuantitativos del proyecto.


---

```python
# Crear un DataFrame para presentar un resumen claro de todos los resultados
summary_data = {
    'Caso de Uso': [
        'Precios de Viviendas', 'Precios de Viviendas', 'Precios de Viviendas',
        'Horas Trabajadas', 'Horas Trabajadas', 'Horas Trabajadas',
        'Indicadores Econ√≥micos', 'Indicadores Econ√≥micos', 'Indicadores Econ√≥micos'
    ],
    'T√©cnica Aplicada': [
        'Elastic Net', 'Elastic Net', 'Elastic Net',
        'Regresi√≥n Cuant√≠lica', 'Regresi√≥n Cuant√≠lica', 'Regresi√≥n Cuant√≠lica',
        'VAR', 'VAR', 'VAR'
    ],
    'M√©trica / Par√°metro': [
        'RMSE', 'MAE', 'R¬≤',
        'Pinball Loss (Q10)', 'Pinball Loss (Q50)', 'Pinball Loss (Q90)',
        'Lags √ìptimos (AIC)', 'RMSE (realgdp_diff)', 'MAE (realinv_diff)'
    ],
    'Valor': [
        f"{rmse_elastic:.4f}", f"{mae_elastic:.4f}", f"{r2_elastic:.2%}",
        f"{pinball_losses[0.1]:.4f}", f"{pinball_losses[0.5]:.4f}", f"{pinball_losses[0.9]:.4f}",
        f"{optimal_lags}", f"{np.sqrt(mean_squared_error(test_data['realgdp'], forecast_df_diff['realgdp'])):.2f}", f"{mean_absolute_error(test_data['realinv'], forecast_df_diff['realinv']):.2f}"
    ]
}
summary_df = pd.DataFrame(summary_data)
print("üìä TABLA RESUMEN DE RESULTADOS:")
display(summary_df)
```

```
üìä TABLA RESUMEN DE RESULTADOS:

```

```
              Caso de Uso      T√©cnica Aplicada  M√©trica / Par√°metro   Valor
0    Precios de Viviendas           Elastic Net                 RMSE  0.7448
1    Precios de Viviendas           Elastic Net                  MAE  0.5332
2    Precios de Viviendas           Elastic Net                   R¬≤  57.67%
3        Horas Trabajadas  Regresi√≥n Cuant√≠lica   Pinball Loss (Q10)  1.9333
4        Horas Trabajadas  Regresi√≥n Cuant√≠lica   Pinball Loss (Q50)  3.5896
5        Horas Trabajadas  Regresi√≥n Cuant√≠lica   Pinball Loss (Q90)  2.0272
6  Indicadores Econ√≥micos                   VAR   Lags √ìptimos (AIC)       3
7  Indicadores Econ√≥micos                   VAR  RMSE (realgdp_diff)   83.48
8  Indicadores Econ√≥micos                   VAR   MAE (realinv_diff)   51.65
```


---

<a id='ch22'></a>

### **Interpretaci√≥n de la Tabla Resumen de Resultados**

Esta tabla consolida los resultados clave de tres an√°lisis de modelizaci√≥n distintos, cada uno abordando un problema diferente con una t√©cnica especializada. La interpretaci√≥n conjunta de estos resultados ofrece una visi√≥n panor√°mica sobre la importancia de seleccionar la herramienta anal√≠tica adecuada para cada desaf√≠o espec√≠fico.

#### **Conclusi√≥n General üéØ**

El resumen demuestra la aplicaci√≥n exitosa de un espectro de t√©cnicas de modelado, cada una revelando una faceta distinta del problema a resolver. Desde una predicci√≥n de valor central con **Elastic Net**, pasando por una cuantificaci√≥n de la incertidumbre con **Regresi√≥n Cuant√≠lica**, hasta la modelizaci√≥n de din√°micas temporales con **VAR**, los resultados subrayan que la eficacia de un modelo depende intr√≠nsecamente de su alineaci√≥n con el objetivo de negocio.

---

#### **An√°lisis Detallado por Caso de Uso**

* ### **1. Precios de Viviendas (Elastic Net): *Predicci√≥n de Valor Central***
    * **Resultados Clave**: El modelo explica el **57.67%** de la varianza en los precios (R¬≤) con un error promedio (MAE) de **0.53** unidades.
    * **Interpretaci√≥n**: El modelo Elastic Net proporciona un rendimiento **moderado y s√≥lido**. Ha logrado capturar m√°s de la mitad de los factores que influyen en el precio de una vivienda, ofreciendo una predicci√≥n de referencia √∫til. Si bien no es un modelo de alta precisi√≥n, es una herramienta eficaz para obtener una estimaci√≥n del valor central y, gracias a su naturaleza lineal, permite interpretar f√°cilmente el impacto de cada caracter√≠stica.

* ### **2. Horas Trabajadas (Regresi√≥n Cuant√≠lica): *Cuantificaci√≥n de la Incertidumbre***
    * **Resultados Clave**: Se evalu√≥ el ajuste para los percentiles 10, 50 y 90 a trav√©s de la m√©trica Pinball Loss.
    * **Interpretaci√≥n**: El √©xito de este caso de uso no radica en un √∫nico valor de error, sino en la **capacidad de la t√©cnica para modelar la distribuci√≥n completa** de las horas trabajadas. En lugar de obtener una sola predicci√≥n (ej. "40 horas"), este enfoque nos permite establecer un intervalo de confianza (ej. "estamos 80% seguros de que trabajar√° entre 28 y 52 horas"). Es una aplicaci√≥n m√°s sofisticada que va m√°s all√° de la predicci√≥n promedio para **gestionar el riesgo y la variabilidad**.

* ### **3. Indicadores Econ√≥micos (VAR): *Modelado de Din√°micas y Tendencias***
    * **Resultados Clave**: Se determin√≥ una estructura de modelo √≥ptima con **3 lags** y se evalu√≥ su capacidad de pron√≥stico (RMSE de 83.48 para el cambio en PIB, MAE de 51.65 para el cambio en inversi√≥n).
    * **Interpretaci√≥n**: El an√°lisis VAR fue exitoso en dos frentes: primero, en definir una estructura de modelo robusta (un VAR con memoria de 3 trimestres). Segundo, en revelar las limitaciones del pron√≥stico: los altos valores de error demuestran que, si bien el modelo puede proyectar la **tendencia de crecimiento a largo plazo**, es **incapaz de predecir la volatilidad y los ciclos econ√≥micos a corto plazo**. Este hallazgo es crucial para no sobreestimar la capacidad del modelo para anticipar recesiones o booms econ√≥micos.

---

### **S√≠ntesis Final**

La tabla resumen ilustra perfectamente el principio de que **no existe un "mejor modelo" universal, sino la "mejor t√©cnica para cada pregunta"**:
* Para una **estimaci√≥n puntual e interpretable**, Elastic Net fue una elecci√≥n s√≥lida.
* Para **entender la variabilidad y el riesgo**, la Regresi√≥n Cuant√≠lica fue superior.
* Para **analizar interdependencias y tendencias a largo plazo** en sistemas complejos, el modelo VAR fue la herramienta adecuada, revelando tanto la direcci√≥n del sistema como los l√≠mites de su predictibilidad a corto plazo.


---

<a id='ch23'></a>

### 4.2 Comparaci√≥n y Justificaci√≥n de Resultados

#### o ¬øQu√© t√©cnica result√≥ m√°s robusta para cada caso?

La robustez de una t√©cnica depende de su capacidad para resolver el problema espec√≠fico de manera fiable y precisa. Basado en los resultados, la elecci√≥n es clara para cada caso de uso:

* **Precios de Viviendas (Regresi√≥n de Valor Central): Elastic Net**
**Justificaci√≥n**: En este contexto, donde el objetivo era obtener una estimaci√≥n puntual e interpretable del precio, Elastic Net fue una t√©cnica robusta. Logr√≥ un rendimiento moderado (R¬≤ de 57.7%) y, lo que es m√°s importante, proporcion√≥ coeficientes claros que explican el impacto de cada variable (ej. la fuerte influencia del ingreso y la ubicaci√≥n). Su robustez radica en su simplicidad y su capacidad para realizar selecci√≥n de caracter√≠sticas de forma autom√°tica.
* **Horas Trabajadas (An√°lisis de Distribuci√≥n): Regresi√≥n Cuant√≠lica**
**Justificaci√≥n**: La Regresi√≥n Cuant√≠lica fue la t√©cnica m√°s robusta porque abord√≥ el verdadero desaf√≠o del problema: la alta variabilidad de las horas trabajadas. En lugar de ofrecer un promedio potencialmente enga√±oso, model√≥ con √©xito un **intervalo de predicci√≥n** (capturando los percentiles 10, 50 y 90). Su robustez proviene de su capacidad para cuantificar la incertidumbre y ofrecer una visi√≥n completa del rango de resultados probables, lo cual fue validado visualmente.
* **Indicadores Econ√≥micos (Pron√≥stico de Series de Tiempo): Proceso VAR**
**Justificaci√≥n**: El **proceso metodol√≥gico del VAR** fue robusto. Se aplicaron rigurosamente los pasos de verificaci√≥n de estacionariedad y selecci√≥n de lags √≥ptimos (AIC eligi√≥ 3 lags). Sin embargo, el *modelo VAR en s√≠* demostr√≥ ser robusto solo para un fin: **pronosticar la tendencia a largo plazo**. Fue fr√°gil y poco fiable para predecir la volatilidad y los ciclos a corto plazo.

#### o ¬øQu√© limitaciones o ventajas presentaron?

| T√©cnica Aplicada | Ventajas (Pros) | Limitaciones (Contras) |
| :--- | :--- | :--- |
| **Elastic Net** | <ul><li>**Alta Interpretabilidad**: Sus coeficientes son directos y f√°ciles de entender.</li><li>**Selecci√≥n de Variables Autom√°tica**: Descarta caracter√≠sticas irrelevantes, simplificando el modelo.</li><li>**Eficiencia Computacional**: Es r√°pido de entrenar.</li></ul> | <ul><li>**Supuesto de Linealidad**: Falla si las relaciones no son lineales, como se vio en el caso de predicci√≥n de ingresos.</li><li>**Precisi√≥n Limitada**: Generalmente menos preciso que modelos m√°s complejos (R¬≤ de ~58% es solo moderado).</li><li>**Solo Predice el Promedio**: No ofrece informaci√≥n sobre la incertidumbre de la predicci√≥n.</li></ul> |
| **Regresi√≥n Cuant√≠lica** | <ul><li>**Cuantifica la Incertidumbre**: Su principal ventaja es que genera un rango de predicciones (intervalos).</li><li>**Visi√≥n Completa**: Modela la distribuci√≥n completa de la variable, no solo su media.</li><li>**Robusto ante Outliers**: Es menos sensible a valores at√≠picos que los modelos basados en la media.</li></ul> | <ul><li>**Mayor Complejidad**: Requiere entrenar un modelo por cada cuantil, lo que es m√°s costoso computacionalmente.</li><li>**Interpretaci√≥n M√∫ltiple**: Requiere explicar m√∫ltiples resultados (un pron√≥stico por cuantil) en lugar de uno solo.</li></ul> |
| **Modelo VAR** | <ul><li>**Analiza Sistemas**: Modela la interdependencia entre m√∫ltiples series de tiempo simult√°neamente.</li><li>**Bueno para Tendencias**: Es eficaz para capturar y proyectar el comportamiento promedio a largo plazo.</li><li>**Marco Estad√≠stico S√≥lido**: Se basa en una teor√≠a econom√©trica bien establecida.</li></ul> | <ul><li>**Ciego a la Volatilidad y Ciclos**: Falla completamente en predecir puntos de inflexi√≥n, recesiones o shocks a corto plazo.</li><li>**Requiere Estacionariedad**: Necesita un preprocesamiento cuidadoso (diferenciaci√≥n) que complica la interpretaci√≥n.</li><li>**Complejidad con Muchas Variables**: Se vuelve inmanejable r√°pidamente a medida que se a√±aden m√°s series al sistema.</li></ul> |

***

### 5\. Presentar Conclusiones con Tablas y Visualizaciones

La conclusi√≥n principal de este conjunto de an√°lisis es que **la selecci√≥n de la t√©cnica de modelado debe estar subordinada al objetivo espec√≠fico del problema**. No existe un "mejor modelo" universal, sino una herramienta adecuada para cada tarea. Esta conclusi√≥n se apoya directamente en la siguiente tabla resumen y en las visualizaciones clave generadas.

#### Visualizaciones Clave de Soporte

* Para los **Precios de Viviendas**, la **gr√°fica de coeficientes de Elastic Net** fue fundamental para interpretar el modelo, mostrando visualmente el impacto positivo del ingreso y el negativo de la ubicaci√≥n.
* Para las **Horas Trabajadas**, la **gr√°fica de dispersi√≥n con el intervalo de predicci√≥n** demostr√≥ el √©xito de la Regresi√≥n Cuant√≠lica, mostrando c√≥mo la banda de predicci√≥n (roja a verde) envolv√≠a a los datos reales (negros).
* Para los **Indicadores Econ√≥micos**, la **gr√°fica del pron√≥stico final en escala original** fue la evidencia m√°s clara de las limitaciones del VAR, al mostrar una l√≠nea de tendencia suave que ignoraba por completo la volatilidad y los ciclos econ√≥micos reales.

En conjunto, estos elementos demuestran un proceso anal√≠tico completo donde cada t√©cnica fue evaluada no solo por su precisi√≥n num√©rica, sino tambi√©n por su capacidad para proporcionar insights valiosos y realistas acordes al problema planteado.


---

[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos Avanzados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_3_Boosting_Bagging/README.md)
