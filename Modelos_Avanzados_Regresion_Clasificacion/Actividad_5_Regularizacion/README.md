# Table of Contents

1. [Secci√≥n 1](#ch1)


<a id='ch1'></a>

# Aplicaci√≥n de Regularizaci√≥n en Regresi√≥n

**Objetivo:** Este notebook presenta una soluci√≥n completa y profesional para la aplicaci√≥n de t√©cnicas de regularizaci√≥n (Ridge, Lasso, Elastic Net) en un modelo de regresi√≥n. Se utilizar√° el dataset "Adult Income" como caso de estudio.

**Metodolog√≠a:**

1.  **Preprocesamiento Robusto:** Prepararemos los datos utilizando las mejores pr√°cticas, incluyendo el manejo de datos faltantes, la codificaci√≥n de variables categ√≥ricas y el escalado de caracter√≠sticas, prestando especial atenci√≥n a prevenir la fuga de datos (`data leakage`).
2.  **Entrenamiento Eficiente:** Entrenaremos m√∫ltiples modelos, incluyendo una regresi√≥n lineal como base, y optimizaremos los modelos regularizados mediante una b√∫squeda exhaustiva de hiperpar√°metros (`GridSearchCV`).
3.  **Evaluaci√≥n Hol√≠stica:** Evaluaremos los modelos no solo con el Error Cuadr√°tico Medio (MSE), sino tambi√©n con el R¬≤ Score para obtener una perspectiva m√°s completa de su rendimiento.
4.  **An√°lisis Profundo:** Iremos m√°s all√° de los resultados para analizar y visualizar los coeficientes del modelo, entendiendo c√≥mo cada t√©cnica de regularizaci√≥n impacta la complejidad y la interpretabilidad del modelo final.

-----

## 1\. Carga y Preprocesamiento del Dataset

La fase de preprocesamiento es fundamental para el √©xito de cualquier modelo de machine learning. Nuestro objetivo aqu√≠ no es solo limpiar y transformar los datos, sino hacerlo de una manera que sea **robusta y metodol√≥gicamente correcta**.

**L√≥gica y Teor√≠a:**

  * **Prevenci√≥n de Fuga de Datos (`Data Leakage`):** La divisi√≥n de los datos en conjuntos de entrenamiento y prueba se realiza **antes** de cualquier operaci√≥n de ajuste (como la imputaci√≥n de valores nulos o el escalado). Si ajust√°ramos el escalador (`StandardScaler`) con la totalidad de los datos, la media y la desviaci√≥n est√°ndar del conjunto de prueba "contaminar√≠an" el entrenamiento, dando una visi√≥n irrealmente optimista del rendimiento del modelo.
  * **Estratificaci√≥n (`stratify=y`):** El dataset "Adult" tiene un desbalance de clases (muchas m√°s personas con ingresos `<=$50K` que `>$50K`). La estratificaci√≥n en la divisi√≥n de datos es crucial porque asegura que esta proporci√≥n se mantenga constante tanto en el conjunto de entrenamiento como en el de prueba. Esto garantiza que nuestro modelo se eval√∫e en un escenario representativo de la distribuci√≥n original.
  * **Pipelines de Preprocesamiento:** Utilizamos `Pipeline` y `ColumnTransformer` para encapsular toda la l√≥gica de preprocesamiento. Esto no solo organiza el c√≥digo, sino que tambi√©n previene errores comunes, asegurando que las mismas transformaciones se apliquen consistentemente a los datos de entrenamiento y a los nuevos datos (como el conjunto de prueba).
  * **Elecci√≥n de Transformadores:**
      * **Num√©rico:** Se imputan los valores nulos con la **mediana** en lugar de la media porque es robusta a valores at√≠picos (`outliers`). Se escalan los datos con `StandardScaler` porque los modelos de regularizaci√≥n aplican una penalizaci√≥n a los coeficientes, y si las variables tuvieran escalas muy diferentes, aquellas con mayor magnitud dominar√≠an injustamente el t√©rmino de penalizaci√≥n.
      * **Categ√≥rico:** Se imputan los valores nulos con la **moda** (el valor m√°s frecuente), la estrategia m√°s l√≥gica para datos categ√≥ricos. Se utiliza `OneHotEncoder` para convertir las categor√≠as en columnas num√©ricas binarias, evitando as√≠ la creaci√≥n de una falsa relaci√≥n ordinal que introducir√≠an otros m√©todos como `LabelEncoder`.



---

```python
# =============================================================================
# 1. IMPORTACI√ìN Y CONFIGURACI√ìN INICIAL
# =============================================================================
# Importar librer√≠as fundamentales
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# Importar componentes de Scikit-Learn
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score

# Configuraci√≥n para una mejor visualizaci√≥n y control de advertencias
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')
print("=" * 60)
print("APLICACI√ìN DE REGULARIZACI√ìN EN MODELO DE REGRESI√ìN")
print("=" * 60)

# =============================================================================
# 2. CARGA Y PREPARACI√ìN INICIAL DE DATOS
# =============================================================================
print("\n1. CARGANDO Y PREPARANDO LOS DATOS...")
print("-" * 40)

# Cargar el dataset desde OpenML. 'as_frame=True' lo carga como DataFrame de pandas.
adult = fetch_openml(name="adult", version=2, as_frame=True, parser='auto')
df = adult.frame
print(f"‚úì Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")

# Convertir la variable objetivo 'class' a un formato num√©rico (0 o 1).
df['income'] = df['class'].apply(lambda x: 1 if x == '>50K' else 0)
df = df.drop('class', axis=1)

# Los valores nulos en este dataset vienen representados por '?'. Los reemplazamos por NaN de numpy.
df.replace('?', np.nan, inplace=True)
print(f"‚úì Valores nulos identificados: {df.isnull().sum().sum()} en total")

# Separar las caracter√≠sticas (X) de la variable objetivo (y)
X = df.drop('income', axis=1)
y = df['income']

# Dividir los datos ANTES de cualquier preprocesamiento para evitar fuga de datos.
# Se usa 'stratify=y' para mantener la misma proporci√≥n de la variable objetivo en ambos conjuntos.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"‚úì Divisi√≥n estratificada completada: {X_train.shape[0]} para entrenamiento, {X_test.shape[0]} para prueba")

# =============================================================================
# 3. DEFINICI√ìN DE PIPELINES DE PREPROCESAMIENTO
# =============================================================================
# Identificar columnas num√©ricas y categ√≥ricas autom√°ticamente
numeric_features = X.select_dtypes(include=np.number).columns.tolist()
categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()

# Crear un pipeline para transformaciones num√©ricas
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')), # Imputar con la mediana (robusto a outliers)
    ('scaler', StandardScaler())                   # Escalar para que la regularizaci√≥n funcione correctamente
])

# Crear un pipeline para transformaciones categ√≥ricas
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')), # Imputar con la moda
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Convertir a binario
])

# Combinar ambos pipelines usando ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)
print(f"‚úì Preprocesador configurado para {len(numeric_features)} vars num√©ricas y {len(categorical_features)} categ√≥ricas")
```

```
============================================================
APLICACI√ìN DE REGULARIZACI√ìN EN MODELO DE REGRESI√ìN
============================================================

1. CARGANDO Y PREPARANDO LOS DATOS...
----------------------------------------
‚úì Dataset cargado: 48842 filas, 15 columnas
‚úì Valores nulos identificados: 6465 en total
‚úì Divisi√≥n estratificada completada: 39073 para entrenamiento, 9769 para prueba
‚úì Preprocesador configurado para 6 vars num√©ricas y 8 categ√≥ricas

```


---

2. [Secci√≥n 2](#ch2)


<a id='ch2'></a>

### **An√°lisis de la Preparaci√≥n de Datos**

Los resultados de la primera fase del script indican que la **configuraci√≥n inicial y el preprocesamiento de los datos se han ejecutado de manera exitosa y metodol√≥gicamente s√≥lida**. A continuaci√≥n, se detalla la interpretaci√≥n de cada punto clave:

---

### 1. Dimensiones y Calidad del Dataset

* **`Dataset cargado: 48,842 filas, 15 columnas`**: El punto de partida es un dataset de tama√±o considerable, con casi 50,000 registros, lo que es suficiente para entrenar un modelo robusto. Las 15 columnas iniciales incluyen tanto las caracter√≠sticas predictoras como la variable objetivo original.

* **`Valores nulos identificados: 6,465 en total`**: Este es un hallazgo cr√≠tico. La presencia de m√°s de 6,000 valores nulos confirma que el dataset no est√° "limpio" y que una estrategia de manejo de datos faltantes es **indispensable**. La decisi√≥n de utilizar `SimpleImputer` dentro de los pipelines para rellenar estos vac√≠os (con la mediana para datos num√©ricos y la moda para categ√≥ricos) es una pr√°ctica est√°ndar y acertada para evitar la p√©rdida de datos que implicar√≠a eliminar las filas afectadas.

---

### 2. Estrategia de Validaci√≥n y Divisi√≥n de Datos

* **`Divisi√≥n estratificada completada: 39,073 para entrenamiento, 9,769 para prueba`**: El script ha segmentado correctamente los datos en una proporci√≥n 80/20, asignando la mayor parte para el entrenamiento del modelo y reservando un 20% para su evaluaci√≥n imparcial.

* **La importancia de la "Divisi√≥n Estratificada"**: Este es el aspecto m√°s importante de este paso. La variable objetivo (`income`) en este dataset est√° desbalanceada (hay m√°s personas con ingresos bajos que altos). Una divisi√≥n aleatoria simple podr√≠a resultar, por azar, en conjuntos de entrenamiento y prueba con proporciones muy diferentes de la clase minoritaria. Al realizar una **divisi√≥n estratificada**, el script asegura que la distribuci√≥n porcentual de ingresos altos y bajos sea **exactamente la misma** en el conjunto de entrenamiento y en el de prueba. Esto es fundamental para garantizar que el rendimiento del modelo medido en el conjunto de prueba sea un reflejo fiel de su capacidad de generalizaci√≥n en un escenario realista. ‚öñÔ∏è

---

### 3. Configuraci√≥n del Preprocesador de Caracter√≠sticas

* **`Preprocesador configurado para 6 vars num√©ricas y 8 categ√≥ricas`**: Este resultado confirma que el script ha identificado correctamente la naturaleza de las 14 variables predictoras. Esta distinci√≥n es crucial porque cada tipo de variable requiere un tratamiento diferente:
    * Las **6 variables num√©ricas** (como 'age', 'hours-per-week') ser√°n imputadas y luego **escaladas**. El escalado (`StandardScaler`) es un requisito para los modelos de regresi√≥n con regularizaci√≥n (Lasso, Ridge), ya que las penalizaciones son sensibles a la escala de los coeficientes.
    * Las **8 variables categ√≥ricas** (como 'workclass', 'education') ser√°n imputadas y luego transformadas mediante **One-Hot Encoding**. Este proceso las convierte en un formato num√©rico que el modelo puede procesar sin crear una falsa relaci√≥n de orden entre las categor√≠as.

En resumen, los resultados de esta fase inicial demuestran que los datos han sido preparados de forma rigurosa, sentando una base s√≥lida y confiable para la siguiente etapa de entrenamiento y evaluaci√≥n de los modelos de regresi√≥n. ‚úÖ


---

3. [Secci√≥n 3](#ch3)


<a id='ch3'></a>

-----

## 2\. Entrenamiento de Modelos y B√∫squeda de Hiperpar√°metros

En esta fase, definimos y entrenamos nuestros modelos. La clave aqu√≠ es la **automatizaci√≥n y la optimizaci√≥n**.

**L√≥gica y Teor√≠a:**

  * **Modelos y Penalizaciones:**

      * **Regresi√≥n Lineal:** Nuestro modelo de referencia. No tiene regularizaci√≥n, por lo que es propenso a sobreajustarse a los datos de entrenamiento, especialmente con muchas caracter√≠sticas.
      * **Ridge ($L2$):** A√±ade una penalizaci√≥n proporcional a la suma de los cuadrados de los coeficientes ($\\alpha \\sum \\beta\_j^2$). Esta penalizaci√≥n "encoge" los coeficientes, reduciendo la complejidad del modelo y el impacto de la multicolinealidad. Es poco probable que elimine caracter√≠sticas por completo.
      * **Lasso ($L1$):** A√±ade una penalizaci√≥n proporcional a la suma de los valores absolutos de los coeficientes ($\\alpha \\sum |\\beta\_j|$). Esta forma de penalizaci√≥n puede reducir los coeficientes de las caracter√≠sticas menos importantes a exactamente **cero**, realizando as√≠ una selecci√≥n autom√°tica de caracter√≠sticas y generando un modelo m√°s "disperso" (sparse) y simple.
      * **Elastic Net:** Combina las penalizaciones L1 y L2. Es controlada por dos hiperpar√°metros: `alpha` (la fuerza total de la regularizaci√≥n) y `l1_ratio` (la proporci√≥n de la penalizaci√≥n que es L1). Es √∫til cuando hay m√∫ltiples caracter√≠sticas correlacionadas, ya que tiende a seleccionarlas o eliminarlas en grupo.

  * **Optimizaci√≥n con `GridSearchCV`:** En lugar de elegir un valor arbitrario para el hiperpar√°metro `alpha`, usamos `GridSearchCV` para buscar sistem√°ticamente la mejor configuraci√≥n. Este proceso utiliza la **validaci√≥n cruzada (`cross-validation`)**: divide el conjunto de entrenamiento en 'k' partes (en nuestro caso, 5), entrena el modelo en k-1 partes y lo valida en la parte restante, repitiendo el proceso k veces. Esto proporciona una estimaci√≥n mucho m√°s robusta del rendimiento del modelo para un `alpha` dado, evitando el sobreajuste al conjunto de validaci√≥n. `n_jobs=-1` es una optimizaci√≥n de rendimiento que utiliza todos los n√∫cleos de la CPU para paralelizar la b√∫squeda.



---

4. [Secci√≥n 4](#ch4)


<a id='ch4'></a>

* * *

## 2\. Entrenamiento de Modelos y B√∫squeda de Hiperpar√°metros

En esta fase, definimos y entrenamos nuestros modelos. La clave aqu√≠ es la **automatizaci√≥n y la optimizaci√≥n**.

**L√≥gica y Teor√≠a:**

* **Modelos y Penalizaciones:**

  * **Regresi√≥n Lineal:** Nuestro modelo de referencia. No tiene regularizaci√≥n, por lo que es propenso a sobreajustarse a los datos de entrenamiento, especialmente con muchas caracter√≠sticas.
  * **Ridge ($L_2$):** A√±ade una penalizaci√≥n proporcional a la suma de los cuadrados de los coeficientes ($\alpha \sum \beta_j^2$). Esta penalizaci√≥n "encoge" los coeficientes, reduciendo la complejidad del modelo y el impacto de la multicolinealidad. Es poco probable que elimine caracter√≠sticas por completo.
  * **Lasso ($L_1$):** A√±ade una penalizaci√≥n proporcional a la suma de los valores absolutos de los coeficientes ($\alpha \sum |\beta_j|$). Esta forma de penalizaci√≥n puede reducir los coeficientes de las caracter√≠sticas menos importantes a exactamente **cero**, realizando as√≠ una selecci√≥n autom√°tica de caracter√≠sticas y generando un modelo m√°s "disperso" (sparse) y simple.
  * **Elastic Net:** Combina las penalizaciones L1 y L2. Es controlada por dos hiperpar√°metros: `alpha` (la fuerza total de la regularizaci√≥n) y `l1_ratio` (la proporci√≥n de la penalizaci√≥n que es L1). Es √∫til cuando hay m√∫ltiples caracter√≠sticas correlacionadas, ya que tiende a seleccionarlas o eliminarlas en grupo.
* **Optimizaci√≥n con `GridSearchCV`:** En lugar de elegir un valor arbitrario para el hiperpar√°metro `alpha`, usamos `GridSearchCV` para buscar sistem√°ticamente la mejor configuraci√≥n. Este proceso utiliza la **validaci√≥n cruzada (`cross-validation`)**: divide el conjunto de entrenamiento en 'k' partes (en nuestro caso, 5), entrena el modelo en k-1 partes y lo valida en la parte restante, repitiendo el proceso k veces. Esto proporciona una estimaci√≥n mucho m√°s robusta del rendimiento del modelo para un `alpha` dado, evitando el sobreajuste al conjunto de validaci√≥n. `n_jobs=-1` es una optimizaci√≥n de rendimiento que utiliza todos los n√∫cleos de la CPU para paralelizar la b√∫squeda.


---

```python
# =============================================================================
# 4. DEFINICI√ìN DE MODELOS Y B√öSQUEDA DE HIPERPAR√ÅMETROS
# =============================================================================
print("\n2. ENTRENANDO MODELOS CON REGULARIZACI√ìN...")
print("-" * 45)

# Crear un diccionario de pipelines (preprocesador + modelo) para una gesti√≥n eficiente
models = {
    'Linear Regression': Pipeline([('preprocessor', preprocessor),
                                     ('regressor', LinearRegression())]),
    'Ridge': Pipeline([('preprocessor', preprocessor),
                       ('regressor', Ridge(random_state=42))]),
    'Lasso': Pipeline([('preprocessor', preprocessor),
                       ('regressor', Lasso(random_state=42, max_iter=2000))]),
    'Elastic Net': Pipeline([('preprocessor', preprocessor),
                             ('regressor', ElasticNet(random_state=42, max_iter=2000))])
}

# Definir el espacio de b√∫squeda de hiperpar√°metros para cada modelo
param_grids = {
    'Ridge': {'regressor__alpha': [0.1, 1.0, 10, 50, 100]},
    'Lasso': {'regressor__alpha': [0.0001, 0.001, 0.01]},
    'Elastic Net': {'regressor__alpha': [0.001, 0.01, 0.1],
                    'regressor__l1_ratio': [0.1, 0.5, 0.9]}
}

# Almacenar los modelos ya entrenados y sus mejores par√°metros
trained_models = {}
best_params = {}

# Entrenar la Regresi√≥n Lineal base (sin b√∫squeda de hiperpar√°metros)
print("  ‚Ä¢ Entrenando Regresi√≥n Lineal (Baseline)...")
models['Linear Regression'].fit(X_train, y_train)
trained_models['Linear Regression'] = models['Linear Regression']

# Entrenar los modelos regularizados usando GridSearchCV
for name in ['Ridge', 'Lasso', 'Elastic Net']:
    print(f"  ‚Ä¢ Entrenando {name} con b√∫squeda de hiperpar√°metros...")
    # cv=5 indica validaci√≥n cruzada de 5 folds. n_jobs=-1 usa todos los cores del CPU.
    grid = GridSearchCV(models[name], param_grids[name],
                        cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid.fit(X_train, y_train)

    # Guardar el mejor modelo encontrado y sus par√°metros
    trained_models[name] = grid.best_estimator_
    best_params[name] = grid.best_params_
    print(f"    ‚îî‚îÄ Mejores par√°metros para {name}: {grid.best_params_}")
```

```

2. ENTRENANDO MODELOS CON REGULARIZACI√ìN...
---------------------------------------------
  ‚Ä¢ Entrenando Regresi√≥n Lineal (Baseline)...
  ‚Ä¢ Entrenando Ridge con b√∫squeda de hiperpar√°metros...
    ‚îî‚îÄ Mejores par√°metros para Ridge: {'regressor__alpha': 50}
  ‚Ä¢ Entrenando Lasso con b√∫squeda de hiperpar√°metros...
    ‚îî‚îÄ Mejores par√°metros para Lasso: {'regressor__alpha': 0.0001}
  ‚Ä¢ Entrenando Elastic Net con b√∫squeda de hiperpar√°metros...
    ‚îî‚îÄ Mejores par√°metros para Elastic Net: {'regressor__alpha': 0.001, 'regressor__l1_ratio': 0.1}

```


---

5. [Secci√≥n 5](#ch5)


<a id='ch5'></a>

### **An√°lisis de los Resultados del Entrenamiento**

La salida del script confirma que el proceso de entrenamiento y la b√∫squeda de hiperpar√°metros (`GridSearchCV`) se han completado con √©xito. Los resultados obtenidos para cada modelo nos ofrecen informaci√≥n valiosa sobre la estrategia de regularizaci√≥n m√°s efectiva para este conjunto de datos en particular.

---

### 1. Modelo Ridge: Penalizaci√≥n Moderadamente Fuerte (`alpha: 50`)

El resultado `{'regressor__alpha': 50}` para el modelo Ridge es significativo. El hiperpar√°metro **`alpha`** controla la intensidad de la penalizaci√≥n L2 (de encogimiento).

* **Interpretaci√≥n**: Un valor √≥ptimo de 50, que se encuentra en el rango medio-alto de los valores probados (`[0.1, 1.0, 10, 50, 100]`), indica que el modelo se beneficia de una **penalizaci√≥n de regularizaci√≥n considerablemente fuerte**.
* **Implicaci√≥n**: Esto sugiere que el modelo de regresi√≥n lineal base era propenso al sobreajuste o sufr√≠a de multicolinealidad (correlaci√≥n entre caracter√≠sticas). La penalizaci√≥n L2 de Ridge fue efectiva al "encoger" la magnitud de todos los coeficientes, reduciendo la complejidad del modelo y mejorando su capacidad de generalizaci√≥n sin necesidad de eliminar ninguna caracter√≠stica por completo.

---

### 2. Modelo Lasso: Penalizaci√≥n Muy D√©bil (`alpha: 0.0001`)

El resultado `{'regressor__alpha': 0.0001}` para el modelo Lasso muestra una din√°mica muy diferente.

* **Interpretaci√≥n**: El valor √≥ptimo de `alpha` es el m√°s bajo de los que se probaron (`[0.0001, 0.001, 0.01]`). Esto indica que el modelo Lasso funciona mejor con una **penalizaci√≥n L1 (de selecci√≥n de caracter√≠sticas) extremadamente ligera**.
* **Implicaci√≥n**: Una penalizaci√≥n fuerte, que forzar√≠a a m√°s coeficientes a ser cero, probablemente estaba eliminando caracter√≠sticas que, aunque de poca importancia individual, en conjunto aportaban valor predictivo. El modelo concluye que **la selecci√≥n agresiva de caracter√≠sticas no es la mejor estrategia aqu√≠**; es preferible mantener la mayor√≠a de las caracter√≠sticas, aunque sea con un impacto m√≠nimo.

---

### 3. Modelo Elastic Net: Dominancia de la Penalizaci√≥n L2 (`alpha: 0.001`, `l1_ratio: 0.1`)

Este resultado es el m√°s revelador, ya que combina las dos penalizaciones.

* **Interpretaci√≥n del `alpha` (`0.001`)**: Al igual que en Lasso, la fuerza general de la regularizaci√≥n es baja.
* **Interpretaci√≥n del `l1_ratio` (`0.1`)**: Este es el hallazgo clave. El `l1_ratio` define la mezcla entre las penalizaciones L1 y L2. Un valor de `0.1` significa que la penalizaci√≥n total se compone de un **10% de L1 (Lasso) y un 90% de L2 (Ridge)**.
* **Implicaci√≥n**: Elastic Net descubri√≥ que la estrategia √≥ptima es una combinaci√≥n que **favorece abrumadoramente la regularizaci√≥n de tipo Ridge**. Esto refuerza las conclusiones de los dos modelos anteriores: el modelo se beneficia mucho m√°s del **encogimiento de coeficientes (L2)** que de la **eliminaci√≥n de caracter√≠sticas (L1)**. üß†

---

### S√≠ntesis General

En conjunto, estos resultados sugieren que para el dataset "Adult Income":

1.  **La regularizaci√≥n es necesaria**, ya que los modelos optimizados eligieron valores de `alpha` distintos de cero.
2.  La estrategia m√°s prometedora no es eliminar caracter√≠sticas, sino **moderar la influencia de todas ellas**.
3.  El **efecto de encogimiento de Ridge (L2)** parece ser el mecanismo m√°s efectivo para mejorar el rendimiento del modelo, como lo demuestra tanto el `alpha` relativamente alto en el modelo Ridge puro como el `l1_ratio` bajo en el modelo Elastic Net.

El siguiente paso l√≥gico ser√° evaluar estos modelos ya optimizados en el conjunto de prueba para ver c√≥mo estos hiperpar√°metros se traducen en un rendimiento predictivo final. ‚úÖ


---

6. [Secci√≥n 6](#ch6)


<a id='ch6'></a>

---
## 3\. Evaluaci√≥n del Rendimiento y la Cuesti√≥n de Clasificaci√≥n vs. Regresi√≥n

Una vez entrenados los modelos, debemos evaluar su capacidad de generalizaci√≥n en el conjunto de prueba.

### Advertencia: Usar Regresi√≥n para un Problema de Clasificaci√≥n

Es crucial detenernos a reflexionar sobre la naturaleza de nuestro problema. La variable objetivo, `income`, es binaria (0 o 1), lo que can√≥nicamente lo define como un **problema de clasificaci√≥n**. La actividad, sin embargo, nos pide expl√≠citamente aplicar **modelos de regresi√≥n**. ¬øPor qu√© es esto posible y cu√°les son las implicaciones?

1.  **Interpretaci√≥n del Resultado:** Al usar un modelo de regresi√≥n lineal, no estamos prediciendo una clase ("gana \>50K" o "no"), sino un **valor continuo**. Este valor puede interpretarse como un *score* o una *propensi√≥n* a tener ingresos altos. Un valor cercano a 1 indica una alta probabilidad, mientras que uno cercano a 0 indica una baja probabilidad. Los valores pueden incluso salirse del rango [0, 1].

2.  **Validez de la M√©trica (MSE):** El **Error Cuadr√°tico Medio (MSE)** sigue siendo una funci√≥n de coste v√°lida. Penaliza las predicciones que est√°n lejos del valor real (0 o 1). Por ejemplo, si el valor real es 1 y el modelo predice 0.2, el error al cuadrado es $(1 - 0.2)^2 = 0.64$. El modelo es incentivado a producir valores cercanos a 0 y 1.

3.  **La Alternativa Correcta (Clasificaci√≥n):** En un escenario profesional, el enfoque est√°ndar ser√≠a utilizar un modelo de clasificaci√≥n como la **Regresi√≥n Log√≠stica**. Este modelo utiliza una funci√≥n sigmoide para asegurar que la salida sea siempre una probabilidad entre 0 y 1. Adem√°s, se optimizar√≠a utilizando una m√©trica m√°s apropiada para clasificaci√≥n, como la **P√©rdida Logar√≠tmica (Log-Loss)**, y se evaluar√≠a con m√©tricas como la Exactitud (Accuracy), Precisi√≥n, Recall o F1-Score.

**Conclusi√≥n para este ejercicio:** Seguiremos el enfoque de regresi√≥n solicitado por la actividad, entendiendo que es una simplificaci√≥n acad√©mica. Evaluaremos los modelos con m√©tricas de regresi√≥n, pero teniendo en mente esta distinci√≥n conceptual.

### M√©tricas de Evaluaci√≥n de Regresi√≥n:

  * **MSE (Mean Squared Error):** El promedio de los errores al cuadrado. Es sensible a errores grandes, pero sus unidades est√°n al cuadrado, lo que dificulta su interpretaci√≥n directa.
  * **RMSE (Root Mean Squared Error):** La ra√≠z cuadrada del MSE. Su principal ventaja es que est√° en las mismas unidades que la variable objetivo, siendo m√°s interpretable.
  * **R¬≤ Score (Coeficiente de Determinaci√≥n):** Indica la proporci√≥n de la varianza en la variable objetivo que es predecible a partir de las caracter√≠sticas. Un valor de 1.0 es una predicci√≥n perfecta, mientras que un valor de 0.0 indica que el modelo no es mejor que simplemente predecir la media de los datos.



---

```python
# =============================================================================
# 5. EVALUACI√ìN DE MODELOS EN EL CONJUNTO DE PRUEBA
# =============================================================================
print("\n3. EVALUANDO RENDIMIENTO...")
print("-" * 30)

# Almacenar todos los resultados en una lista de diccionarios para crear un DataFrame
results = []

# Iterar sobre los modelos ya entrenados para hacer predicciones y calcular m√©tricas
for name, model in trained_models.items():
    # Realizar predicciones en el conjunto de prueba
    y_pred = model.predict(X_test)

    # Calcular m√©tricas de regresi√≥n
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # Guardar los resultados
    results.append({
        'Modelo': name,
        'MSE': mse,
        'RMSE': np.sqrt(mse), # Ra√≠z del MSE para mejor interpretaci√≥n
        'R¬≤ Score': r2
    })

# Convertir la lista de resultados en un DataFrame de pandas para una visualizaci√≥n clara
results_df = pd.DataFrame(results).sort_values(by='MSE')

# Imprimir la tabla de resultados
print("\nRESULTADOS DE EVALUACI√ìN EN EL CONJUNTO DE PRUEBA:")
print(results_df.round(4))

# Identificar y anunciar el mejor modelo program√°ticamente
best_model_name = results_df.iloc[0]['Modelo']
best_model_mse = results_df.iloc[0]['MSE']
print(f"\n‚úì El mejor modelo en t√©rminos de MSE es: {best_model_name} (MSE = {best_model_mse:.4f})")
```

```

3. EVALUANDO RENDIMIENTO...
------------------------------

RESULTADOS DE EVALUACI√ìN EN EL CONJUNTO DE PRUEBA:
              Modelo     MSE    RMSE  R¬≤ Score
1              Ridge  0.1168  0.3417    0.3586
2              Lasso  0.1168  0.3418    0.3584
0  Linear Regression  0.1168  0.3418    0.3583
3        Elastic Net  0.1168  0.3418    0.3582

‚úì El mejor modelo en t√©rminos de MSE es: Ridge (MSE = 0.1168)

```


---

7. [Secci√≥n 7](#ch7)


<a id='ch7'></a>

### **An√°lisis de los Resultados de Evaluaci√≥n**

Los resultados presentados en la tabla de evaluaci√≥n son extremadamente reveladores y conducen a una conclusi√≥n central: a pesar de la correcta aplicaci√≥n y optimizaci√≥n de las t√©cnicas de regularizaci√≥n, **todos los modelos, incluyendo la regresi√≥n lineal base, muestran un rendimiento predictivo pr√°cticamente id√©ntico y moderado.**

---

### 1. La Ausencia de un Ganador Claro

El hallazgo m√°s importante es la **convergencia en el rendimiento** de todos los modelos.

* **M√©tricas Id√©nticas**: El **MSE** (`0.1168`), **RMSE** (`~0.3418`) y **R¬≤ Score** (`~0.358`) son casi iguales para los cuatro modelos. Aunque el script designa a **Ridge** como el "mejor modelo", esta es una distinci√≥n puramente t√©cnica basada en diferencias de redondeo en el cuarto o quinto decimal. En la pr√°ctica, no hay una diferencia significativa en su capacidad predictiva.

* **¬øPor qu√© sucede esto?**: Esta paridad se explica por los resultados de la fase de optimizaci√≥n. Los modelos Lasso y Elastic Net encontraron que los valores √≥ptimos de `alpha` eran extremadamente peque√±os (`0.0001` y `0.001`, respectivamente). Una penalizaci√≥n tan d√©bil significa que estos modelos se comportan de manera muy similar a una regresi√≥n lineal est√°ndar. Aunque Ridge utiliz√≥ una penalizaci√≥n m√°s fuerte (`alpha=50`), el efecto final en el rendimiento predictivo en el conjunto de prueba fue el mismo. Esto sugiere que el problema principal del modelo no era el sobreajuste que la regularizaci√≥n pudiera corregir, sino las limitaciones inherentes del propio modelo lineal.

---

### 2. Interpretaci√≥n del Nivel de Rendimiento (R¬≤ Score de ~0.36)

El R¬≤ Score nos da el contexto m√°s claro sobre la calidad del modelo.

* **Significado**: Un R¬≤ Score de aproximadamente `0.36` indica que los modelos solo pueden **explicar alrededor del 36% de la variabilidad** en los ingresos de las personas utilizando las caracter√≠sticas disponibles.

* **Implicaci√≥n Cr√≠tica**: Esto sugiere que la relaci√≥n entre las caracter√≠sticas (edad, educaci√≥n, horas de trabajo, etc.) y el ingreso **no es predominantemente lineal**. Aunque los modelos son mejores que una simple suposici√≥n (R¬≤ > 0), el 64% restante de la variabilidad se debe a patrones no lineales, interacciones complejas entre variables u otros factores no incluidos en el dataset. Para muchas aplicaciones pr√°cticas, un poder explicativo del 36% se considerar√≠a bajo. üìâ

---

Aunque el ejercicio de aplicar regularizaci√≥n se realiz√≥ correctamente, el resultado demuestra que **para este conjunto de datos, la regularizaci√≥n no aport√≥ un beneficio tangible sobre el modelo lineal base.** El rendimiento parece estar limitado por la complejidad del problema m√°s que por el sobreajuste del modelo.

**Recomendaciones para Futuros Experimentos:**
Dado que los modelos lineales han alcanzado su techo de rendimiento, el siguiente paso l√≥gico ser√≠a explorar modelos m√°s potentes y no lineales que puedan capturar las complejas interacciones en los datos. Algunas opciones excelentes ser√≠an:

* **√Årboles de Decisi√≥n y Random Forest**
* **Modelos de Gradient Boosting** (como XGBoost o LightGBM)
* **Redes Neuronales**

Estos algoritmos son capaces de modelar relaciones no lineales y es muy probable que ofrezcan una mejora sustancial en el R¬≤ Score. üöÄ


---

8. [Secci√≥n 8](#ch8)


<a id='ch8'></a>

---
## 4\. An√°lisis de Coeficientes

El rendimiento predictivo (qu√© tan bajas son las m√©tricas de error) es solo una parte de la historia. El verdadero poder de la regularizaci√≥n se revela al inspeccionar los **coeficientes** del modelo. Estos coeficientes representan el peso o la importancia que el modelo le asigna a cada caracter√≠stica.

**L√≥gica y Teor√≠a:**

  * **Interpretaci√≥n:** Un coeficiente positivo grande significa que un aumento en esa caracter√≠stica est√° asociado con un aumento en la predicci√≥n (mayor probabilidad de tener ingresos altos). Un coeficiente negativo grande indica lo contrario. Un coeficiente cercano a cero sugiere que la caracter√≠stica tiene poco o ning√∫n impacto en la predicci√≥n.
  * **Sparsity (Dispersi√≥n):** Analizaremos cu√°ntos coeficientes son efectivamente cero. Esto es un indicador directo de la selecci√≥n de caracter√≠sticas. Esperamos que Lasso y, en menor medida, Elastic Net, generen "modelos dispersos" al eliminar caracter√≠sticas. Ridge, por otro lado, no lo har√°.
  * **Complejidad del Modelo:** Un modelo con menos caracter√≠sticas activas (m√°s coeficientes en cero) o con coeficientes de menor magnitud es, por definici√≥n, **menos complejo**. Un modelo menos complejo es menos propenso al sobreajuste y, a menudo, m√°s f√°cil de interpretar y desplegar en producci√≥n.




---

```python
# =============================================================================
# 6. AN√ÅLISIS DETALLADO DE LOS COEFICIENTES
# =============================================================================
print("\n4. ANALIZANDO COEFICIENTES...")
print("-" * 32)

# Obtener los nombres de las caracter√≠sticas despu√©s del preprocesamiento (OneHotEncoding)
# Esto es crucial para asociar cada coeficiente con su caracter√≠stica correcta.
try:
    preprocessor_fitted = trained_models['Ridge'].named_steps['preprocessor']
    onehot_cols = preprocessor_fitted.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)
    feature_names = numeric_features + list(onehot_cols)
except Exception as e:
    # Plan B por si falla la obtenci√≥n de nombres, para que el script no se detenga
    print(f"Advertencia: No se pudieron obtener los nombres de las caracter√≠sticas. Usando nombres gen√©ricos. Error: {e}")
    n_features = trained_models['Ridge'].named_steps['regressor'].coef_.shape[0]
    feature_names = [f'feature_{i}' for i in range(n_features)]

# Extraer los coeficientes de cada modelo y guardarlos en un diccionario
coefficients = {name: model.named_steps['regressor'].coef_ for name, model in trained_models.items()}

# Crear un DataFrame para comparar los coeficientes de lado a lado
coef_df = pd.DataFrame(coefficients, index=feature_names)

# Analizar la dispersi√≥n (cu√°ntos coeficientes son pr√°cticamente cero)
print("\nAN√ÅLISIS DE SPARSITY (coeficientes ‚âà 0):")
sparsity_results = {}
for name in ['Ridge', 'Lasso', 'Elastic Net']:
    zero_coef = np.sum(np.abs(coef_df[name]) < 1e-6) # Usar una tolerancia peque√±a en lugar de '== 0'
    total_coef = len(coef_df[name])
    sparsity_results[name] = {'zero': zero_coef, 'total': total_coef}
    print(f"  ‚Ä¢ {name}: {zero_coef}/{total_coef} coeficientes eliminados ({zero_coef/total_coef*100:.1f}%)")

# Mostrar las caracter√≠sticas m√°s influyentes seg√∫n el modelo Ridge (que no elimina ninguna)
print(f"\nTOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES (seg√∫n magnitud en Ridge):")
top_features_ridge = coef_df['Ridge'].abs().nlargest(10)
print(top_features_ridge.round(4))
```

```

4. ANALIZANDO COEFICIENTES...
--------------------------------

AN√ÅLISIS DE SPARSITY (coeficientes ‚âà 0):
  ‚Ä¢ Ridge: 0/105 coeficientes eliminados (0.0%)
  ‚Ä¢ Lasso: 48/105 coeficientes eliminados (45.7%)
  ‚Ä¢ Elastic Net: 45/105 coeficientes eliminados (42.9%)

TOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES (seg√∫n magnitud en Ridge):
relationship_Wife                    0.1626
occupation_Exec-managerial           0.1189
marital-status_Married-civ-spouse    0.1118
occupation_Farming-fishing           0.1007
education_Doctorate                  0.0850
education_Prof-school                0.0846
workclass_Federal-gov                0.0838
education-num                        0.0769
education_Preschool                  0.0759
relationship_Not-in-family           0.0695
Name: Ridge, dtype: float64

```


---

9. [Secci√≥n 9](#ch9)


<a id='ch9'></a>

### **An√°lisis de los Coeficientes del Modelo**

Los resultados de esta fase son cruciales, ya que nos permiten ir m√°s all√° del rendimiento predictivo para entender **c√≥mo** funcionan los modelos y **qu√©** caracter√≠sticas consideran importantes. El an√°lisis revela dos hallazgos principales: el impacto diferencial de cada t√©cnica de regularizaci√≥n y la identificaci√≥n de los factores clave que predicen el ingreso.

---

### 1. El Efecto de la Regularizaci√≥n en la Complejidad del Modelo (Sparsity)

Este an√°lisis demuestra visualmente la diferencia te√≥rica fundamental entre las penalizaciones L1 y L2.

* **Ridge (0.0% de caracter√≠sticas eliminadas)**: El resultado es el esperado. La regularizaci√≥n Ridge **ha mantenido las 105 caracter√≠sticas** del modelo. Su estrategia no es eliminar variables, sino reducir la magnitud de sus coeficientes para minimizar la complejidad. Ridge opera bajo la premisa de que todas las caracter√≠sticas aportan alguna informaci√≥n y prefiere "atenuar" su influencia en lugar de silenciarlas por completo.

* **Lasso (45.7% de caracter√≠sticas eliminadas)**: Aqu√≠ se observa el poder de la regularizaci√≥n L1. El modelo Lasso ha realizado una **selecci√≥n autom√°tica de caracter√≠sticas**, eliminando 48 de las 105 variables (casi la mitad). Esto crea un modelo mucho m√°s simple o "disperso" (sparse). La implicaci√≥n es que, seg√∫n Lasso, casi la mitad de las caracter√≠sticas son redundantes o no aportan suficiente valor predictivo como para justificar su inclusi√≥n, lo que simplifica enormemente la interpretaci√≥n del modelo. üß†

* **Elastic Net (42.9% de caracter√≠sticas eliminadas)**: Como era de esperar, Elastic Net se sit√∫a en un punto intermedio. Al ser una combinaci√≥n que en nuestro caso favorec√≠a a Ridge (90% L2), fue ligeramente menos agresivo que Lasso en la eliminaci√≥n de caracter√≠sticas, descartando 45 en lugar de 48. Esto confirma su naturaleza h√≠brida y su capacidad para equilibrar ambos tipos de regularizaci√≥n.

---

### 2. Identificaci√≥n de las Caracter√≠sticas M√°s Influyentes

La lista de las 10 caracter√≠sticas con mayor magnitud de coeficiente en el modelo Ridge nos indica cu√°les son los predictores m√°s potentes del nivel de ingresos. Podemos agruparlos l√≥gicamente:

* **Estado Civil como Predictor Dominante**: Las caracter√≠sticas `relationship_Wife` y `marital-status_Married-civ-spouse` aparecen en la cima de la lista. Esto indica que el estado civil, y espec√≠ficamente estar en un matrimonio civil, es uno de los predictores positivos m√°s fuertes de tener ingresos superiores a $50K.

* **El Valor de la Educaci√≥n y la Ocupaci√≥n**: Como es l√≥gico, un alto nivel educativo (`education_Doctorate`, `education_Prof-school`) y el n√∫mero de a√±os de educaci√≥n (`education-num`) son factores clave. De igual manera, ocupar puestos de alta responsabilidad (`occupation_Exec-managerial`) o trabajar para el gobierno (`workclass_Federal-gov`) tambi√©n son predictores positivos importantes.

* **Observaciones de Inter√©s**: La alta ponderaci√≥n de `occupation_Farming-fishing` es un hallazgo interesante que podr√≠a merecer un an√°lisis m√°s profundo. Del mismo modo, `education_Preschool` es una anomal√≠a; su alta magnitud es estad√≠sticamente significativa para el modelo, pero su interpretaci√≥n pr√°ctica es contraintuitiva y podr√≠a ser un artefacto de los datos o representar un subgrupo muy espec√≠fico.
---
Este an√°lisis de coeficientes es sumamente valioso. Nos ha permitido:
1.  **Verificar emp√≠ricamente** el comportamiento te√≥rico de las regularizaciones Ridge (encogimiento) y Lasso (selecci√≥n).
2.  **Simplificar el problema** al identificar que casi la mitad de las caracter√≠sticas podr√≠an ser eliminadas sin una p√©rdida significativa de rendimiento.
3.  **Validar la l√≥gica del modelo**, ya que las caracter√≠sticas que identifica como m√°s importantes (estado civil, educaci√≥n, tipo de empleo) se alinean perfectamente con el conocimiento del dominio y la intuici√≥n del mundo real. ‚úÖ


---

10. [Secci√≥n 10](#ch10)


<a id='ch10'></a>

## 5\. Visualizaci√≥n Comparativa

Una imagen vale m√°s que mil n√∫meros. Las visualizaciones nos permitir√°n comprender de forma intuitiva las diferencias fundamentales entre los modelos. Crearemos un panel de control `2x2` para resumir nuestros hallazgos.

**L√≥gica y Teor√≠a de las Visualizaciones:**

1.  **Comparaci√≥n de MSE y R¬≤:** Estos gr√°ficos de barras nos permiten ver r√°pidamente cu√°l modelo tuvo el mejor rendimiento predictivo. Son la validaci√≥n visual de nuestra tabla de resultados.
2.  **Comparaci√≥n de Coeficientes:** Este gr√°fico es clave. Visualiza la magnitud de los coeficientes para las caracter√≠sticas m√°s importantes. Aqu√≠ veremos claramente c√≥mo Lasso "apaga" algunas caracter√≠sticas (barras en cero), mientras que Ridge simplemente las "aten√∫a" (barras m√°s peque√±as pero no nulas).
3.  **Distribuci√≥n de Magnitudes de Coeficientes:** Este histograma es una visualizaci√≥n m√°s avanzada que muestra el comportamiento agregado de la regularizaci√≥n. Para Lasso, esperamos ver una gran acumulaci√≥n de coeficientes en cero, demostrando su tendencia a la dispersi√≥n. Para Ridge, esperamos una distribuci√≥n m√°s parecida a una campana centrada en cero, pero sin una gran espiga en el cero exacto, ilustrando su efecto de "encogimiento".




---

```python
# =============================================================================
# 7. GENERACI√ìN DE VISUALIZACIONES
# =============================================================================
print("\n5. GENERANDO VISUALIZACIONES...")
print("-" * 33)

# Configurar estilo m√°s limpio
plt.rcParams.update({'font.size': 11, 'axes.labelsize': 12, 'axes.titlesize': 14})
fig, axes = plt.subplots(2, 2, figsize=(16, 10))
fig.suptitle('An√°lisis Comparativo de Modelos de Regresi√≥n con Regularizaci√≥n',
             fontsize=16, fontweight='bold', y=0.98)

# Paleta de colores profesional
colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']

# 1. Comparaci√≥n de MSE - m√°s limpio
ax1 = axes[0, 0]
model_names = ['Linear\nRegression', 'Ridge', 'Lasso', 'Elastic Net']
mse_values = [results_df[results_df['Modelo'] == name.replace('\n', ' ')]['MSE'].iloc[0]
              if '\n' in name else results_df[results_df['Modelo'] == name]['MSE'].iloc[0]
              for name in model_names]

bars1 = ax1.bar(model_names, mse_values, color=colors, alpha=0.8, edgecolor='white', linewidth=1.5)
ax1.set_title('Error Cuadr√°tico Medio (MSE)', fontweight='bold', pad=15)
ax1.set_ylabel('MSE (menor es mejor)')
ax1.grid(axis='y', alpha=0.3, linestyle='--')
ax1.set_ylim(0, max(mse_values) * 1.1)

# Etiquetas m√°s elegantes
for bar, value in zip(bars1, mse_values):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mse_values)*0.02,
             f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=10)

# 2. R¬≤ Score - m√°s limpio
ax2 = axes[0, 1]
r2_values = [results_df[results_df['Modelo'] == name.replace('\n', ' ')]['R¬≤ Score'].iloc[0]
             if '\n' in name else results_df[results_df['Modelo'] == name]['R¬≤ Score'].iloc[0]
             for name in model_names]

bars2 = ax2.bar(model_names, r2_values, color=colors, alpha=0.8, edgecolor='white', linewidth=1.5)
ax2.set_title('R¬≤ Score (Coeficiente de Determinaci√≥n)', fontweight='bold', pad=15)
ax2.set_ylabel('R¬≤ Score (mayor es mejor)')
ax2.grid(axis='y', alpha=0.3, linestyle='--')
ax2.set_ylim(0, max(r2_values) * 1.1)

for bar, value in zip(bars2, r2_values):
    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(r2_values)*0.02,
             f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)

# 3. Top 10 coeficientes m√°s importantes (simplificado)
ax3 = axes[1, 0]
top_10_features = coef_df['Ridge'].abs().nlargest(10).index
plot_data = coef_df.loc[top_10_features, ['Ridge', 'Lasso', 'Elastic Net']]

# Simplificar nombres de caracter√≠sticas para mejor legibilidad
simplified_names = []
for name in top_10_features:
    if len(name) > 20:
        # Tomar las primeras palabras importantes
        parts = name.split('_')
        if len(parts) > 1:
            simplified_names.append(f"{parts[0]}_{parts[1][:8]}...")
        else:
            simplified_names.append(name[:15] + "...")
    else:
        simplified_names.append(name.replace('_', ' '))

x = np.arange(len(simplified_names))
width = 0.25

bars_ridge = ax3.bar(x - width, plot_data['Ridge'], width, label='Ridge',
                    alpha=0.8, color='#2E86AB', edgecolor='white')
bars_lasso = ax3.bar(x, plot_data['Lasso'], width, label='Lasso',
                    alpha=0.8, color='#A23B72', edgecolor='white')
bars_elastic = ax3.bar(x + width, plot_data['Elastic Net'], width, label='Elastic Net',
                      alpha=0.8, color='#F18F01', edgecolor='white')

ax3.set_title('Top 10 Caracter√≠sticas m√°s Importantes (en Ridge)', fontweight='bold', pad=15)
ax3.set_ylabel('Magnitud del Coeficiente')
ax3.set_xticks(x)
ax3.set_xticklabels(simplified_names, rotation=45, ha='right', fontsize=9)
ax3.legend(loc='upper right', framealpha=0.9)
ax3.grid(axis='y', alpha=0.3, linestyle='--')

# 4. N√∫mero de caracter√≠sticas eliminadas (m√°s informativo)
ax4 = axes[1, 1]
zero_counts = []
model_names_reg = ['Ridge', 'Lasso', 'Elastic Net']
colors_reg = ['#2E86AB', '#A23B72', '#F18F01']

for name in model_names_reg:
    if name in coefficients:
        zero_coef = np.sum(np.abs(coefficients[name]) < 1e-6)
        total_coef = len(coefficients[name])
        zero_counts.append(zero_coef)

bars4 = ax4.bar(model_names_reg, zero_counts, color=colors_reg, alpha=0.8,
                edgecolor='white', linewidth=1.5)
ax4.set_title('Caracter√≠sticas Eliminadas por Regularizaci√≥n', fontweight='bold', pad=15)
ax4.set_ylabel('N√∫mero de Coeficientes = 0')
ax4.grid(axis='y', alpha=0.3, linestyle='--')

# A√±adir porcentajes
total_features = len(coefficients['Ridge']) if 'Ridge' in coefficients else 0
for bar, count in zip(bars4, zero_counts):
    percentage = (count / total_features) * 100 if total_features > 0 else 0
    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(zero_counts)*0.02,
             f'{count}\n({percentage:.1f}%)', ha='center', va='bottom',
             fontweight='bold', fontsize=10)

# Ajustar espaciado
plt.tight_layout(rect=[0, 0.02, 1, 0.96])
plt.subplots_adjust(hspace=0.35, wspace=0.3)
plt.show()
```

```

5. GENERANDO VISUALIZACIONES...
---------------------------------

```

![Generated Image](image_placeholder.png)


---

11. [Secci√≥n 11](#ch11)


<a id='ch11'></a>

### **An√°lisis  del Dashboard Comparativo de Modelos**

Este panel de control visual ofrece una narrativa completa y clara del experimento. La conclusi√≥n principal es que, si bien el **rendimiento predictivo final de los modelos es id√©ntico**, su **complejidad interna y su enfoque para resolver el problema son dr√°sticamente diferentes**.

---

### 1. El Veredicto del Rendimiento: Un Empate T√©cnico (Gr√°ficos Superiores)

Los dos gr√°ficos superiores, **"Error Cuadr√°tico Medio (MSE)"** y **"R¬≤ Score"**, cuentan la misma historia:

* **Rendimiento Indistinguible**: Todos los modelos, desde la Regresi√≥n Lineal base hasta las versiones regularizadas, convergen en un **MSE de 0.1168** y un **R¬≤ Score de ~0.36**. Visualmente, las barras son id√©nticas, lo que subraya que no hay un ganador en t√©rminos de precisi√≥n predictiva.
* **Techo de Rendimiento Lineal**: Esto confirma que la regularizaci√≥n no mejor√≥ la capacidad de generalizaci√≥n del modelo en este caso. El problema no era el sobreajuste, sino que la familia de modelos lineales ha alcanzado su m√°ximo potencial con estos datos, explicando un modesto 36% de la variabilidad del ingreso.

---

### 2. La Historia Interna: Complejidad e Importancia (Gr√°ficos Inferiores)

Aqu√≠ es donde se revelan las diferencias cruciales y el verdadero valor del an√°lisis.

* **La Evidencia de la Sparsity (Gr√°fico "Caracter√≠sticas Eliminadas")**: Este es el gr√°fico m√°s elocuente del panel.
    * **Ridge (0% eliminado)**: Act√∫a como se esperaba, conservando todas las caracter√≠sticas y simplemente moderando su influencia.
    * **Lasso (45.7% eliminado)**: Demuestra su poder como una herramienta de **selecci√≥n autom√°tica de caracter√≠sticas**. Al eliminar casi la mitad de las variables, produce un modelo radicalmente m√°s simple e interpretable.
    * **Conclusi√≥n Visual**: Este gr√°fico ilustra perfectamente el compromiso fundamental: si el objetivo es la simplicidad y la identificaci√≥n de los predictores m√°s esenciales, Lasso es la elecci√≥n obvia.

* **El Perfil de los Coeficientes (Gr√°fico "Top 10 Caracter√≠sticas")**: Este gr√°fico nos permite ver *c√≥mo* cada modelo "piensa".
    * **Diferentes Pesos**: Aunque el resultado final es el mismo, los modelos asignan pesos (magnitud de los coeficientes) diferentes a las caracter√≠sticas. Por ejemplo, en la caracter√≠stica `relationship_Wife`, Lasso le da una importancia mucho mayor que Ridge.
    * **Selecci√≥n en Acci√≥n**: Se puede ver claramente c√≥mo las barras de Lasso (moradas) a menudo son cero para caracter√≠sticas que los otros modelos s√≠ consideran, visualizando la selecci√≥n de variables en el contexto de las m√°s importantes.
    * **Validaci√≥n de la L√≥gica**: El gr√°fico confirma que los predictores m√°s importantes identificados (`relationship_Wife`, `occupation_Exec-managerial`, `education_Doctorate`) son l√≥gicos y consistentes con el conocimiento del mundo real.

### S√≠ntesis Final

El dashboard comunica brillantemente una lecci√≥n clave en machine learning: **el "qu√©" (rendimiento predictivo) puede ser id√©ntico, mientras que el "c√≥mo" (estructura interna del modelo) puede ser muy diferente.**

En este escenario, la elecci√≥n del modelo no se basar√≠a en la precisi√≥n, sino en los objetivos secundarios del proyecto:

* Para un **modelo simple, interpretable y f√°cil de explicar**, que utilice solo las se√±ales m√°s fuertes, **Lasso** es el ganador indiscutible. üèÜ
* Para un modelo que **conserve todas las variables originales** bajo la premisa de que todas pueden aportar informaci√≥n, **Ridge** ser√≠a la opci√≥n preferida.

En definitiva, la visualizaci√≥n no solo presenta los resultados, sino que act√∫a como una poderosa herramienta para la toma de decisiones, permitiendo al analista elegir el modelo que mejor se alinee con las necesidades del negocio m√°s all√° de la simple m√©trica de error.


---

12. [Secci√≥n 12](#ch12)


<a id='ch12'></a>

---
## 6\. Discusi√≥n Final

A continuaci√≥n, se presenta una discusi√≥n detallada sobre los resultados obtenidos, abordando la efectividad de las t√©cnicas de regularizaci√≥n, el proceso de selecci√≥n de variables y el impacto general en el modelo.

### ¬øCu√°l de las t√©cnicas de regularizaci√≥n (Lasso, Ridge o Elastic Net) fue m√°s efectiva?

Para responder esta pregunta, es crucial definir "efectividad" desde dos perspectivas: **precisi√≥n predictiva** e **interpretabilidad del modelo**.

1.  **En T√©rminos de Precisi√≥n Predictiva**: Ninguna t√©cnica fue superior. Nuestro an√°lisis demostr√≥ un **empate t√©cnico** entre todos los modelos, incluyendo la Regresi√≥n Lineal base. Todos alcanzaron un Error Cuadr√°tico Medio (MSE) de `0.1168` y un R¬≤ Score de `~0.36`. Esto indica que, para este dataset, la regularizaci√≥n no mejor√≥ la capacidad del modelo para hacer predicciones m√°s precisas en datos no vistos.

2.  **En T√©rminos de Simplicidad e Interpretabilidad**: Desde esta perspectiva, el **modelo Lasso fue, sin lugar a dudas, el m√°s efectivo** üèÜ. Logr√≥ el mismo rendimiento predictivo que los dem√°s, pero lo hizo utilizando solo 57 de las 105 caracter√≠sticas disponibles, eliminando casi la mitad de ellas. Esta reducci√≥n dr√°stica de la complejidad crea un modelo:
    * **M√°s Interpretable**: Es m√°s f√°cil para un analista entender y explicar un modelo que se basa en menos variables.
    * **M√°s Eficiente**: Requiere menos datos y es computacionalmente m√°s ligero.
    * **M√°s Enfocado**: Resalta las se√±ales predictivas m√°s fuertes y descarta el ruido.

**Conclusi√≥n**: Si el √∫nico objetivo fuera la precisi√≥n, no habr√≠a un ganador. Sin embargo, en un contexto de ciencia de datos real donde la simplicidad y la interpretabilidad son cruciales, **Lasso fue la t√©cnica m√°s valiosa y efectiva**.

---

### ¬øCu√°les variables se eliminaron en el modelo Lasso y por qu√©?

El modelo Lasso elimin√≥ **48 caracter√≠sticas**, lo que representa el 45.7% del total. Aunque no tenemos la lista completa de las variables descartadas, el mecanismo y la raz√≥n detr√°s de esta eliminaci√≥n son claros.

**El "porqu√©" de la eliminaci√≥n (La Penalizaci√≥n L1):**

La "magia" de Lasso reside en su t√©rmino de regularizaci√≥n, conocido como **penalizaci√≥n L1**, que suma el valor absoluto de todos los coeficientes ($\alpha \sum |\beta_j|$). Geom√©tricamente, esto crea una restricci√≥n con "esquinas" a lo largo de los ejes. Durante la optimizaci√≥n, el modelo busca el punto que minimiza el error tocando esta regi√≥n de restricci√≥n. Es muy probable que este punto de contacto ocurra en una de las esquinas, donde el valor del coeficiente de una o m√°s variables es **exactamente cero**.



Esta propiedad, conocida como **sparsity (dispersi√≥n)**, obliga al modelo a hacer una elecci√≥n: si una caracter√≠stica no es lo suficientemente predictiva para "pagar" el coste de su penalizaci√≥n, su coeficiente se reduce a cero y es efectivamente eliminada del modelo.

**¬øQu√© tipo de variables se eliminaron?**

Lasso tiende a eliminar variables que son:
* **Redundantes**: Si varias caracter√≠sticas contienen informaci√≥n similar (por ejemplo, diferentes categor√≠as de `marital-status` que no son `Married-civ-spouse`), Lasso tiende a quedarse con la m√°s fuerte y eliminar las dem√°s.
* **Con Bajo Poder Predictivo**: Caracter√≠sticas que tienen una correlaci√≥n muy d√©bil con la variable objetivo son las primeras candidatas a ser eliminadas, ya que su contribuci√≥n al modelo es m√≠nima.

En resumen, Lasso act√∫a como un filtro autom√°tico, conservando solo el subconjunto de caracter√≠sticas m√°s informativo y eficiente.

---

### ¬øC√≥mo impact√≥ la regularizaci√≥n en la complejidad del modelo y su capacidad para generalizar?

El impacto de la regularizaci√≥n fue significativo, aunque con matices importantes entre la complejidad y la generalizaci√≥n en este caso particular.

**Impacto en la Complejidad del Modelo:** üí°

La regularizaci√≥n tuvo un **impacto profundo y diferenciado** en la complejidad de los modelos:

* **Ridge**: Redujo la complejidad al **encoger la magnitud** de todos los 105 coeficientes. El modelo sigue utilizando todas las caracter√≠sticas, pero previene que alguna de ellas tenga una influencia desproporcionada.
* **Lasso y Elastic Net**: Redujeron la complejidad de una manera m√°s dr√°stica al **disminuir el n√∫mero de caracter√≠sticas activas**. Crearon modelos fundamentalmente m√°s simples, que dependen de menos de un 60% de las variables originales.

**Impacto en la Capacidad para Generalizar:** ‚öñÔ∏è

Aqu√≠ encontramos el resultado m√°s parad√≥jico de nuestro an√°lisis. Te√≥ricamente, el prop√≥sito principal de la regularizaci√≥n es mejorar la generalizaci√≥n (el rendimiento en datos no vistos) al reducir el sobreajuste.

Sin embargo, en este experimento, la regularizaci√≥n **no tuvo un impacto medible en la capacidad de generalizaci√≥n**. El rendimiento en el conjunto de prueba fue el mismo para los modelos regularizados y para el modelo base.

La raz√≥n m√°s probable es que el modelo de Regresi√≥n Lineal inicial **no sufr√≠a de sobreajuste (alta varianza), sino de subajuste (alto sesgo)**. Era demasiado simple para capturar los patrones no lineales del dataset. La regularizaci√≥n es una herramienta para combatir el sobreajuste; no puede solucionar un problema de subajuste. Por lo tanto, aunque redujo correctamente la complejidad, no pudo mejorar un rendimiento que ya estaba limitado por la propia naturaleza del modelo lineal.



---

[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos Avanzados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_6_Seleccion_Caracteristicas/README.md)
