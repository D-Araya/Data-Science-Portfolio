{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Construir un modelo de clasificaci칩n para predecir la probabilidad de diabetes en pacientes usando  el  conjunto  de  datos  Pima  Indians  Diabetes  Dataset,  aplicando  Grid  Search  y  Random  Search para optimizar el rendimiento del modelo y comparar sus resultados en t칠rminos de precisi칩n, F1-score y eficiencia computacional.\n",
        "----\n",
        "\n",
        "## 1\\. Carga y Exploraci칩n de Datos 游늵\n",
        "\n",
        "Primero, cargamos el conjunto de datos de diabetes de Pima Indians desde la URL https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv. Usamos la librer칤a **pandas** para leer el archivo CSV. Es crucial asignar nombres a las columnas, ya que el archivo original no los incluye. Luego, exploramos los datos para entender su estructura, los tipos de cada variable y sus estad칤sticas descriptivas b치sicas.\n",
        "\n",
        "#### Descripci칩n de las Variables:\n",
        "\n",
        "* **preg:** N칰mero de embarazos.\n",
        "* **plas:** Concentraci칩n de glucosa en plasma a las 2 horas en una prueba de tolerancia a la glucosa oral. Un valor alto es un indicador clave de diabetes.\n",
        "* **pres:** Presi칩n arterial diast칩lica (mm Hg). La hipertensi칩n a menudo se asocia con la diabetes.\n",
        "* **skin:** Grosor del pliegue cut치neo del tr칤ceps (mm). Puede indicar la adiposidad corporal.\n",
        "* **test:** Insulina s칠rica de 2 horas (mu U/ml). Niveles anormales de insulina est치n directamente relacionados con la diabetes.\n",
        "* **mass:** 칈ndice de Masa Corporal (IMC). La obesidad es un factor de riesgo importante para la diabetes tipo 2.\n",
        "* **pedi:** Funci칩n de pedigr칤 de diabetes. Proporciona una medida de la predisposici칩n gen칠tica a la diabetes.\n",
        "* **age:** Edad (a침os). El riesgo de diabetes tipo 2 aumenta con la edad.\n",
        "* **class:** Variable de clase (0 o 1). Indica si el paciente tiene diabetes (1) o no (0). Esta es nuestra variable objetivo.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "1uKVCyECnwGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci칩n de la librer칤a para manipulaci칩n de datos\n",
        "import pandas as pd\n",
        "\n",
        "# 1. CARGA Y EXPLORACI칍N DE DATOS\n",
        "\n",
        "# URL del conjunto de datos\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "# Nombres de las columnas seg칰n la descripci칩n del dataset\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "# Cargar los datos en un DataFrame de pandas\n",
        "data = pd.read_csv(url, header=None, names=column_names)\n",
        "\n",
        "# Mostrar las primeras 5 filas para una vista r치pida\n",
        "print(\"### 1. Carga y Exploraci칩n de Datos ###\")\n",
        "print(\"\\nPrimeras 5 filas del conjunto de datos:\")\n",
        "print(data.head())\n",
        "\n",
        "# Mostrar informaci칩n general (tipos de datos, valores no nulos)\n",
        "print(\"\\nInformaci칩n del conjunto de datos:\")\n",
        "data.info()\n",
        "\n",
        "# Mostrar estad칤sticas descriptivas (media, desviaci칩n est치ndar, etc.)\n",
        "print(\"\\nEstad칤sticas descriptivas:\")\n",
        "print(data.describe())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1. Carga y Exploraci칩n de Datos ###\n",
            "\n",
            "Primeras 5 filas del conjunto de datos:\n",
            "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
            "0     6   148    72    35     0  33.6  0.627   50      1\n",
            "1     1    85    66    29     0  26.6  0.351   31      0\n",
            "2     8   183    64     0     0  23.3  0.672   32      1\n",
            "3     1    89    66    23    94  28.1  0.167   21      0\n",
            "4     0   137    40    35   168  43.1  2.288   33      1\n",
            "\n",
            "Informaci칩n del conjunto de datos:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   preg    768 non-null    int64  \n",
            " 1   plas    768 non-null    int64  \n",
            " 2   pres    768 non-null    int64  \n",
            " 3   skin    768 non-null    int64  \n",
            " 4   test    768 non-null    int64  \n",
            " 5   mass    768 non-null    float64\n",
            " 6   pedi    768 non-null    float64\n",
            " 7   age     768 non-null    int64  \n",
            " 8   class   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "\n",
            "Estad칤sticas descriptivas:\n",
            "             preg        plas        pres        skin        test        mass  \\\n",
            "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
            "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
            "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
            "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
            "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
            "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
            "\n",
            "             pedi         age       class  \n",
            "count  768.000000  768.000000  768.000000  \n",
            "mean     0.471876   33.240885    0.348958  \n",
            "std      0.331329   11.760232    0.476951  \n",
            "min      0.078000   21.000000    0.000000  \n",
            "25%      0.243750   24.000000    0.000000  \n",
            "50%      0.372500   29.000000    0.000000  \n",
            "75%      0.626250   41.000000    1.000000  \n",
            "max      2.420000   81.000000    1.000000  \n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTv5FIhTnwGG",
        "outputId": "3acd0754-9873-43c5-a3b1-f55a46c1e71f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 2\\. Preprocesamiento de Datos 丘뙖잺\n",
        "\n",
        "Antes de entrenar el modelo, preparamos los datos.\n",
        "\n",
        "  * **Separaci칩n de Variables:** Dividimos el dataset en caracter칤sticas (`X`) y la variable objetivo (`y`).\n",
        "  * **Divisi칩n de Datos:** Particionamos los datos en un conjunto de entrenamiento (70%) y uno de prueba (30%). Usamos `random_state` para que esta divisi칩n sea siempre la misma y nuestros resultados sean reproducibles.\n",
        "  * **Escalado de Variables:** Aplicamos `StandardScaler` para estandarizar las caracter칤sticas num칠ricas. Esto es importante porque los algoritmos de Machine Learning funcionan mejor cuando las variables tienen una escala similar. Se ajusta el escalador **solo** con los datos de entrenamiento (`fit_transform`) y luego se aplica esa misma transformaci칩n a los datos de prueba (`transform`) para evitar la fuga de datos.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "ivnqAPepnwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci칩n de las herramientas de preprocesamiento y modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. PREPROCESAMIENTO\n",
        "\n",
        "# Separar las caracter칤sticas (X) y la variable objetivo (y)\n",
        "X = data.drop('class', axis=1)  # Todas las columnas excepto la clase\n",
        "y = data['class']              # Solo la columna de la clase\n",
        "\n",
        "# Dividir los datos: 70% para entrenamiento, 30% para prueba\n",
        "# random_state asegura que la divisi칩n sea reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar el escalador est치ndar\n",
        "scaler = StandardScaler()\n",
        "# Ajustar el escalador en los datos de entrenamiento y transformar ambos conjuntos\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n### 2. Preprocesamiento de Datos ###\")\n",
        "print(f\"Forma del conjunto de entrenamiento (X_train): {X_train_scaled.shape}\")\n",
        "print(f\"Forma del conjunto de prueba (X_test): {X_test_scaled.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 2. Preprocesamiento de Datos ###\n",
            "Forma del conjunto de entrenamiento (X_train): (537, 8)\n",
            "Forma del conjunto de prueba (X_test): (231, 8)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls2hTbNsnwGG",
        "outputId": "ad74b91b-f663-4c06-80f2-1432c4dcf5c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 3\\. Modelo Base 游꿢\n",
        "\n",
        "Creamos y evaluamos un modelo `RandomForestClassifier` sin ning칰n tipo de optimizaci칩n, usando sus hiperpar치metros por defecto. Esto nos sirve como un punto de referencia (baseline) para comparar los resultados de los modelos optimizados. Lo evaluamos con m칠tricas clave:\n",
        "\n",
        "  * **Accuracy:** Porcentaje de predicciones correctas.\n",
        "  * **Recall (Sensibilidad):** Capacidad del modelo para encontrar todos los casos positivos.\n",
        "  * **F1-Score:** Media arm칩nica de precisi칩n y recall, 칰til en clases desbalanceadas.\n",
        "  * **AUC (츼rea bajo la curva ROC):** Mide la capacidad del modelo para distinguir entre clases.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "3FGKXG3HnwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci칩n del modelo y las m칠tricas de evaluaci칩n\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import time\n",
        "\n",
        "# 3. MODELO BASE\n",
        "\n",
        "# Inicializar el clasificador con par치metros por defecto\n",
        "base_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time_base = time.time()\n",
        "# Entrenar el modelo con los datos de entrenamiento escalados\n",
        "base_model.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalizaci칩n del entrenamiento\n",
        "end_time_base = time.time()\n",
        "# Calcular el tiempo total de entrenamiento\n",
        "training_time_base = end_time_base - start_time_base\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_base = base_model.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_base = base_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calcular las m칠tricas de evaluaci칩n /  Evaluar el rendimiento del modelo base\n",
        "accuracy_base = accuracy_score(y_test, y_pred_base)\n",
        "recall_base = recall_score(y_test, y_pred_base)\n",
        "f1_base = f1_score(y_test, y_pred_base)\n",
        "auc_base = roc_auc_score(y_test, y_prob_base)\n",
        "\n",
        "# Imprimir las m칠tricas de evaluaci칩n del modelo base\n",
        "print(\"\\n### 3. Resultados del Modelo Base ###\")\n",
        "print(f\"Accuracy: {accuracy_base:.4f}\")\n",
        "print(f\"Recall: {recall_base:.4f}\")\n",
        "print(f\"F1-Score: {f1_base:.4f}\")\n",
        "print(f\"AUC: {auc_base:.4f}\")\n",
        "print(f\"Tiempo de entrenamiento: {training_time_base:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificaci칩n del Modelo Base:\")\n",
        "print(classification_report(y_test, y_pred_base))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 3. Resultados del Modelo Base ###\n",
            "Accuracy: 0.7576\n",
            "Recall: 0.6625\n",
            "F1-Score: 0.6543\n",
            "AUC: 0.8046\n",
            "Tiempo de entrenamiento: 0.2123 segundos\n",
            "\n",
            "Reporte de Clasificaci칩n del Modelo Base:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.81       151\n",
            "           1       0.65      0.66      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.74      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1AL4zOHnwGH",
        "outputId": "4b10bdb8-94c8-4b89-ebb2-fc311282c702"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 4\\. Aplicar Grid Search\n",
        "\n",
        "**Grid Search** es una t칠cnica de optimizaci칩n que prueba de manera exhaustiva todas las combinaciones posibles de un conjunto de hiperpar치metros que le proporcionamos. Definimos una \"cuadr칤cula\" (`param_grid`) con los valores que queremos probar para `n_estimators`, `max_depth` y `min_samples_split`. `GridSearchCV` entrena un modelo para cada combinaci칩n usando validaci칩n cruzada (`cv=5`) y selecciona la que ofrece el mejor rendimiento."
      ],
      "metadata": {
        "id": "9rLOc80snwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci칩n de GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 4. APLICAR GRID SEARCH\n",
        "\n",
        "# Definir la cuadr칤cula de hiperpar치metros a probar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],      # N칰mero de 치rboles\n",
        "    'max_depth': [None, 10, 20],         # Profundidad m치xima de los 치rboles\n",
        "    'min_samples_split': [2, 5, 10]    # Muestras m칤nimas para dividir un nodo\n",
        "}\n",
        "\n",
        "# Inicializar GridSearchCV\n",
        "# n_jobs=-1 usa todos los n칰cleos de CPU para acelerar la b칰squeda\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Medir el tiempo de la b칰squeda\n",
        "start_time_grid = time.time()\n",
        "# Ejecutar la b칰squeda en los datos de entrenamiento\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalizaci칩n de la b칰squeda\n",
        "end_time_grid = time.time()\n",
        "# Calcular el tiempo total de la b칰squeda\n",
        "training_time_grid = end_time_grid - start_time_grid\n",
        "\n",
        "# Obtener los mejores hiperpar치metros encontrados\n",
        "best_params_grid = grid_search.best_params_\n",
        "# Obtener el mejor modelo encontrado por Grid Search\n",
        "best_model_grid = grid_search.best_estimator_\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el mejor modelo\n",
        "y_pred_grid = best_model_grid.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_grid = best_model_grid.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluar el rendimiento del modelo optimizado con Grid Search\n",
        "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
        "recall_grid = recall_score(y_test, y_pred_grid)\n",
        "f1_grid = f1_score(y_test, y_pred_grid)\n",
        "auc_grid = roc_auc_score(y_test, y_prob_grid)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 4. Resultados de Grid Search ###\")\n",
        "print(f\"Mejores Hiperpar치metros: {best_params_grid}\")\n",
        "print(f\"Accuracy: {accuracy_grid:.4f}\")\n",
        "print(f\"F1-Score: {f1_grid:.4f}\")\n",
        "print(f\"AUC: {auc_grid:.4f}\")\n",
        "print(f\"Tiempo de b칰squeda: {training_time_grid:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificaci칩n (Grid Search):\")\n",
        "print(classification_report(y_test, y_pred_grid))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 4. Resultados de Grid Search ###\n",
            "Mejores Hiperpar치metros: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Accuracy: 0.7576\n",
            "F1-Score: 0.6500\n",
            "AUC: 0.8046\n",
            "Tiempo de b칰squeda: 31.7483 segundos\n",
            "\n",
            "Reporte de Clasificaci칩n (Grid Search):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       151\n",
            "           1       0.65      0.65      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAIcDQlXnwGH",
        "outputId": "7f45a765-2687-4259-c2ad-fe709724ec61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 5\\. Aplicar Random Search 游쑆n",
        "\n",
        "A diferencia de Grid Search, **Random Search** no prueba todas las combinaciones, sino que selecciona un n칰mero fijo de combinaciones de hiperpar치metros (`n_iter`) de manera aleatoria a partir de un rango o distribuci칩n de valores. Esto la hace mucho m치s r치pida y eficiente, especialmente cuando el espacio de b칰squeda es grande. A menudo, encuentra modelos muy buenos (o incluso los mejores) en mucho menos tiempo."
      ],
      "metadata": {
        "id": "f3OVx0flnwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaci칩n de RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 5. APLICAR RANDOM SEARCH\n",
        "\n",
        "# Definir una distribuci칩n de hiperpar치metros (puede ser m치s amplia)\n",
        "param_dist = {\n",
        "    'n_estimators': range(50, 301, 50),\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Inicializar RandomizedSearchCV\n",
        "# n_iter=10 significa que probar치 10 combinaciones aleatorias\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=10,  # N칰mero de combinaciones de par치metros a probar\n",
        "                                   cv=5,\n",
        "                                   scoring='accuracy',\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Registrar el tiempo de inicio de la b칰squeda\n",
        "start_time_random = time.time()\n",
        "# Ejecutar la b칰squeda aleatoria en los datos de entrenamiento\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalizaci칩n de la b칰squeda\n",
        "end_time_random = time.time()\n",
        "# Calcular el tiempo total de la b칰squeda\n",
        "training_time_random = end_time_random - start_time_random\n",
        "\n",
        "# Obtener los mejores hiperpar치metros encontrados\n",
        "best_params_random = random_search.best_params_\n",
        "# Obtener el mejor modelo encontrado por Random Search\n",
        "best_model_random = random_search.best_estimator_\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el mejor modelo\n",
        "y_pred_random = best_model_random.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_random = best_model_random.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluar el rendimiento del modelo optimizado con Random Search\n",
        "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
        "recall_random = recall_score(y_test, y_pred_random)\n",
        "f1_random = f1_score(y_test, y_pred_random)\n",
        "auc_random = roc_auc_score(y_test, y_prob_random)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 5. Resultados de Random Search ###\")\n",
        "print(f\"Mejores Hiperpar치metros: {best_params_random}\")\n",
        "print(f\"Accuracy: {accuracy_random:.4f}\")\n",
        "print(f\"F1-Score: {f1_random:.4f}\")\n",
        "print(f\"AUC: {auc_random:.4f}\")\n",
        "print(f\"Tiempo de b칰squeda: {training_time_random:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificaci칩n (Random Search):\")\n",
        "print(classification_report(y_test, y_pred_random))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 5. Resultados de Random Search ###\n",
            "Mejores Hiperpar치metros: {'n_estimators': 250, 'min_samples_split': 2, 'max_depth': None}\n",
            "Accuracy: 0.7576\n",
            "F1-Score: 0.6500\n",
            "AUC: 0.8054\n",
            "Tiempo de b칰squeda: 24.9731 segundos\n",
            "\n",
            "Reporte de Clasificaci칩n (Random Search):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       151\n",
            "           1       0.65      0.65      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpoIexminwGH",
        "outputId": "f2749eff-ade8-4e31-9b69-967d06dd0787"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 6\\. Comparaci칩n y An치lisis 游늳\n",
        "\n",
        "Para facilitar la comparaci칩n, consolidamos las m칠tricas y los tiempos de entrenamiento de los tres modelos (Base, Grid Search y Random Search) en una tabla. Esto nos permite ver de un vistazo qu칠 t칠cnica ofreci칩 el mejor equilibrio entre rendimiento y costo computacional."
      ],
      "metadata": {
        "id": "3L-PZNunnwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. COMPARACI칍N Y AN츼LISIS\n",
        "\n",
        "# Crear un DataFrame para comparar los resultados de manera ordenada\n",
        "comparison_data = {\n",
        "    'Modelo': ['Base', 'Grid Search', 'Random Search'],\n",
        "    'Accuracy': [accuracy_base, accuracy_grid, accuracy_random],\n",
        "    'Recall': [recall_base, recall_grid, recall_random],\n",
        "    'F1-Score': [f1_base, f1_grid, f1_random],\n",
        "    'AUC': [auc_base, auc_grid, auc_random],\n",
        "    'Tiempo (s)': [training_time_base, training_time_grid, training_time_random]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data).round(4) # Redondear para mejor visualizaci칩n\n",
        "\n",
        "# Imprimir la tabla de comparaci칩n\n",
        "print(\"\\n### 6. Tabla de Comparaci칩n de Modelos ###\")\n",
        "print(comparison_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 6. Tabla de Comparaci칩n de Modelos ###\n",
            "          Modelo  Accuracy  Recall  F1-Score     AUC  Tiempo (s)\n",
            "0           Base    0.7576  0.6625    0.6543  0.8046      0.2123\n",
            "1    Grid Search    0.7576  0.6500    0.6500  0.8046     31.7483\n",
            "2  Random Search    0.7576  0.6500    0.6500  0.8054     24.9731\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT-x3a0inwGH",
        "outputId": "7191cd31-9abb-4771-eef5-5989d8f80cec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "## 7\\. Reflexi칩n Final 游\n",
        "\n",
        "#### **쮺u치l t칠cnica fue m치s eficiente? 丘뙖잺**\n",
        "\n",
        "La eficiencia se mide en t칠rminos de costo computacional, es decir, el **tiempo de ejecuci칩n**.\n",
        "\n",
        "* **Modelo Base:** Con un tiempo de solo **0.21 segundos**, fue, por un margen abrumador, el m칠todo m치s eficiente. Esto es l칩gico, ya que no realiza ninguna b칰squeda de hiperpar치metros; simplemente entrena el modelo una vez.\n",
        "* **Random Search:** Tard칩 **24.97 segundos** en ejecutarse.\n",
        "* **Grid Search:** Fue la t칠cnica m치s lenta, con un tiempo de **31.75 segundos**.\n",
        "\n",
        "**Conclusi칩n:** Entre las dos t칠cnicas de optimizaci칩n, **Random Search fue m치s eficiente que Grid Search**. Logr칩 un rendimiento pr치cticamente id칠ntico al de Grid Search pero en aproximadamente un 20% menos de tiempo, ya que eval칰a un subconjunto aleatorio de las combinaciones en lugar de probarlas todas exhaustivamente. Sin embargo, ninguna t칠cnica de optimizaci칩n se acerc칩 a la eficiencia del modelo base.\n",
        "\n",
        "---\n",
        "\n",
        "#### **쮺u치l encontr칩 el mejor modelo? 游끥**\n",
        "\n",
        "Este es el punto m치s interesante y revelador del an치lisis. Basado en las m칠tricas, el mejor modelo es, sorprendentemente, el **Modelo Base**.\n",
        "\n",
        "* **An치lisis de M칠tricas:**\n",
        "    * **Accuracy:** Las tres t칠cnicas arrojaron la misma exactitud (`0.7576`).\n",
        "    * **AUC:** Random Search (`0.8054`) fue marginalmente superior al Modelo Base y Grid Search (`0.8046`). Sin embargo, una diferencia tan min칰scula es, en la pr치ctica, estad칤sticamente insignificante.\n",
        "    * **F1-Score y Recall:** Aqu칤 es donde el Modelo Base demuestra su superioridad. Obtuvo un **F1-Score de 0.6543** y un **Recall de 0.6625**, ambos superiores a los `0.6500` que lograron tanto Grid Search como Random Search.\n",
        "\n",
        "**Conclusi칩n:** A pesar del tiempo y el c칩mputo invertido, **ninguna de las t칠cnicas de optimizaci칩n logr칩 encontrar una combinaci칩n de hiperpar치metros que superara al modelo con su configuraci칩n por defecto**. Esto no significa que la optimizaci칩n fall칩, sino que nos ense침a algo crucial: los par치metros predeterminados del `RandomForestClassifier` de Scikit-learn ya son muy robustos y estaban excepcionalmente bien adaptados para este problema en particular. Por lo tanto, considerando el equilibrio entre rendimiento (F1-Score/Recall) y simplicidad, **el Modelo Base es el ganador**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **쯈u칠 hubieras hecho diferente? 游뱂**\n",
        "\n",
        "El hecho de que el modelo base ganara es una oportunidad perfecta para refinar el proceso. Aqu칤 hay varias cosas que se podr칤an haber hecho de manera diferente:\n",
        "\n",
        "1.  **Revisar el Preprocesamiento de Datos:** Esta es la sospecha principal. El dataset de Pima Indians es conocido por tener valores \"cero\" en columnas donde es fisiol칩gicamente imposible (ej. `plas`, `pres`, `mass`). Si estos ceros no se trataron como datos faltantes (por ejemplo, reemplaz치ndolos con la media o la mediana de la columna), el modelo est치 aprendiendo de datos incorrectos. Un preprocesamiento m치s cuidadoso podr칤a haber creado una base de datos donde la optimizaci칩n s칤 encontrara mejoras significativas.\n",
        "\n",
        "2.  **Refinar el Espacio de B칰squeda:** El primer intento de b칰squeda de hiperpar치metros es a menudo una exploraci칩n amplia. Dado que el modelo base funcion칩 tan bien, un segundo paso l칩gico ser칤a realizar una b칰squeda mucho m치s **fina y acotada alrededor de los par치metros por defecto**. Por ejemplo, si el `n_estimators` por defecto es 100, en lugar de probar `[50, 100, 200]`, se podr칤a probar `[90, 100, 110, 120]` para buscar mejoras m치s sutiles.\n",
        "\n",
        "3.  **Experimentar con Otros Algoritmos:** Quiz치s `RandomForest` ya alcanz칩 su m치ximo potencial en este dataset. Se podr칤a haber experimentado con otros tipos de modelos que podr칤an ser m치s sensibles al ajuste de hiperpar치metros, como **XGBoost, LightGBM, o incluso un Support Vector Machine (SVM)**, para ver si ofrecen un rendimiento superior.\n",
        "\n",
        "4.  **Optimizar para una M칠trica Espec칤fica:** La b칰squeda se optimiz칩 para `accuracy` (seg칰n el c칩digo previo) o una m칠trica general. En un problema m칠dico como la detecci칩n de diabetes, minimizar los falsos negativos (pacientes con diabetes que no son detectados) es cr칤tico. Por lo tanto, se podr칤a haber configurado la b칰squeda para optimizar espec칤ficamente el **Recall** (`scoring='recall'`), lo que podr칤a haber llevado a un modelo diferente y m치s 칰til desde el punto de vista cl칤nico, aunque su `accuracy` general fuera menor."
      ],
      "metadata": {
        "id": "20fob8synwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-hIlinh3qPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}