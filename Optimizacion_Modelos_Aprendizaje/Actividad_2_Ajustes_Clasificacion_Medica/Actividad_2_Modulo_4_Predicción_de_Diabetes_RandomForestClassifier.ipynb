{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Construir un modelo de clasificación para predecir la probabilidad de diabetes en pacientes usando  el  conjunto  de  datos  Pima  Indians  Diabetes  Dataset,  aplicando  Grid  Search  y  Random  Search para optimizar el rendimiento del modelo y comparar sus resultados en términos de precisión, F1-score y eficiencia computacional.\n",
        "----\n",
        "\n",
        "## 1\\. Carga y Exploración de Datos 📊\n",
        "\n",
        "Primero, cargamos el conjunto de datos de diabetes de Pima Indians desde la URL https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv. Usamos la librería **pandas** para leer el archivo CSV. Es crucial asignar nombres a las columnas, ya que el archivo original no los incluye. Luego, exploramos los datos para entender su estructura, los tipos de cada variable y sus estadísticas descriptivas básicas.\n",
        "\n",
        "#### Descripción de las Variables:\n",
        "\n",
        "* **preg:** Número de embarazos.\n",
        "* **plas:** Concentración de glucosa en plasma a las 2 horas en una prueba de tolerancia a la glucosa oral. Un valor alto es un indicador clave de diabetes.\n",
        "* **pres:** Presión arterial diastólica (mm Hg). La hipertensión a menudo se asocia con la diabetes.\n",
        "* **skin:** Grosor del pliegue cutáneo del tríceps (mm). Puede indicar la adiposidad corporal.\n",
        "* **test:** Insulina sérica de 2 horas (mu U/ml). Niveles anormales de insulina están directamente relacionados con la diabetes.\n",
        "* **mass:** Índice de Masa Corporal (IMC). La obesidad es un factor de riesgo importante para la diabetes tipo 2.\n",
        "* **pedi:** Función de pedigrí de diabetes. Proporciona una medida de la predisposición genética a la diabetes.\n",
        "* **age:** Edad (años). El riesgo de diabetes tipo 2 aumenta con la edad.\n",
        "* **class:** Variable de clase (0 o 1). Indica si el paciente tiene diabetes (1) o no (0). Esta es nuestra variable objetivo.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "1uKVCyECnwGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de la librería para manipulación de datos\n",
        "import pandas as pd\n",
        "\n",
        "# 1. CARGA Y EXPLORACIÓN DE DATOS\n",
        "\n",
        "# URL del conjunto de datos\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "# Nombres de las columnas según la descripción del dataset\n",
        "column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "# Cargar los datos en un DataFrame de pandas\n",
        "data = pd.read_csv(url, header=None, names=column_names)\n",
        "\n",
        "# Mostrar las primeras 5 filas para una vista rápida\n",
        "print(\"### 1. Carga y Exploración de Datos ###\")\n",
        "print(\"\\nPrimeras 5 filas del conjunto de datos:\")\n",
        "print(data.head())\n",
        "\n",
        "# Mostrar información general (tipos de datos, valores no nulos)\n",
        "print(\"\\nInformación del conjunto de datos:\")\n",
        "data.info()\n",
        "\n",
        "# Mostrar estadísticas descriptivas (media, desviación estándar, etc.)\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "print(data.describe())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1. Carga y Exploración de Datos ###\n",
            "\n",
            "Primeras 5 filas del conjunto de datos:\n",
            "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
            "0     6   148    72    35     0  33.6  0.627   50      1\n",
            "1     1    85    66    29     0  26.6  0.351   31      0\n",
            "2     8   183    64     0     0  23.3  0.672   32      1\n",
            "3     1    89    66    23    94  28.1  0.167   21      0\n",
            "4     0   137    40    35   168  43.1  2.288   33      1\n",
            "\n",
            "Información del conjunto de datos:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   preg    768 non-null    int64  \n",
            " 1   plas    768 non-null    int64  \n",
            " 2   pres    768 non-null    int64  \n",
            " 3   skin    768 non-null    int64  \n",
            " 4   test    768 non-null    int64  \n",
            " 5   mass    768 non-null    float64\n",
            " 6   pedi    768 non-null    float64\n",
            " 7   age     768 non-null    int64  \n",
            " 8   class   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "\n",
            "Estadísticas descriptivas:\n",
            "             preg        plas        pres        skin        test        mass  \\\n",
            "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
            "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
            "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
            "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
            "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
            "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
            "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
            "\n",
            "             pedi         age       class  \n",
            "count  768.000000  768.000000  768.000000  \n",
            "mean     0.471876   33.240885    0.348958  \n",
            "std      0.331329   11.760232    0.476951  \n",
            "min      0.078000   21.000000    0.000000  \n",
            "25%      0.243750   24.000000    0.000000  \n",
            "50%      0.372500   29.000000    0.000000  \n",
            "75%      0.626250   41.000000    1.000000  \n",
            "max      2.420000   81.000000    1.000000  \n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTv5FIhTnwGG",
        "outputId": "3acd0754-9873-43c5-a3b1-f55a46c1e71f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 2\\. Preprocesamiento de Datos ⚙️\n",
        "\n",
        "Antes de entrenar el modelo, preparamos los datos.\n",
        "\n",
        "  * **Separación de Variables:** Dividimos el dataset en características (`X`) y la variable objetivo (`y`).\n",
        "  * **División de Datos:** Particionamos los datos en un conjunto de entrenamiento (70%) y uno de prueba (30%). Usamos `random_state` para que esta división sea siempre la misma y nuestros resultados sean reproducibles.\n",
        "  * **Escalado de Variables:** Aplicamos `StandardScaler` para estandarizar las características numéricas. Esto es importante porque los algoritmos de Machine Learning funcionan mejor cuando las variables tienen una escala similar. Se ajusta el escalador **solo** con los datos de entrenamiento (`fit_transform`) y luego se aplica esa misma transformación a los datos de prueba (`transform`) para evitar la fuga de datos.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "ivnqAPepnwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de las herramientas de preprocesamiento y modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. PREPROCESAMIENTO\n",
        "\n",
        "# Separar las características (X) y la variable objetivo (y)\n",
        "X = data.drop('class', axis=1)  # Todas las columnas excepto la clase\n",
        "y = data['class']              # Solo la columna de la clase\n",
        "\n",
        "# Dividir los datos: 70% para entrenamiento, 30% para prueba\n",
        "# random_state asegura que la división sea reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar el escalador estándar\n",
        "scaler = StandardScaler()\n",
        "# Ajustar el escalador en los datos de entrenamiento y transformar ambos conjuntos\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n### 2. Preprocesamiento de Datos ###\")\n",
        "print(f\"Forma del conjunto de entrenamiento (X_train): {X_train_scaled.shape}\")\n",
        "print(f\"Forma del conjunto de prueba (X_test): {X_test_scaled.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 2. Preprocesamiento de Datos ###\n",
            "Forma del conjunto de entrenamiento (X_train): (537, 8)\n",
            "Forma del conjunto de prueba (X_test): (231, 8)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls2hTbNsnwGG",
        "outputId": "ad74b91b-f663-4c06-80f2-1432c4dcf5c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 3\\. Modelo Base 🎯\n",
        "\n",
        "Creamos y evaluamos un modelo `RandomForestClassifier` sin ningún tipo de optimización, usando sus hiperparámetros por defecto. Esto nos sirve como un punto de referencia (baseline) para comparar los resultados de los modelos optimizados. Lo evaluamos con métricas clave:\n",
        "\n",
        "  * **Accuracy:** Porcentaje de predicciones correctas.\n",
        "  * **Recall (Sensibilidad):** Capacidad del modelo para encontrar todos los casos positivos.\n",
        "  * **F1-Score:** Media armónica de precisión y recall, útil en clases desbalanceadas.\n",
        "  * **AUC (Área bajo la curva ROC):** Mide la capacidad del modelo para distinguir entre clases.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "3FGKXG3HnwGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación del modelo y las métricas de evaluación\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import time\n",
        "\n",
        "# 3. MODELO BASE\n",
        "\n",
        "# Inicializar el clasificador con parámetros por defecto\n",
        "base_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time_base = time.time()\n",
        "# Entrenar el modelo con los datos de entrenamiento escalados\n",
        "base_model.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalización del entrenamiento\n",
        "end_time_base = time.time()\n",
        "# Calcular el tiempo total de entrenamiento\n",
        "training_time_base = end_time_base - start_time_base\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_base = base_model.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_base = base_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calcular las métricas de evaluación /  Evaluar el rendimiento del modelo base\n",
        "accuracy_base = accuracy_score(y_test, y_pred_base)\n",
        "recall_base = recall_score(y_test, y_pred_base)\n",
        "f1_base = f1_score(y_test, y_pred_base)\n",
        "auc_base = roc_auc_score(y_test, y_prob_base)\n",
        "\n",
        "# Imprimir las métricas de evaluación del modelo base\n",
        "print(\"\\n### 3. Resultados del Modelo Base ###\")\n",
        "print(f\"Accuracy: {accuracy_base:.4f}\")\n",
        "print(f\"Recall: {recall_base:.4f}\")\n",
        "print(f\"F1-Score: {f1_base:.4f}\")\n",
        "print(f\"AUC: {auc_base:.4f}\")\n",
        "print(f\"Tiempo de entrenamiento: {training_time_base:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificación del Modelo Base:\")\n",
        "print(classification_report(y_test, y_pred_base))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 3. Resultados del Modelo Base ###\n",
            "Accuracy: 0.7576\n",
            "Recall: 0.6625\n",
            "F1-Score: 0.6543\n",
            "AUC: 0.8046\n",
            "Tiempo de entrenamiento: 0.2123 segundos\n",
            "\n",
            "Reporte de Clasificación del Modelo Base:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.81       151\n",
            "           1       0.65      0.66      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.74      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1AL4zOHnwGH",
        "outputId": "4b10bdb8-94c8-4b89-ebb2-fc311282c702"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 4\\. Aplicar Grid Search\n",
        "\n",
        "**Grid Search** es una técnica de optimización que prueba de manera exhaustiva todas las combinaciones posibles de un conjunto de hiperparámetros que le proporcionamos. Definimos una \"cuadrícula\" (`param_grid`) con los valores que queremos probar para `n_estimators`, `max_depth` y `min_samples_split`. `GridSearchCV` entrena un modelo para cada combinación usando validación cruzada (`cv=5`) y selecciona la que ofrece el mejor rendimiento."
      ],
      "metadata": {
        "id": "9rLOc80snwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 4. APLICAR GRID SEARCH\n",
        "\n",
        "# Definir la cuadrícula de hiperparámetros a probar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],      # Número de árboles\n",
        "    'max_depth': [None, 10, 20],         # Profundidad máxima de los árboles\n",
        "    'min_samples_split': [2, 5, 10]    # Muestras mínimas para dividir un nodo\n",
        "}\n",
        "\n",
        "# Inicializar GridSearchCV\n",
        "# n_jobs=-1 usa todos los núcleos de CPU para acelerar la búsqueda\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Medir el tiempo de la búsqueda\n",
        "start_time_grid = time.time()\n",
        "# Ejecutar la búsqueda en los datos de entrenamiento\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalización de la búsqueda\n",
        "end_time_grid = time.time()\n",
        "# Calcular el tiempo total de la búsqueda\n",
        "training_time_grid = end_time_grid - start_time_grid\n",
        "\n",
        "# Obtener los mejores hiperparámetros encontrados\n",
        "best_params_grid = grid_search.best_params_\n",
        "# Obtener el mejor modelo encontrado por Grid Search\n",
        "best_model_grid = grid_search.best_estimator_\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el mejor modelo\n",
        "y_pred_grid = best_model_grid.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_grid = best_model_grid.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluar el rendimiento del modelo optimizado con Grid Search\n",
        "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
        "recall_grid = recall_score(y_test, y_pred_grid)\n",
        "f1_grid = f1_score(y_test, y_pred_grid)\n",
        "auc_grid = roc_auc_score(y_test, y_prob_grid)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 4. Resultados de Grid Search ###\")\n",
        "print(f\"Mejores Hiperparámetros: {best_params_grid}\")\n",
        "print(f\"Accuracy: {accuracy_grid:.4f}\")\n",
        "print(f\"F1-Score: {f1_grid:.4f}\")\n",
        "print(f\"AUC: {auc_grid:.4f}\")\n",
        "print(f\"Tiempo de búsqueda: {training_time_grid:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificación (Grid Search):\")\n",
        "print(classification_report(y_test, y_pred_grid))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 4. Resultados de Grid Search ###\n",
            "Mejores Hiperparámetros: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Accuracy: 0.7576\n",
            "F1-Score: 0.6500\n",
            "AUC: 0.8046\n",
            "Tiempo de búsqueda: 31.7483 segundos\n",
            "\n",
            "Reporte de Clasificación (Grid Search):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       151\n",
            "           1       0.65      0.65      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAIcDQlXnwGH",
        "outputId": "7f45a765-2687-4259-c2ad-fe709724ec61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 5\\. Aplicar Random Search 🎲\n",
        "\n",
        "A diferencia de Grid Search, **Random Search** no prueba todas las combinaciones, sino que selecciona un número fijo de combinaciones de hiperparámetros (`n_iter`) de manera aleatoria a partir de un rango o distribución de valores. Esto la hace mucho más rápida y eficiente, especialmente cuando el espacio de búsqueda es grande. A menudo, encuentra modelos muy buenos (o incluso los mejores) en mucho menos tiempo."
      ],
      "metadata": {
        "id": "f3OVx0flnwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 5. APLICAR RANDOM SEARCH\n",
        "\n",
        "# Definir una distribución de hiperparámetros (puede ser más amplia)\n",
        "param_dist = {\n",
        "    'n_estimators': range(50, 301, 50),\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10, 15]\n",
        "}\n",
        "\n",
        "# Inicializar RandomizedSearchCV\n",
        "# n_iter=10 significa que probará 10 combinaciones aleatorias\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=10,  # Número de combinaciones de parámetros a probar\n",
        "                                   cv=5,\n",
        "                                   scoring='accuracy',\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=42)\n",
        "\n",
        "# Registrar el tiempo de inicio de la búsqueda\n",
        "start_time_random = time.time()\n",
        "# Ejecutar la búsqueda aleatoria en los datos de entrenamiento\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "# Registrar el tiempo de finalización de la búsqueda\n",
        "end_time_random = time.time()\n",
        "# Calcular el tiempo total de la búsqueda\n",
        "training_time_random = end_time_random - start_time_random\n",
        "\n",
        "# Obtener los mejores hiperparámetros encontrados\n",
        "best_params_random = random_search.best_params_\n",
        "# Obtener el mejor modelo encontrado por Random Search\n",
        "best_model_random = random_search.best_estimator_\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba con el mejor modelo\n",
        "y_pred_random = best_model_random.predict(X_test_scaled)\n",
        "# Predecir las probabilidades para calcular el AUC\n",
        "y_prob_random = best_model_random.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluar el rendimiento del modelo optimizado con Random Search\n",
        "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
        "recall_random = recall_score(y_test, y_pred_random)\n",
        "f1_random = f1_score(y_test, y_pred_random)\n",
        "auc_random = roc_auc_score(y_test, y_prob_random)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 5. Resultados de Random Search ###\")\n",
        "print(f\"Mejores Hiperparámetros: {best_params_random}\")\n",
        "print(f\"Accuracy: {accuracy_random:.4f}\")\n",
        "print(f\"F1-Score: {f1_random:.4f}\")\n",
        "print(f\"AUC: {auc_random:.4f}\")\n",
        "print(f\"Tiempo de búsqueda: {training_time_random:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificación (Random Search):\")\n",
        "print(classification_report(y_test, y_pred_random))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 5. Resultados de Random Search ###\n",
            "Mejores Hiperparámetros: {'n_estimators': 250, 'min_samples_split': 2, 'max_depth': None}\n",
            "Accuracy: 0.7576\n",
            "F1-Score: 0.6500\n",
            "AUC: 0.8054\n",
            "Tiempo de búsqueda: 24.9731 segundos\n",
            "\n",
            "Reporte de Clasificación (Random Search):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       151\n",
            "           1       0.65      0.65      0.65        80\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.76      0.76      0.76       231\n",
            "\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpoIexminwGH",
        "outputId": "f2749eff-ade8-4e31-9b69-967d06dd0787"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## 6\\. Comparación y Análisis 📈\n",
        "\n",
        "Para facilitar la comparación, consolidamos las métricas y los tiempos de entrenamiento de los tres modelos (Base, Grid Search y Random Search) en una tabla. Esto nos permite ver de un vistazo qué técnica ofreció el mejor equilibrio entre rendimiento y costo computacional."
      ],
      "metadata": {
        "id": "3L-PZNunnwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. COMPARACIÓN Y ANÁLISIS\n",
        "\n",
        "# Crear un DataFrame para comparar los resultados de manera ordenada\n",
        "comparison_data = {\n",
        "    'Modelo': ['Base', 'Grid Search', 'Random Search'],\n",
        "    'Accuracy': [accuracy_base, accuracy_grid, accuracy_random],\n",
        "    'Recall': [recall_base, recall_grid, recall_random],\n",
        "    'F1-Score': [f1_base, f1_grid, f1_random],\n",
        "    'AUC': [auc_base, auc_grid, auc_random],\n",
        "    'Tiempo (s)': [training_time_base, training_time_grid, training_time_random]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data).round(4) # Redondear para mejor visualización\n",
        "\n",
        "# Imprimir la tabla de comparación\n",
        "print(\"\\n### 6. Tabla de Comparación de Modelos ###\")\n",
        "print(comparison_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 6. Tabla de Comparación de Modelos ###\n",
            "          Modelo  Accuracy  Recall  F1-Score     AUC  Tiempo (s)\n",
            "0           Base    0.7576  0.6625    0.6543  0.8046      0.2123\n",
            "1    Grid Search    0.7576  0.6500    0.6500  0.8046     31.7483\n",
            "2  Random Search    0.7576  0.6500    0.6500  0.8054     24.9731\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT-x3a0inwGH",
        "outputId": "7191cd31-9abb-4771-eef5-5989d8f80cec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "## 7\\. Reflexión Final 🧠\n",
        "\n",
        "#### **¿Cuál técnica fue más eficiente? ⚙️**\n",
        "\n",
        "La eficiencia se mide en términos de costo computacional, es decir, el **tiempo de ejecución**.\n",
        "\n",
        "* **Modelo Base:** Con un tiempo de solo **0.21 segundos**, fue, por un margen abrumador, el método más eficiente. Esto es lógico, ya que no realiza ninguna búsqueda de hiperparámetros; simplemente entrena el modelo una vez.\n",
        "* **Random Search:** Tardó **24.97 segundos** en ejecutarse.\n",
        "* **Grid Search:** Fue la técnica más lenta, con un tiempo de **31.75 segundos**.\n",
        "\n",
        "**Conclusión:** Entre las dos técnicas de optimización, **Random Search fue más eficiente que Grid Search**. Logró un rendimiento prácticamente idéntico al de Grid Search pero en aproximadamente un 20% menos de tiempo, ya que evalúa un subconjunto aleatorio de las combinaciones en lugar de probarlas todas exhaustivamente. Sin embargo, ninguna técnica de optimización se acercó a la eficiencia del modelo base.\n",
        "\n",
        "---\n",
        "\n",
        "#### **¿Cuál encontró el mejor modelo? 🏆**\n",
        "\n",
        "Este es el punto más interesante y revelador del análisis. Basado en las métricas, el mejor modelo es, sorprendentemente, el **Modelo Base**.\n",
        "\n",
        "* **Análisis de Métricas:**\n",
        "    * **Accuracy:** Las tres técnicas arrojaron la misma exactitud (`0.7576`).\n",
        "    * **AUC:** Random Search (`0.8054`) fue marginalmente superior al Modelo Base y Grid Search (`0.8046`). Sin embargo, una diferencia tan minúscula es, en la práctica, estadísticamente insignificante.\n",
        "    * **F1-Score y Recall:** Aquí es donde el Modelo Base demuestra su superioridad. Obtuvo un **F1-Score de 0.6543** y un **Recall de 0.6625**, ambos superiores a los `0.6500` que lograron tanto Grid Search como Random Search.\n",
        "\n",
        "**Conclusión:** A pesar del tiempo y el cómputo invertido, **ninguna de las técnicas de optimización logró encontrar una combinación de hiperparámetros que superara al modelo con su configuración por defecto**. Esto no significa que la optimización falló, sino que nos enseña algo crucial: los parámetros predeterminados del `RandomForestClassifier` de Scikit-learn ya son muy robustos y estaban excepcionalmente bien adaptados para este problema en particular. Por lo tanto, considerando el equilibrio entre rendimiento (F1-Score/Recall) y simplicidad, **el Modelo Base es el ganador**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **¿Qué hubieras hecho diferente? 🤔**\n",
        "\n",
        "El hecho de que el modelo base ganara es una oportunidad perfecta para refinar el proceso. Aquí hay varias cosas que se podrían haber hecho de manera diferente:\n",
        "\n",
        "1.  **Revisar el Preprocesamiento de Datos:** Esta es la sospecha principal. El dataset de Pima Indians es conocido por tener valores \"cero\" en columnas donde es fisiológicamente imposible (ej. `plas`, `pres`, `mass`). Si estos ceros no se trataron como datos faltantes (por ejemplo, reemplazándolos con la media o la mediana de la columna), el modelo está aprendiendo de datos incorrectos. Un preprocesamiento más cuidadoso podría haber creado una base de datos donde la optimización sí encontrara mejoras significativas.\n",
        "\n",
        "2.  **Refinar el Espacio de Búsqueda:** El primer intento de búsqueda de hiperparámetros es a menudo una exploración amplia. Dado que el modelo base funcionó tan bien, un segundo paso lógico sería realizar una búsqueda mucho más **fina y acotada alrededor de los parámetros por defecto**. Por ejemplo, si el `n_estimators` por defecto es 100, en lugar de probar `[50, 100, 200]`, se podría probar `[90, 100, 110, 120]` para buscar mejoras más sutiles.\n",
        "\n",
        "3.  **Experimentar con Otros Algoritmos:** Quizás `RandomForest` ya alcanzó su máximo potencial en este dataset. Se podría haber experimentado con otros tipos de modelos que podrían ser más sensibles al ajuste de hiperparámetros, como **XGBoost, LightGBM, o incluso un Support Vector Machine (SVM)**, para ver si ofrecen un rendimiento superior.\n",
        "\n",
        "4.  **Optimizar para una Métrica Específica:** La búsqueda se optimizó para `accuracy` (según el código previo) o una métrica general. En un problema médico como la detección de diabetes, minimizar los falsos negativos (pacientes con diabetes que no son detectados) es crítico. Por lo tanto, se podría haber configurado la búsqueda para optimizar específicamente el **Recall** (`scoring='recall'`), lo que podría haber llevado a un modelo diferente y más útil desde el punto de vista clínico, aunque su `accuracy` general fuera menor."
      ],
      "metadata": {
        "id": "20fob8synwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-hIlinh3qPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}