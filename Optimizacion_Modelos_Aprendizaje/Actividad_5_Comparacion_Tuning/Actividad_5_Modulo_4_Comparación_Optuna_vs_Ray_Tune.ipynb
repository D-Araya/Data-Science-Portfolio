{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Comparación de Estrategias de Tuning Automático: Optuna vs. Ray Tune**\n",
        "\n",
        "  * **Objetivo:** Aplicar y comparar las librerías **Optuna** y **Ray Tune** para optimizar los hiperparámetros de un modelo `RandomForestClassifier`. El rendimiento se evaluará sobre el conjunto de datos de Cáncer de Mama de Scikit-learn, utilizando el F1-score como métrica principal.\n",
        "  * **Modelo:** RandomForestClassifier\n",
        "  * **Dataset:** Breast Cancer Wisconsin (Diagnostic)\n",
        "  * **Métrica:** F1-Score\n",
        "\n",
        "-----\n",
        "\n",
        "### 1\\. Carga y Preprocesamiento de Datos 📊\n",
        "\n",
        "Primero, cargamos el conjunto de datos de cáncer de mama directamente desde `scikit-learn`. Este dataset contiene 569 muestras y 30 características numéricas. La tarea es clasificar los tumores como **malignos (0)** o **benignos (1)**.\n",
        "\n",
        "El preprocesamiento es un paso crucial:\n",
        "\n",
        "  * **Separación de Variables:** Dividimos el dataset en características (`X`) y la variable objetivo (`y`).\n",
        "  * **División de Datos:** Particionamos los datos en un conjunto de entrenamiento (70%) y uno de prueba (30%). Usamos `random_state` para asegurar la reproducibilidad de los resultados.\n",
        "  * **Escalado de Variables:** Aplicamos `StandardScaler` para estandarizar las características. Esto asegura que todas las variables tengan la misma escala (media 0 y desviación estándar 1), lo cual es fundamental para el rendimiento de muchos algoritmos de Machine Learning.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "1nEONCnQTa4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bPCCjGjzhBpI",
        "outputId": "bd433c29-63ab-4b4f-9045-b3304097c14d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[tune]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M_OqTcUxhInV",
        "outputId": "6e3ccc3b-2258-478d-99c4-881969aaa720"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray[tune]\n",
            "  Downloading ray-2.47.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (8.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (4.24.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.2.2)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (18.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2025.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.9->ray[tune]) (2.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2025.7.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.14.1)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.47.1-cp311-cp311-manylinux2014_x86_64.whl (68.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.47.1 tensorboardX-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importación de librerías necesarias\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import optuna\n",
        "import ray\n",
        "from ray import tune\n",
        "\n",
        "# 1. CARGA Y PREPROCESAMIENTO\n",
        "\n",
        "# Cargar el conjunto de datos de cáncer de mama\n",
        "cancer_dataset = load_breast_cancer()\n",
        "# Crear un DataFrame de pandas para facilitar la manipulación\n",
        "# Las características están en 'data' y los nombres de las columnas en 'feature_names'\n",
        "X = pd.DataFrame(cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
        "# La variable objetivo (0: maligno, 1: benigno) está en 'target'\n",
        "y = pd.Series(cancer_dataset.target)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento (70%) y prueba (30%)\n",
        "# random_state=42 asegura que la división sea siempre la misma para reproducibilidad\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar el escalador estándar\n",
        "scaler = StandardScaler()\n",
        "# Ajustar el escalador SÓLO con los datos de entrenamiento para evitar fuga de datos\n",
        "# y transformar el conjunto de entrenamiento\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Aplicar la MISMA transformación al conjunto de prueba\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"### 1. Carga y Preprocesamiento de Datos ###\")\n",
        "print(f\"Forma del conjunto de entrenamiento (X_train): {X_train_scaled.shape}\")\n",
        "print(f\"Forma del conjunto de prueba (X_test): {X_test_scaled.shape}\")\n",
        "print(\"\\nPrimeras 5 filas de datos (sin escalar):\")\n",
        "print(X.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1. Carga y Preprocesamiento de Datos ###\n",
            "Forma del conjunto de entrenamiento (X_train): (398, 30)\n",
            "Forma del conjunto de prueba (X_test): (171, 30)\n",
            "\n",
            "Primeras 5 filas de datos (sin escalar):\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyzeNdiVTa4j",
        "outputId": "1310a59c-c2f7-4190-b2e2-1217b1d01a32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 2\\. Modelo Base (Sin Tuning) 🎯\n",
        "\n",
        "Antes de aplicar técnicas de optimización, entrenamos un `RandomForestClassifier` con sus hiperparámetros por defecto. Este modelo nos servirá como **punto de referencia (baseline)** para medir si las técnicas de tuning realmente aportan una mejora. Evaluamos su rendimiento calculando el `f1_score`, una métrica robusta que balancea la precisión y el recall, ideal para problemas de clasificación."
      ],
      "metadata": {
        "id": "GhteXImdTa4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. MODELO BASE\n",
        "\n",
        "# Inicializar el clasificador con parámetros por defecto para reproducibilidad\n",
        "base_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time_base = time.time()\n",
        "# Entrenar el modelo con los datos de entrenamiento escalados\n",
        "base_model.fit(X_train_scaled, y_train)\n",
        "end_time_base = time.time()\n",
        "# Calcular el tiempo total de entrenamiento\n",
        "training_time_base = end_time_base - start_time_base\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_base = base_model.predict(X_test_scaled)\n",
        "\n",
        "# Calcular el F1-Score para evaluar el rendimiento\n",
        "f1_base = f1_score(y_test, y_pred_base)\n",
        "\n",
        "# Imprimir las métricas de evaluación del modelo base\n",
        "print(\"\\n### 2. Resultados del Modelo Base ###\")\n",
        "print(f\"F1-Score: {f1_base:.4f}\")\n",
        "print(f\"Tiempo de entrenamiento: {training_time_base:.4f} segundos\")\n",
        "print(\"\\nReporte de Clasificación del Modelo Base:\")\n",
        "print(classification_report(y_test, y_pred_base))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 2. Resultados del Modelo Base ###\n",
            "F1-Score: 0.9772\n",
            "Tiempo de entrenamiento: 0.2771 segundos\n",
            "\n",
            "Reporte de Clasificación del Modelo Base:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jhm_JU7Ta4k",
        "outputId": "ea6325b3-60f3-4333-e5d5-51dc2a2670a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 3\\. Aplicación de Optuna 🔎\n",
        "\n",
        "**Optuna** es una librería de optimización de hiperparámetros moderna y fácil de usar. Su principal ventaja es su API pitónica y su capacidad para \"podar\" (pruning) de forma inteligente los *trials* (intentos) que no parecen prometedores.\n",
        "\n",
        "Definimos una función `objective` que Optuna intentará maximizar. Dentro de esta función:\n",
        "\n",
        "1.  **Definimos el espacio de búsqueda:** Indicamos a Optuna los rangos de valores para `n_estimators`, `max_depth` y `min_samples_split`.\n",
        "2.  **Entrenamos el modelo:** Se instancia un `RandomForestClassifier` con la combinación de hiperparámetros sugerida por el `trial`.\n",
        "3.  **Evaluamos y devolvemos el F1-Score:** Optuna usa este valor para decidir cómo continuar la búsqueda.\n",
        "\n",
        "Ejecutamos el estudio durante 20 `trials` para explorar el espacio de búsqueda."
      ],
      "metadata": {
        "id": "-Di7KmxJTa4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. APLICACIÓN DE OPTUNA\n",
        "\n",
        "# Definir la función objetivo que Optuna debe maximizar\n",
        "def objective(trial):\n",
        "    # Definir el espacio de búsqueda de hiperparámetros\n",
        "    # trial.suggest_int sugiere un entero dentro de un rango\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 400)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 15)\n",
        "\n",
        "    # Crear el modelo con los hiperparámetros sugeridos\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        random_state=42,\n",
        "        n_jobs=-1 # Usar todos los procesadores\n",
        "    )\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Realizar predicciones\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calcular y devolver el F1-Score\n",
        "    return f1_score(y_test, y_pred)\n",
        "\n",
        "# Medir el tiempo total de la búsqueda\n",
        "start_time_optuna = time.time()\n",
        "\n",
        "# Crear un estudio de Optuna para maximizar el F1-Score\n",
        "# La dirección 'maximize' indica que queremos el valor más alto posible para la función objetivo\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# Iniciar la optimización con 20 trials (20 combinaciones de hiperparámetros)\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "end_time_optuna = time.time()\n",
        "# Calcular el tiempo total de la búsqueda\n",
        "search_time_optuna = end_time_optuna - start_time_optuna\n",
        "\n",
        "# Obtener los mejores hiperparámetros encontrados\n",
        "best_params_optuna = study.best_params\n",
        "# Obtener el mejor F1-score obtenido durante la búsqueda\n",
        "best_f1_optuna = study.best_value\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 3. Resultados de Optuna ###\")\n",
        "print(f\"Mejores Hiperparámetros: {best_params_optuna}\")\n",
        "print(f\"Mejor F1-Score (en la búsqueda): {best_f1_optuna:.4f}\")\n",
        "print(f\"Tiempo de búsqueda: {search_time_optuna:.4f} segundos\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-15 01:40:18,772] A new study created in memory with name: no-name-168ba10a-61b4-4fbf-bcb6-7b56f78dbf87\n",
            "[I 2025-07-15 01:40:19,263] Trial 0 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 170, 'max_depth': 17, 'min_samples_split': 12}. Best is trial 0 with value: 0.9724770642201835.\n",
            "[I 2025-07-15 01:40:19,933] Trial 1 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 217, 'max_depth': 37, 'min_samples_split': 8}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:20,801] Trial 2 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 275, 'max_depth': 22, 'min_samples_split': 6}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:21,192] Trial 3 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 120, 'max_depth': 45, 'min_samples_split': 9}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:22,290] Trial 4 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 376, 'max_depth': 18, 'min_samples_split': 10}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:22,956] Trial 5 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 211, 'max_depth': 31, 'min_samples_split': 8}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:23,549] Trial 6 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 195, 'max_depth': 38, 'min_samples_split': 11}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:23,904] Trial 7 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 111, 'max_depth': 22, 'min_samples_split': 5}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:25,080] Trial 8 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 392, 'max_depth': 11, 'min_samples_split': 9}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:26,122] Trial 9 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 342, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:26,329] Trial 10 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 59, 'max_depth': 50, 'min_samples_split': 15}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:27,232] Trial 11 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 288, 'max_depth': 29, 'min_samples_split': 4}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:28,194] Trial 12 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 275, 'max_depth': 30, 'min_samples_split': 6}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:29,451] Trial 13 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 271, 'max_depth': 36, 'min_samples_split': 2}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:30,634] Trial 14 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 247, 'max_depth': 24, 'min_samples_split': 7}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:31,646] Trial 15 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 320, 'max_depth': 41, 'min_samples_split': 2}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:32,152] Trial 16 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 168, 'max_depth': 25, 'min_samples_split': 13}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:32,840] Trial 17 finished with value: 0.9724770642201835 and parameters: {'n_estimators': 235, 'max_depth': 35, 'min_samples_split': 4}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:33,796] Trial 18 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 315, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 1 with value: 0.9771689497716894.\n",
            "[I 2025-07-15 01:40:34,240] Trial 19 finished with value: 0.9771689497716894 and parameters: {'n_estimators': 139, 'max_depth': 43, 'min_samples_split': 6}. Best is trial 1 with value: 0.9771689497716894.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 3. Resultados de Optuna ###\n",
            "Mejores Hiperparámetros: {'n_estimators': 217, 'max_depth': 37, 'min_samples_split': 8}\n",
            "Mejor F1-Score (en la búsqueda): 0.9772\n",
            "Tiempo de búsqueda: 15.4700 segundos\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD_7z2erTa4k",
        "outputId": "4bf0c546-ccce-49bd-e195-e28246471199"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 4\\. Aplicación de Ray Tune ⚡\n",
        "\n",
        "**Ray Tune** es un framework de optimización de hiperparámetros diseñado para ser escalable y permitir la computación distribuida. Aunque su configuración inicial es un poco más compleja que la de Optuna, su poder reside en su capacidad para paralelizar la búsqueda en múltiples CPUs o incluso en un clúster de máquinas.\n",
        "\n",
        "El proceso es similar:\n",
        "\n",
        "1.  **Definir una función entrenable:** Esta función recibe un diccionario `config` con los hiperparámetros.\n",
        "2.  **Especificar el espacio de búsqueda:** Se crea un diccionario donde las llaves son los nombres de los hiperparámetros y los valores son distribuciones de Ray Tune (ej. `tune.randint`).\n",
        "3.  **Ejecutar la búsqueda:** `tune.run` gestiona la ejecución, probando 20 combinaciones (`num_samples`) y reportando el `f1_score` para maximizarlo.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "NUGovJx3Ta4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. APLICACIÓN DE RAY TUNE\n",
        "\n",
        "# Inicializar Ray (si ya está corriendo, no hace nada)\n",
        "ray.init(ignore_reinit_error=True, logging_level=30) # Reducir verbosidad\n",
        "\n",
        "# Definir la función entrenable que Ray Tune ejecutará\n",
        "def trainable_rf(config):\n",
        "    # Crear el modelo con los hiperparámetros del diccionario 'config'\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=config[\"n_estimators\"],\n",
        "        max_depth=config[\"max_depth\"],\n",
        "        min_samples_split=config[\"min_samples_split\"],\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # Entrenar el modelo\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    # Realizar predicciones\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    # Calcular el F1-Score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    # Reportar la métrica a Ray Tune\n",
        "    tune.report({\"f1_score\": f1})\n",
        "\n",
        "# Definir el espacio de búsqueda para Ray Tune\n",
        "# Es análogo al de Optuna, pero con la sintaxis de Ray\n",
        "search_space = {\n",
        "    \"n_estimators\": tune.randint(50, 401),\n",
        "    \"max_depth\": tune.randint(10, 51),\n",
        "    \"min_samples_split\": tune.randint(2, 16)\n",
        "}\n",
        "\n",
        "# Medir el tiempo total de la búsqueda\n",
        "start_time_ray = time.time()\n",
        "\n",
        "# Ejecutar la optimización con Ray Tune\n",
        "analysis = tune.run(\n",
        "    trainable_rf,          # La función a optimizar\n",
        "    config=search_space,       # El espacio de búsqueda\n",
        "    num_samples=20,            # Número de combinaciones a probar (trials)\n",
        "    metric=\"f1_score\",         # Métrica a optimizar\n",
        "    mode=\"max\",                # Queremos maximizar esta métrica\n",
        "    verbose=0                  # Reducir los mensajes en la consola\n",
        ")\n",
        "\n",
        "end_time_ray = time.time()\n",
        "# Calcular el tiempo total de la búsqueda\n",
        "search_time_ray = end_time_ray - start_time_ray\n",
        "\n",
        "# Obtener la mejor configuración (hiperparámetros) encontrada\n",
        "best_params_ray = analysis.best_config\n",
        "# Obtener el mejor F1-score\n",
        "best_f1_ray = analysis.best_result[\"f1_score\"]\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"\\n### 4. Resultados de Ray Tune ###\")\n",
        "print(f\"Mejores Hiperparámetros: {best_params_ray}\")\n",
        "print(f\"Mejor F1-Score: {best_f1_ray:.4f}\")\n",
        "print(f\"Tiempo de búsqueda: {search_time_ray:.4f} segundos\")\n",
        "\n",
        "# Detener Ray para liberar recursos\n",
        "ray.shutdown()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+\n",
            "| Configuration for experiment     trainable_rf_2025-07-15_02-02-20   |\n",
            "+---------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator              |\n",
            "| Scheduler                        FIFOScheduler                      |\n",
            "| Number of trials                 20                                 |\n",
            "+---------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/trainable_rf_2025-07-15_02-02-20\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-07-15_01-49-34_081384_509/artifacts/2025-07-15_02-02-20/trainable_rf_2025-07-15_02-02-20/driver_artifacts`\n",
            "\n",
            "\n",
            "### 4. Resultados de Ray Tune ###\n",
            "Mejores Hiperparámetros: {'n_estimators': 219, 'max_depth': 17, 'min_samples_split': 2}\n",
            "Mejor F1-Score: 0.9772\n",
            "Tiempo de búsqueda: 141.3193 segundos\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXfx7eksTa4l",
        "outputId": "ad592440-6e3b-4482-df45-0ca4d16a7e0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5\\. Comparación de Resultados 📈\n",
        "\n",
        "Para facilitar el análisis, consolidamos los resultados de los tres enfoques (Base, Optuna y Ray Tune) en una tabla comparativa. Esto nos permite contrastar de un vistazo el rendimiento (F1-Score), el costo computacional (tiempo) y el número de combinaciones probadas."
      ],
      "metadata": {
        "id": "bVZppVcKTa4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. COMPARACIÓN DE RESULTADOS\n",
        "\n",
        "# Crear un DataFrame para comparar los resultados de manera ordenada\n",
        "comparison_data = {\n",
        "    'Modelo': ['Base', 'Optuna', 'Ray Tune'],\n",
        "    'F1-Score': [f1_base, best_f1_optuna, best_f1_ray],\n",
        "    'Mejores Hiperparámetros': ['Por defecto', str(best_params_optuna), str(best_params_ray)],\n",
        "    'Combinaciones Probadas': [1, 20, 20],\n",
        "    'Tiempo (s)': [training_time_base, search_time_optuna, search_time_ray]\n",
        "}\n",
        "# Redondear para mejor visualización\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df['F1-Score'] = comparison_df['F1-Score'].round(4)\n",
        "comparison_df['Tiempo (s)'] = comparison_df['Tiempo (s)'].round(4)\n",
        "\n",
        "\n",
        "# Imprimir la tabla de comparación\n",
        "print(\"\\n### 5. Tabla de Comparación de Modelos ###\")\n",
        "print(comparison_df.to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### 5. Tabla de Comparación de Modelos ###\n",
            "     Modelo  F1-Score                                         Mejores Hiperparámetros  Combinaciones Probadas  Tiempo (s)\n",
            "0      Base    0.9772                                                     Por defecto                       1      0.2771\n",
            "1    Optuna    0.9772  {'n_estimators': 217, 'max_depth': 37, 'min_samples_split': 8}                      20     15.4700\n",
            "2  Ray Tune    0.9772  {'n_estimators': 219, 'max_depth': 17, 'min_samples_split': 2}                      20    141.3193\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IymDWpSdTa4l",
        "outputId": "5b946afc-99e0-42d8-a7fd-af10603992d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 6\\. Reflexión Final y Análisis 🧠\n",
        "\n",
        "El resultado más revelador de esta comparación es que **ninguna de las técnicas de optimización (Optuna y Ray Tune) logró mejorar el F1-Score del modelo base**. Los tres enfoques alcanzaron un F1-Score idéntico de **0.9772**. Esto sugiere que para este conjunto de datos específico, los hiperparámetros por defecto del `RandomForestClassifier` de Scikit-learn ya son excepcionalmente buenos.\n",
        "\n",
        "Con esta métrica clave siendo igual en todos los casos, la comparación se centra casi exclusivamente en la **eficiencia computacional (tiempo) y la complejidad**.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Visualización Comparativa 📊**\n",
        "\n",
        "Un gráfico de barras es ideal para visualizar la diferencia drástica en el tiempo de ejecución. Dado que la diferencia de magnitud es tan grande, usaremos una **escala logarítmica** en el eje Y para poder apreciar la diferencia entre el modelo Base y Optuna, que de otro modo sería invisible en comparación con Ray Tune."
      ],
      "metadata": {
        "id": "xTfs1yqXtH2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Recrear los datos del DataFrame para la visualización\n",
        "comparison_data = {\n",
        "    'Modelo': ['Base', 'Optuna', 'Ray Tune'],\n",
        "    'F1-Score': [0.9772, 0.9772, 0.9772],\n",
        "    'Tiempo (s)': [0.2771, 15.4700, 141.3193]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Crear el gráfico de barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(comparison_df['Modelo'], comparison_df['Tiempo (s)'], color=['#4CAF50', '#2196F3', '#FFC107'])\n",
        "\n",
        "# Usar escala logarítmica para una mejor visualización de las diferencias\n",
        "plt.yscale('log')\n",
        "\n",
        "# Añadir etiquetas y título\n",
        "plt.ylabel('Tiempo de Ejecución (s) - Escala Logarítmica')\n",
        "plt.xlabel('Enfoque del Modelo')\n",
        "plt.title('Comparación de Tiempos de Ejecución')\n",
        "\n",
        "# Añadir el valor de tiempo encima de cada barra\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.2f}s', va='bottom', ha='center') # va: vertical alignment\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "QgRIAYg1tIVY",
        "outputId": "f179eeeb-7332-4dd5-fbbd-87e25cbadd26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El gráfico ilustra de manera contundente el costo computacional de cada enfoque. Mientras que el modelo base es casi instantáneo, Ray Tune es órdenes de magnitud más lento que Optuna para esta tarea.\n",
        "\n",
        "-----\n",
        "\n",
        "### **Reflexión sobre Cada Enfoque 🧠**\n",
        "\n",
        "#### **Modelo Base (Sin Tuning)**\n",
        "\n",
        "  * **Ventajas:**\n",
        "      * **Eficiencia Máxima:** Con un tiempo de solo **0.28 segundos**, es, por mucho, el método más rápido.\n",
        "      * **Rendimiento Óptimo:** En este caso particular, logró el mejor F1-Score posible sin ningún costo de optimización.\n",
        "      * **Simplicidad Extrema:** No requiere librerías adicionales ni configuración compleja. Es la línea de partida ideal.\n",
        "  * **Desventajas:**\n",
        "      * **Dependencia de la Suerte:** Su éxito aquí es una casualidad afortunada. En la gran mayoría de los problemas, los parámetros por defecto no son los óptimos y confiar en ellos puede llevar a un rendimiento deficiente. No es una estrategia robusta a largo plazo.\n",
        "\n",
        "#### **Optuna**\n",
        "\n",
        "  * **Ventajas:**\n",
        "      * **Búsqueda Relativamente Rápida:** Aunque fue significativamente más lento que el modelo base, completó 20 pruebas en solo **15 segundos**. Esto demuestra que tiene una sobrecarga (overhead) muy baja, haciéndolo ideal para optimizaciones rápidas en una sola máquina.\n",
        "      * **Facilidad de Uso:** Su API es intuitiva y se integra de forma muy natural en un flujo de trabajo de Python.\n",
        "  * **Desventajas:**\n",
        "      * **Costo sin Beneficio (en este caso):** Su principal desventaja aquí fue que invirtió tiempo y recursos computacionales para no obtener ninguna mejora en el rendimiento. El esfuerzo de optimización no se tradujo en un mejor modelo.\n",
        "\n",
        "#### **Ray Tune**\n",
        "\n",
        "  * **Ventajas:**\n",
        "      * **Potencial de Escalabilidad:** Su única ventaja teórica en este contexto. Ray Tune está diseñado para la computación distribuida, permitiendo escalar la búsqueda de hiperparámetros a través de múltiples núcleos de CPU o incluso a un clúster de máquinas. Si necesitáramos ejecutar miles de pruebas, sería la herramienta adecuada.\n",
        "  * **Desventajas:**\n",
        "      * **Sobrecarga (Overhead) Masiva:** Esta es su debilidad más evidente aquí. Tardó **141 segundos**, casi **10 veces más que Optuna**, para realizar la misma tarea. La gestión del paralelismo y su arquitectura de escalabilidad introducen un costo computacional fijo muy alto que lo hace ineficiente para problemas a pequeña escala.\n",
        "      * **Complejidad Innecesaria:** Para una optimización en una sola máquina, su poder es excesivo y contraproducente, resultando en una espera mucho mayor para obtener el mismo resultado que las otras técnicas.\n",
        "\n",
        "En resumen, para este problema, el **modelo base fue el \"ganador\" indiscutible** por ofrecer el mismo rendimiento en una fracción del tiempo. Entre las herramientas de tuning, **Optuna demostró ser mucho más adecuado y eficiente que Ray Tune** para una tarea de esta escala."
      ],
      "metadata": {
        "id": "iBJeDx-btQpr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1lCDPY99tRJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}