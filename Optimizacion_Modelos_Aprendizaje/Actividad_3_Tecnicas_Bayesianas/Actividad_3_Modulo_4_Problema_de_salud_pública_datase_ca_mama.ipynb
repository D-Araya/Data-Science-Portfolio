{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizaci√≥n de Modelos en Salud usando T√©cnicas Bayesianas**\n",
        "\n",
        "**Objetivo:** Aplicar la Optimizaci√≥n Bayesiana para ajustar los hiperpar√°metros de un modelo de clasificaci√≥n binaria (Random Forest) sobre un problema de salud p√∫blica, comparando dos enfoques populares: Scikit-Optimize (skopt) y Hyperopt, evaluando el rendimiento del modelo y la eficiencia de cada t√©cnica.\n",
        "\n",
        "-----\n",
        "\n",
        "## **1. Cargar y Preparar los Datos üì¶**\n",
        "\n",
        "Iniciamos cargando las librer√≠as necesarias para todo el proceso. Luego, cargamos el dataset de c√°ncer de mama (`load_breast_cancer`) que viene incluido en **Scikit-learn**. Para asegurar que el modelo aprenda de manera efectiva, realizamos los siguientes pasos de preparaci√≥n:\n",
        "\n",
        "  * **Separar Variables:** Dividimos los datos en caracter√≠sticas (`X`) y la variable objetivo (`y`).\n",
        "  * **Dividir Datos:** Particionamos el dataset en conjuntos de entrenamiento (70%) y prueba (30%), utilizando `random_state` para garantizar que la divisi√≥n sea siempre la misma y nuestros resultados sean reproducibles.\n",
        "  * **Escalar Variables:** Aplicamos `StandardScaler` para estandarizar las caracter√≠sticas. Este paso es crucial para que los algoritmos de Machine Learning no se vean sesgados por variables con rangos de valores muy diferentes. Ajustamos el escalador **solo** en los datos de entrenamiento (`fit_transform`) y aplicamos la misma transformaci√≥n a los datos de prueba (`transform`) para evitar la fuga de informaci√≥n del conjunto de prueba al de entrenamiento.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "TxipY1lB6qo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC-cjK5d7rzw",
        "outputId": "961a0a0c-b0a8-47ac-9955-8e721680f998"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYHZ9D5270op",
        "outputId": "6c16ee61-b00c-466a-aa60-0d802089ea6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.15.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 0. Importaci√≥n de Librer√≠as\n",
        "# =============================================================================\n",
        "\n",
        "# Librer√≠as para manipulaci√≥n de datos y operaciones num√©ricas\n",
        "import numpy as np  # Para operaciones num√©ricas, especialmente con arrays.\n",
        "import pandas as pd # Para la manipulaci√≥n y an√°lisis de datos en DataFrames.\n",
        "import time         # Para medir el tiempo de ejecuci√≥n de los procesos.\n",
        "import warnings     # Para manejar advertencias y evitar que saturen la salida.\n",
        "\n",
        "# Clases y funciones de Scikit-learn para el modelado y la evaluaci√≥n\n",
        "from sklearn.datasets import load_breast_cancer               # Para cargar el dataset de c√°ncer de mama.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score # Para dividir los datos y para validaci√≥n cruzada.\n",
        "from sklearn.preprocessing import StandardScaler              # Para estandarizar las caracter√≠sticas (features).\n",
        "from sklearn.ensemble import RandomForestClassifier           # El modelo de clasificaci√≥n que vamos a optimizar.\n",
        "from sklearn.metrics import classification_report, f1_score   # M√©tricas para evaluar el rendimiento del clasificador.\n",
        "\n",
        "# Librer√≠as para Optimizaci√≥n Bayesiana\n",
        "# Scikit-Optimize (skopt)\n",
        "from skopt import BayesSearchCV                               # Implementaci√≥n de optimizaci√≥n bayesiana con API similar a Scikit-learn.\n",
        "from skopt.space import Integer, Real                         # Para definir el espacio de b√∫squeda de hiperpar√°metros.\n",
        "\n",
        "# Hyperopt\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials         # Funciones y objetos para la optimizaci√≥n con Hyperopt.\n",
        "\n",
        "# Ignorar advertencias para una salida m√°s limpia\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Cargar y Preparar los Datos\n",
        "# =============================================================================\n",
        "print(\"--- 1. Carga y Preparaci√≥n de Datos ---\")\n",
        "\n",
        "# Carga del dataset desde Scikit-learn\n",
        "data = load_breast_cancer() # Carga el objeto del dataset.\n",
        "X, y = data.data, data.target # Separa las caracter√≠sticas (X) y la variable objetivo (y).\n",
        "\n",
        "# Divisi√≥n en conjunto de entrenamiento (70%) y prueba (30%)\n",
        "# Se usa random_state para que la divisi√≥n sea reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Escalado de las variables\n",
        "# Es importante escalar los datos para que las caracter√≠sticas con rangos m√°s amplios no dominen el modelo.\n",
        "scaler = StandardScaler() # Crea una instancia del escalador.\n",
        "X_train_scaled = scaler.fit_transform(X_train) # Ajusta el escalador con los datos de entrenamiento y los transforma.\n",
        "X_test_scaled = scaler.transform(X_test) # Transforma los datos de prueba usando el mismo escalador.\n",
        "print(\"\\nDatos divididos y escalados correctamente.\")\n",
        "print(f\"Forma del conjunto de entrenamiento (X_train): {X_train_scaled.shape}\")\n",
        "print(f\"Forma del conjunto de prueba (X_test): {X_test_scaled.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Carga y Preparaci√≥n de Datos ---\n",
            "\n",
            "Datos divididos y escalados correctamente.\n",
            "Forma del conjunto de entrenamiento (X_train): (398, 30)\n",
            "Forma del conjunto de prueba (X_test): (171, 30)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRCI2GNn6qo9",
        "outputId": "d926e784-790b-4d59-caa2-990c31170565"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **2. Entrenar Modelo Base üéØ**\n",
        "\n",
        "Antes de optimizar, creamos y evaluamos un `RandomForestClassifier` sin ajuste de hiperpar√°metros, es decir, con su configuraci√≥n por defecto. Este modelo nos servir√° como **punto de referencia (baseline)** para medir si las t√©cnicas de optimizaci√≥n realmente aportan una mejora. Lo evaluamos usando `classification_report` y, espec√≠ficamente, el **F1-Score**, una m√©trica robusta que balancea la precisi√≥n y la sensibilidad, especialmente √∫til en problemas de salud."
      ],
      "metadata": {
        "id": "bwvSPcEB6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 2. Entrenar Modelo Base (Sin Ajuste)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 2. Entrenamiento del Modelo Base (Random Forest) ---\")\n",
        "\n",
        "# Implementa un modelo RandomForestClassifier con sus hiperpar√°metros por defecto\n",
        "base_model = RandomForestClassifier(random_state=42) # Crea la instancia del clasificador para reproducibilidad.\n",
        "\n",
        "# Entrena el modelo con los datos de entrenamiento escalados\n",
        "base_model.fit(X_train_scaled, y_train) # Ajusta el modelo.\n",
        "\n",
        "# Realiza predicciones sobre el conjunto de prueba\n",
        "y_pred_base = base_model.predict(X_test_scaled) # Predice las etiquetas para los datos de prueba.\n",
        "\n",
        "# Eval√∫a el rendimiento del modelo base\n",
        "f1_base = f1_score(y_test, y_pred_base, average='weighted') # Calcula el F1-Score ponderado.\n",
        "print(f\"\\nF1-Score del modelo base: {f1_base:.4f}\") # Imprime el F1-Score.\n",
        "print(\"\\nReporte de Clasificaci√≥n del modelo base:\")\n",
        "print(classification_report(y_test, y_pred_base)) # Imprime m√©tricas detalladas (precisi√≥n, recall, f1-score)."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Entrenamiento del Modelo Base (Random Forest) ---\n",
            "\n",
            "F1-Score del modelo base: 0.9706\n",
            "\n",
            "Reporte de Clasificaci√≥n del modelo base:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYTwoQq-6qo-",
        "outputId": "e4140c22-8850-4a70-a0fa-e373f05f87ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **3. Aplicar Optimizaci√≥n Bayesiana ‚Äì Parte A (Scikit-Optimize) ü§ñ**\n",
        "\n",
        "Ahora aplicamos la primera t√©cnica de optimizaci√≥n. **Scikit-Optimize (`skopt`)** se integra perfectamente con Scikit-learn a trav√©s de la clase `BayesSearchCV`. Esta herramienta busca de manera inteligente los mejores hiperpar√°metros. En lugar de probar todas las combinaciones como Grid Search, `BayesSearchCV` utiliza los resultados de evaluaciones anteriores para decidir qu√© combinaci√≥n probar a continuaci√≥n, haciendo el proceso mucho m√°s eficiente.\n",
        "\n",
        "  * **Definimos un espacio de b√∫squeda:** Indicamos los rangos de valores para `n_estimators`, `max_depth` y `min_samples_split`.\n",
        "  * **Ejecutamos la b√∫squeda:** Configuramos `BayesSearchCV` para que realice 30 iteraciones (`n_iter=30`), use validaci√≥n cruzada de 3 pliegues (`cv=3`) y optimice para la m√©trica F1 (`scoring='f1'`).\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "HnpvgiRd6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. Aplicar Optimizaci√≥n Bayesiana ‚Äì Parte A (Scikit-Optimize)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 3. Optimizaci√≥n Bayesiana con Scikit-Optimize ---\")\n",
        "\n",
        "# Definici√≥n del espacio de b√∫squeda para los hiperpar√°metros\n",
        "# Se especifica un rango para cada hiperpar√°metro que se quiere optimizar.\n",
        "search_space_skopt = {\n",
        "    'n_estimators': Integer(50, 500),      # N√∫mero de √°rboles en el bosque (entero entre 50 y 500).\n",
        "    'max_depth': Integer(5, 50),           # Profundidad m√°xima de cada √°rbol (entero entre 5 y 50).\n",
        "    'min_samples_split': Integer(2, 20)    # N√∫mero m√≠nimo de muestras para dividir un nodo (entero entre 2 y 20).\n",
        "}\n",
        "\n",
        "# Configuraci√≥n de la optimizaci√≥n bayesiana con BayesSearchCV\n",
        "opt_skopt = BayesSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42), # El modelo a optimizar.\n",
        "    search_spaces=search_space_skopt,      # El espacio de b√∫squeda definido.\n",
        "    n_iter=30,                             # N√∫mero de iteraciones de la optimizaci√≥n.\n",
        "    cv=3,                                  # Validaci√≥n cruzada con 3 folds.\n",
        "    scoring='f1',                          # M√©trica objetivo a maximizar.\n",
        "    random_state=42,                       # Semilla para reproducibilidad.\n",
        "    n_jobs=-1                              # Usar todos los n√∫cleos de CPU disponibles para acelerar.\n",
        ")\n",
        "\n",
        "# Inicia el cron√≥metro para medir el tiempo de ejecuci√≥n\n",
        "start_time_skopt = time.time()\n",
        "\n",
        "# Ejecuta la b√∫squeda de hiperpar√°metros\n",
        "opt_skopt.fit(X_train_scaled, y_train) # Inicia el proceso de optimizaci√≥n.\n",
        "\n",
        "# Detiene el cron√≥metro y calcula el tiempo total\n",
        "exec_time_skopt = time.time() - start_time_skopt\n",
        "\n",
        "# Muestra los mejores hiperpar√°metros encontrados\n",
        "print(f\"Mejores hiperpar√°metros (Scikit-Optimize): {opt_skopt.best_params_}\")\n",
        "print(f\"Tiempo de ejecuci√≥n (Scikit-Optimize): {exec_time_skopt:.2f} segundos\")\n",
        "\n",
        "# Eval√∫a el modelo optimizado en el conjunto de prueba\n",
        "best_model_skopt = opt_skopt.best_estimator_ # Obtiene el mejor modelo encontrado.\n",
        "y_pred_skopt = best_model_skopt.predict(X_test_scaled) # Realiza predicciones con el mejor modelo.\n",
        "f1_skopt = f1_score(y_test, y_pred_skopt, average='weighted') # Calcula el F1-Score.\n",
        "\n",
        "print(f\"\\nF1-Score del modelo optimizado (Scikit-Optimize): {f1_skopt:.4f}\")\n",
        "print(\"\\nReporte de Clasificaci√≥n (Scikit-Optimize):\")\n",
        "print(classification_report(y_test, y_pred_skopt))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Optimizaci√≥n Bayesiana con Scikit-Optimize ---\n",
            "Mejores hiperpar√°metros (Scikit-Optimize): OrderedDict([('max_depth', 50), ('min_samples_split', 2), ('n_estimators', 50)])\n",
            "Tiempo de ejecuci√≥n (Scikit-Optimize): 78.68 segundos\n",
            "\n",
            "F1-Score del modelo optimizado (Scikit-Optimize): 0.9706\n",
            "\n",
            "Reporte de Clasificaci√≥n (Scikit-Optimize):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hSx9bhm6qo-",
        "outputId": "e92bff6f-1a5e-4e64-c4db-aae7561a0512"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **4. Aplicar Optimizaci√≥n Bayesiana ‚Äì Parte B (Hyperopt) üß†**\n",
        "\n",
        "La segunda t√©cnica que probaremos es **Hyperopt**. Esta librer√≠a es m√°s flexible pero requiere una configuraci√≥n un poco m√°s manual.\n",
        "\n",
        "  * **Definimos el espacio de b√∫squeda:** Usamos la sintaxis propia de Hyperopt (`hp.quniform`) para definir los mismos rangos que en `skopt`. `quniform` genera n√∫meros uniformemente distribuidos que luego redondeamos a enteros.\n",
        "  * **Creamos una funci√≥n objetivo:** Esta funci√≥n (`objective`) toma un conjunto de hiperpar√°metros, entrena un modelo con ellos, lo eval√∫a mediante validaci√≥n cruzada y devuelve una \"p√©rdida\". Como Hyperopt siempre *minimiza*, devolvemos el F1-Score negativo.\n",
        "  * **Ejecutamos la optimizaci√≥n:** Usamos la funci√≥n `fmin` para que busque los par√°metros que minimizan nuestra funci√≥n objetivo, utilizando el algoritmo `tpe.suggest` (Tree-structured Parzen Estimator).\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "wzR0pu9z6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 4. Aplicar Optimizaci√≥n Bayesiana ‚Äì Parte B (Hyperopt)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 4. Optimizaci√≥n Bayesiana con Hyperopt ---\")\n",
        "\n",
        "# Definici√≥n del mismo espacio de b√∫squeda usando la sintaxis de Hyperopt\n",
        "# hp.quniform(label, low, high, q) devuelve un valor como round(uniform(low, high) / q) * q\n",
        "# Usamos q=1 para obtener valores enteros.\n",
        "search_space_hyperopt = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 1), # Rango para n_estimators.\n",
        "    'max_depth': hp.quniform('max_depth', 5, 50, 1),          # Rango para max_depth.\n",
        "    'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1) # Rango para min_samples_split.\n",
        "}\n",
        "\n",
        "# Definici√≥n de la funci√≥n objetivo que Hyperopt intentar√° minimizar\n",
        "def objective(params):\n",
        "    # Hyperopt pasa los par√°metros como float, hay que convertirlos a entero para el modelo\n",
        "    params['n_estimators'] = int(params['n_estimators'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['min_samples_split'] = int(params['min_samples_split'])\n",
        "\n",
        "    # Crea el clasificador con los hiperpar√°metros recibidos\n",
        "    clf = RandomForestClassifier(**params, random_state=42)\n",
        "\n",
        "    # Calcula el F1-score mediante validaci√≥n cruzada para una evaluaci√≥n robusta\n",
        "    f1 = cross_val_score(clf, X_train_scaled, y_train, cv=3, scoring='f1').mean()\n",
        "\n",
        "    # Hyperopt minimiza la funci√≥n, por lo que devolvemos el F1-score negativo\n",
        "    return {'loss': -f1, 'status': STATUS_OK}\n",
        "\n",
        "# Objeto para almacenar el historial de la b√∫squeda\n",
        "trials = Trials()\n",
        "\n",
        "# Inicia el cron√≥metro\n",
        "start_time_hyperopt = time.time()\n",
        "\n",
        "# Ejecuta la optimizaci√≥n con la funci√≥n fmin\n",
        "best_params_hyperopt = fmin(\n",
        "    fn=objective,                         # La funci√≥n objetivo a minimizar.\n",
        "    space=search_space_hyperopt,          # El espacio de b√∫squeda.\n",
        "    algo=tpe.suggest,                     # El algoritmo de optimizaci√≥n (Tree-structured Parzen Estimator).\n",
        "    max_evals=30,                         # El n√∫mero de evaluaciones (debe ser igual a n_iter de skopt).\n",
        "    trials=trials,                        # El objeto para guardar el historial de la b√∫squeda.\n",
        "    rstate=np.random.default_rng(42)      # Semilla para reproducibilidad.\n",
        ")\n",
        "\n",
        "# Detiene el cron√≥metro y calcula el tiempo total\n",
        "exec_time_hyperopt = time.time() - start_time_hyperopt\n",
        "\n",
        "# fmin devuelve los par√°metros optimizados como float, los convertimos a enteros\n",
        "best_params_hyperopt['n_estimators'] = int(best_params_hyperopt['n_estimators'])\n",
        "best_params_hyperopt['max_depth'] = int(best_params_hyperopt['max_depth'])\n",
        "best_params_hyperopt['min_samples_split'] = int(best_params_hyperopt['min_samples_split'])\n",
        "\n",
        "# Muestra los resultados\n",
        "print(f\"Mejores hiperpar√°metros (Hyperopt): {best_params_hyperopt}\")\n",
        "print(f\"Tiempo de ejecuci√≥n (Hyperopt): {exec_time_hyperopt:.2f} segundos\")\n",
        "\n",
        "# Entrena el modelo final con los mejores hiperpar√°metros encontrados por Hyperopt\n",
        "final_model_hyperopt = RandomForestClassifier(**best_params_hyperopt, random_state=42)\n",
        "final_model_hyperopt.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Eval√∫a el modelo final\n",
        "y_pred_hyperopt = final_model_hyperopt.predict(X_test_scaled)\n",
        "f1_hyperopt = f1_score(y_test, y_pred_hyperopt, average='weighted')\n",
        "print(f\"\\nF1-Score del modelo optimizado (Hyperopt): {f1_hyperopt:.4f}\")\n",
        "print(\"\\nReporte de Clasificaci√≥n (Hyperopt):\")\n",
        "print(classification_report(y_test, y_pred_hyperopt))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Optimizaci√≥n Bayesiana con Hyperopt ---\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:50<00:00,  1.70s/trial, best loss: -0.9703867119562045]\n",
            "Mejores hiperpar√°metros (Hyperopt): {'max_depth': 17, 'min_samples_split': 3, 'n_estimators': 66}\n",
            "Tiempo de ejecuci√≥n (Hyperopt): 51.01 segundos\n",
            "\n",
            "F1-Score del modelo optimizado (Hyperopt): 0.9706\n",
            "\n",
            "Reporte de Clasificaci√≥n (Hyperopt):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSSkx6l_6qo_",
        "outputId": "57800091-a28d-44c5-919e-eb83a74dfe33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **5. Comparar y Reflexionar üìä**\n",
        "\n",
        "Para facilitar el an√°lisis, consolidamos las m√©tricas clave (F1-Score, tiempo) y los par√°metros encontrados de los tres modelos (Base, Scikit-Optimize y Hyperopt) en una √∫nica tabla. Esto nos permite visualizar de forma clara y directa cu√°l fue el resultado de cada enfoque."
      ],
      "metadata": {
        "id": "GYwjTFJn6qo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 5. Comparar y Reflexionar\n",
        "# =============================================================================\n",
        "print(\"\\n--- 5. Comparaci√≥n y Reflexi√≥n Final ---\")\n",
        "\n",
        "# Creaci√≥n de un DataFrame para comparar los resultados de manera clara\n",
        "summary = pd.DataFrame({\n",
        "    'Modelo': ['Base', 'Scikit-Optimize', 'Hyperopt'], # Nombres de los modelos evaluados.\n",
        "    'F1-Score (Test)': [f1_base, f1_skopt, f1_hyperopt], # M√©trica de rendimiento clave.\n",
        "    'Tiempo de Optimizaci√≥n (s)': [0, exec_time_skopt, exec_time_hyperopt], # Eficiencia computacional.\n",
        "    'Mejores Par√°metros': [ # Hiperpar√°metros que generaron el mejor resultado.\n",
        "        'Default', # El modelo base usa los par√°metros por defecto.\n",
        "        str(opt_skopt.best_params_), # Par√°metros encontrados por Scikit-Optimize.\n",
        "        str(best_params_hyperopt) # Par√°metros encontrados por Hyperopt.\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Formatea las columnas num√©ricas para una mejor lectura\n",
        "summary['F1-Score (Test)'] = summary['F1-Score (Test)'].apply(lambda x: f\"{x:.4f}\")\n",
        "summary['Tiempo de Optimizaci√≥n (s)'] = summary['Tiempo de Optimizaci√≥n (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Imprime la tabla de resumen\n",
        "# Establece la opci√≥n para mostrar el contenido completo de las columnas\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(\"\\nTabla Comparativa de Resultados:\")\n",
        "print(summary)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 5. Comparaci√≥n y Reflexi√≥n Final ---\n",
            "\n",
            "Tabla Comparativa de Resultados:\n",
            "            Modelo F1-Score (Test) Tiempo de Optimizaci√≥n (s)  \\\n",
            "0             Base          0.9706                       0.00   \n",
            "1  Scikit-Optimize          0.9706                      78.68   \n",
            "2         Hyperopt          0.9706                      51.01   \n",
            "\n",
            "                                                                 Mejores Par√°metros  \n",
            "0                                                                           Default  \n",
            "1  OrderedDict([('max_depth', 50), ('min_samples_split', 2), ('n_estimators', 50)])  \n",
            "2                     {'max_depth': 17, 'min_samples_split': 3, 'n_estimators': 66}  \n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AzHNAL66qo_",
        "outputId": "87103152-4c52-4670-c63a-99d17b508417"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qu√© t√©cnica fue m√°s efectiva y por qu√©.  \n",
        "\n",
        "### **An√°lisis de Efectividad: Scikit-Optimize vs. Hyperopt**\n",
        "\n",
        "Para determinar qu√© t√©cnica fue m√°s efectiva, debemos evaluar los resultados desde tres perspectivas clave: la **calidad predictiva del modelo final**, la **eficiencia computacional** del proceso de optimizaci√≥n y la **simplicidad** de la soluci√≥n.\n",
        "\n",
        "#### **1. Calidad Predictiva (F1-Score)**\n",
        "\n",
        "Este es el criterio m√°s importante. El objetivo de la optimizaci√≥n es encontrar un modelo que generalice mejor y, por lo tanto, tenga un mejor rendimiento en datos no vistos.\n",
        "\n",
        "* **Modelo Base:** F1-Score = 0.9706\n",
        "* **Modelo con Scikit-Optimize:** F1-Score = 0.9706\n",
        "* **Modelo con Hyperopt:** F1-Score = 0.9706\n",
        "\n",
        "**An√°lisis:**\n",
        "Sorprendentemente, ambas t√©cnicas de optimizaci√≥n bayesiana encontraron combinaciones de hiperpar√°metros que resultaron en un **F1-Score id√©ntico** al del modelo base. Esto nos lleva a una conclusi√≥n fundamental: para este dataset y con la m√©trica F1-Score, los par√°metros por defecto del `RandomForestClassifier` de Scikit-learn ya son excepcionalmente buenos.\n",
        "\n",
        "Desde el punto de vista del rendimiento puro, **hay un triple empate**. Ninguna t√©cnica de optimizaci√≥n logr√≥ superar al modelo base, lo que significa que el costo computacional de la optimizaci√≥n no se tradujo en una mejora predictiva.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Eficiencia Computacional (Tiempo de Optimizaci√≥n)**\n",
        "\n",
        "Si varias t√©cnicas alcanzan el mismo nivel de rendimiento, la siguiente medida de efectividad es la rapidez con la que lo logran.\n",
        "\n",
        "* **Scikit-Optimize:** 78.68 segundos\n",
        "* **Hyperopt:** 51.01 segundos\n",
        "\n",
        "**An√°lisis:**\n",
        "Aqu√≠ hay un claro ganador. **Hyperopt fue significativamente m√°s eficiente que Scikit-Optimize**. Logr√≥ encontrar una combinaci√≥n de hiperpar√°metros con el mismo rendimiento m√°ximo en solo **51.01 segundos**, mientras que Scikit-Optimize tard√≥ **78.68 segundos**. Esto representa un **ahorro de tiempo de aproximadamente el 35%**.\n",
        "\n",
        "Esta diferencia puede deberse a la eficiencia del algoritmo subyacente (`TPE` en Hyperopt) o a la forma en que explora el espacio de b√∫squeda. En esta ejecuci√≥n, Hyperopt naveg√≥ por el espacio de hiperpar√°metros de manera m√°s efectiva para llegar a una soluci√≥n √≥ptima m√°s r√°pidamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Simplicidad de la Soluci√≥n (An√°lisis de Hiperpar√°metros)**\n",
        "\n",
        "* **Scikit-Optimize:** `max_depth=50`, `min_samples_split=2`, `n_estimators=50`\n",
        "* **Hyperopt:** `max_depth=17`, `min_samples_split=3`, `n_estimators=66`\n",
        "\n",
        "**An√°lisis:**\n",
        "Ambas librer√≠as encontraron soluciones diferentes para el mismo problema, lo que demuestra que en el espacio de hiperpar√°metros pueden existir m√∫ltiples \"picos\" de rendimiento similar.\n",
        "* **Scikit-Optimize** opt√≥ por un modelo con √°rboles muy profundos (`max_depth=50`) pero menos numerosos (`n_estimators=50`).\n",
        "* **Hyperopt** prefiri√≥ un modelo con √°rboles m√°s restringidos en profundidad (`max_depth=17`) pero compensado con un mayor n√∫mero de ellos (`n_estimators=66`). Un modelo con menor profundidad m√°xima como el de Hyperopt suele ser menos propenso al sobreajuste, lo que podr√≠a considerarse una ventaja te√≥rica, aunque en la pr√°ctica no se reflej√≥ en un mejor F1-Score.\n",
        "\n",
        "---\n",
        "\n",
        "### **¬øQu√© t√©cnica fue m√°s efectiva?**\n",
        "\n",
        "La respuesta depende de c√≥mo definas \"efectividad\":\n",
        "\n",
        "* Si la **efectividad se mide √∫nicamente por la calidad del modelo final (F1-Score)**, entonces **ninguna fue m√°s efectiva que la otra, ni siquiera que el modelo base**. Todas llegaron al mismo techo de rendimiento. En este escenario, el enfoque m√°s efectivo ser√≠a, ir√≥nicamente, no optimizar y usar el modelo base, ahorrando tiempo y recursos.\n",
        "\n",
        "* Si la **efectividad se mide por la capacidad de encontrar la mejor soluci√≥n posible de la manera m√°s eficiente**, entonces **Hyperopt fue la t√©cnica claramente superior**. Cumpli√≥ el objetivo de optimizaci√≥n (alcanzar el F1-Score m√°ximo) utilizando un 35% menos de tiempo computacional que Scikit-Optimize.\n",
        "\n",
        "**Veredicto Final:**\n",
        "\n",
        "Considerando que el prop√≥sito de estas herramientas es el **proceso de optimizaci√≥n** en s√≠ mismo, **Hyperopt demostr√≥ ser m√°s efectiva en este caso particular**. Fue m√°s r√°pida y, por lo tanto, m√°s eficiente en el uso de recursos para lograr el mismo resultado de alta calidad."
      ],
      "metadata": {
        "id": "T-E3DFgoCzmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **6. Documentaci√≥n y presentaci√≥n ‚úçÔ∏è**\n",
        "### **Conclusiones: Optimizaci√≥n Bayesiana vs. T√©cnicas Tradicionales (Grid Search y Random Search)**\n",
        "\n",
        "La elecci√≥n de una t√©cnica de optimizaci√≥n de hiperpar√°metros es una de las decisiones m√°s cr√≠ticas para maximizar el rendimiento de un modelo de Machine Learning. Si bien las t√©cnicas tradicionales como Grid Search y Random Search son populares por su simplicidad, la Optimizaci√≥n Bayesiana representa un paradigma fundamentalmente m√°s avanzado e inteligente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **El Paradigma de B√∫squeda: La Diferencia Fundamental üß†**\n",
        "\n",
        "Para entender por qu√© la Optimizaci√≥n Bayesiana es superior, es crucial analizar c√≥mo funciona cada m√©todo \"bajo el cap√≥\".\n",
        "\n",
        "1.  **Grid Search (B√∫squeda en Rejilla - El Enfoque de Fuerza Bruta):**\n",
        "    * **¬øC√≥mo funciona?:** Define una \"rejilla\" discreta de valores para cada hiperpar√°metro y prueba, de manera exhaustiva, **todas las combinaciones posibles**.\n",
        "    * **Su Debilidad:** Es un m√©todo \"ciego\" y terriblemente ineficiente. No aprende de las evaluaciones anteriores. Si una regi√≥n del espacio de b√∫squeda produce resultados consistentemente malos, Grid Search seguir√° perdiendo tiempo en ella. Su costo computacional crece exponencialmente con cada nuevo hiperpar√°metro (la \"maldici√≥n de la dimensionalidad\"), haci√©ndolo inviable para problemas complejos.\n",
        "\n",
        "2.  **Random Search (B√∫squeda Aleatoria - El Enfoque Estoc√°stico):**\n",
        "    * **¬øC√≥mo funciona?:** En lugar de probar todo, selecciona un n√∫mero fijo de combinaciones de hiperpar√°metros de manera aleatoria dentro de un espacio definido.\n",
        "    * **Su Ventaja y Debilidad:** Es m√°s eficiente que Grid Search porque no se atasca explorando una dimensi√≥n de hiperpar√°metros sin importancia. Sin embargo, tambi√©n es un m√©todo \"ciego\". Cada prueba es un evento independiente; no utiliza la informaci√≥n de los resultados anteriores para guiar su pr√≥xima elecci√≥n. Esencialmente, es como buscar un tesoro en un campo enorme cerrando los ojos y eligiendo lugares al azar.\n",
        "\n",
        "3.  **Optimizaci√≥n Bayesiana (B√∫squeda Inteligente - El Enfoque Informado):**\n",
        "    * **¬øC√≥mo funciona?:** Trata la optimizaci√≥n como un problema de inferencia estad√≠stica. Funciona en un ciclo de dos pasos:\n",
        "        1.  **Construye un Modelo Sustituto (Surrogate Model):** Crea un modelo probabil√≠stico interno (com√∫nmente un Proceso Gaussiano) que funciona como un \"mapa\" de c√≥mo los hiperpar√°metros probablemente afectan la puntuaci√≥n del modelo. Este mapa se actualiza con cada nueva evaluaci√≥n, volvi√©ndose m√°s preciso con el tiempo.\n",
        "        2.  **Usa una Funci√≥n de Adquisici√≥n (Acquisition Function):** Este es el \"cerebro\" del proceso. Utiliza el mapa del modelo sustituto para decidir qu√© combinaci√≥n de hiperpar√°metros probar a continuaci√≥n. Lo hace equilibrando inteligentemente dos objetivos:\n",
        "            * **Explotaci√≥n (Exploitation):** Probar en √°reas donde el modelo sustituto predice un alto rendimiento (cerca de los mejores resultados encontrados hasta ahora).\n",
        "            * **Exploraci√≥n (Exploration):** Probar en √°reas de alta incertidumbre, donde el modelo sabe poco pero podr√≠a haber un pico de rendimiento oculto.\n",
        "    * **Su Fortaleza:** Este enfoque es **informado**. Cada prueba est√° estrat√©gicamente elegida para maximizar lo que se aprende sobre el espacio de b√∫squeda. No pierde tiempo en regiones poco prometedoras y se enfoca r√°pidamente en las √°reas que importan.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Comparativa Directa: Ventajas y Desventajas üìä**\n",
        "\n",
        "| Criterio | Grid Search | Random Search | Optimizaci√≥n Bayesiana |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Eficiencia Computacional** | **Muy Baja.** Inviable para m√°s de 3-4 hiperpar√°metros. | **Media.** Mucho mejor que Grid Search. Eficaz con un presupuesto fijo. | **Muy Alta.** Dise√±ada para encontrar √≥ptimos en el menor n√∫mero de iteraciones posible. |\n",
        "| **Calidad de la Soluci√≥n** | **Variable.** Solo garantiza el √≥ptimo si est√° en la rejilla y se tiene tiempo infinito. | **Buena.** A menudo encuentra soluciones muy buenas de forma r√°pida. | **Excelente.** Tiende a encontrar soluciones mejores o iguales que Random Search, pero con menos iteraciones. |\n",
        "| **Proceso de B√∫squeda** | Ciego y exhaustivo. | Ciego y aleatorio. | **Informado y adaptativo.** |\n",
        "| **Implementaci√≥n** | Muy f√°cil (integrado en `sklearn`). | Muy f√°cil (integrado en `sklearn`). | F√°cil/Intermedia (requiere librer√≠as como `scikit-optimize` o `hyperopt`). |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Conclusi√≥n Final: ¬øCu√°ndo Usar Cada T√©cnica? üéØ**\n",
        "\n",
        "* **Usa Grid Search si...** tienes un espacio de b√∫squeda extremadamente peque√±o (ej. 2 hiperpar√°metros con 3 valores cada uno) y quieres probar absolutamente todo por completitud. En la pr√°ctica, su uso hoy en d√≠a es muy limitado y generalmente no se recomienda.\n",
        "\n",
        "* **Usa Random Search si...** necesitas un m√©todo r√°pido, f√°cil de implementar y que ofrezca una mejora sustancial sobre los par√°metros por defecto. Es un excelente **punto de partida** o *baseline* para cualquier problema de optimizaci√≥n. Si el coste de evaluar tu modelo es bajo, Random Search puede ser suficiente.\n",
        "\n",
        "* **Usa Optimizaci√≥n Bayesiana si...**\n",
        "    * **El rendimiento del modelo es cr√≠tico.** Quieres exprimir hasta la √∫ltima gota de potencial de tu clasificador.\n",
        "    * **El coste de cada evaluaci√≥n (entrenamiento del modelo) es alto.** Esto es clave para modelos como redes neuronales profundas, ensambles grandes o al trabajar con datasets masivos. El ahorro de unas pocas docenas de iteraciones puede significar horas o d√≠as de c√≥mputo.\n",
        "    * **Est√°s trabajando en un problema complejo** con muchos hiperpar√°metros que interact√∫an de formas no lineales.\n",
        "\n",
        "En resumen, mientras que Random Search democratiz√≥ la optimizaci√≥n haci√©ndola m√°s eficiente que Grid Search, la **Optimizaci√≥n Bayesiana representa el siguiente paso evolutivo, cambiando de un enfoque de \"fuerza bruta\" a uno de \"estrategia inteligente\"**. Para cualquier proyecto serio de Machine Learning, es la t√©cnica preferida para lograr resultados de vanguardia."
      ],
      "metadata": {
        "id": "5L6SNxYJEhtV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWpUaqWvC_Ja"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}