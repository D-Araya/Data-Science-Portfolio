{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimización de Modelos en Salud usando Técnicas Bayesianas**\n",
        "\n",
        "**Objetivo:** Aplicar la Optimización Bayesiana para ajustar los hiperparámetros de un modelo de clasificación binaria (Random Forest) sobre un problema de salud pública, comparando dos enfoques populares: Scikit-Optimize (skopt) y Hyperopt, evaluando el rendimiento del modelo y la eficiencia de cada técnica.\n",
        "\n",
        "-----\n",
        "\n",
        "## **1. Cargar y Preparar los Datos 📦**\n",
        "\n",
        "Iniciamos cargando las librerías necesarias para todo el proceso. Luego, cargamos el dataset de cáncer de mama (`load_breast_cancer`) que viene incluido en **Scikit-learn**. Para asegurar que el modelo aprenda de manera efectiva, realizamos los siguientes pasos de preparación:\n",
        "\n",
        "  * **Separar Variables:** Dividimos los datos en características (`X`) y la variable objetivo (`y`).\n",
        "  * **Dividir Datos:** Particionamos el dataset en conjuntos de entrenamiento (70%) y prueba (30%), utilizando `random_state` para garantizar que la división sea siempre la misma y nuestros resultados sean reproducibles.\n",
        "  * **Escalar Variables:** Aplicamos `StandardScaler` para estandarizar las características. Este paso es crucial para que los algoritmos de Machine Learning no se vean sesgados por variables con rangos de valores muy diferentes. Ajustamos el escalador **solo** en los datos de entrenamiento (`fit_transform`) y aplicamos la misma transformación a los datos de prueba (`transform`) para evitar la fuga de información del conjunto de prueba al de entrenamiento.\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "TxipY1lB6qo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC-cjK5d7rzw",
        "outputId": "961a0a0c-b0a8-47ac-9955-8e721680f998"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.1)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYHZ9D5270op",
        "outputId": "6c16ee61-b00c-466a-aa60-0d802089ea6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.15.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 0. Importación de Librerías\n",
        "# =============================================================================\n",
        "\n",
        "# Librerías para manipulación de datos y operaciones numéricas\n",
        "import numpy as np  # Para operaciones numéricas, especialmente con arrays.\n",
        "import pandas as pd # Para la manipulación y análisis de datos en DataFrames.\n",
        "import time         # Para medir el tiempo de ejecución de los procesos.\n",
        "import warnings     # Para manejar advertencias y evitar que saturen la salida.\n",
        "\n",
        "# Clases y funciones de Scikit-learn para el modelado y la evaluación\n",
        "from sklearn.datasets import load_breast_cancer               # Para cargar el dataset de cáncer de mama.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score # Para dividir los datos y para validación cruzada.\n",
        "from sklearn.preprocessing import StandardScaler              # Para estandarizar las características (features).\n",
        "from sklearn.ensemble import RandomForestClassifier           # El modelo de clasificación que vamos a optimizar.\n",
        "from sklearn.metrics import classification_report, f1_score   # Métricas para evaluar el rendimiento del clasificador.\n",
        "\n",
        "# Librerías para Optimización Bayesiana\n",
        "# Scikit-Optimize (skopt)\n",
        "from skopt import BayesSearchCV                               # Implementación de optimización bayesiana con API similar a Scikit-learn.\n",
        "from skopt.space import Integer, Real                         # Para definir el espacio de búsqueda de hiperparámetros.\n",
        "\n",
        "# Hyperopt\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials         # Funciones y objetos para la optimización con Hyperopt.\n",
        "\n",
        "# Ignorar advertencias para una salida más limpia\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Cargar y Preparar los Datos\n",
        "# =============================================================================\n",
        "print(\"--- 1. Carga y Preparación de Datos ---\")\n",
        "\n",
        "# Carga del dataset desde Scikit-learn\n",
        "data = load_breast_cancer() # Carga el objeto del dataset.\n",
        "X, y = data.data, data.target # Separa las características (X) y la variable objetivo (y).\n",
        "\n",
        "# División en conjunto de entrenamiento (70%) y prueba (30%)\n",
        "# Se usa random_state para que la división sea reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Escalado de las variables\n",
        "# Es importante escalar los datos para que las características con rangos más amplios no dominen el modelo.\n",
        "scaler = StandardScaler() # Crea una instancia del escalador.\n",
        "X_train_scaled = scaler.fit_transform(X_train) # Ajusta el escalador con los datos de entrenamiento y los transforma.\n",
        "X_test_scaled = scaler.transform(X_test) # Transforma los datos de prueba usando el mismo escalador.\n",
        "print(\"\\nDatos divididos y escalados correctamente.\")\n",
        "print(f\"Forma del conjunto de entrenamiento (X_train): {X_train_scaled.shape}\")\n",
        "print(f\"Forma del conjunto de prueba (X_test): {X_test_scaled.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Carga y Preparación de Datos ---\n",
            "\n",
            "Datos divididos y escalados correctamente.\n",
            "Forma del conjunto de entrenamiento (X_train): (398, 30)\n",
            "Forma del conjunto de prueba (X_test): (171, 30)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRCI2GNn6qo9",
        "outputId": "d926e784-790b-4d59-caa2-990c31170565"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **2. Entrenar Modelo Base 🎯**\n",
        "\n",
        "Antes de optimizar, creamos y evaluamos un `RandomForestClassifier` sin ajuste de hiperparámetros, es decir, con su configuración por defecto. Este modelo nos servirá como **punto de referencia (baseline)** para medir si las técnicas de optimización realmente aportan una mejora. Lo evaluamos usando `classification_report` y, específicamente, el **F1-Score**, una métrica robusta que balancea la precisión y la sensibilidad, especialmente útil en problemas de salud."
      ],
      "metadata": {
        "id": "bwvSPcEB6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 2. Entrenar Modelo Base (Sin Ajuste)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 2. Entrenamiento del Modelo Base (Random Forest) ---\")\n",
        "\n",
        "# Implementa un modelo RandomForestClassifier con sus hiperparámetros por defecto\n",
        "base_model = RandomForestClassifier(random_state=42) # Crea la instancia del clasificador para reproducibilidad.\n",
        "\n",
        "# Entrena el modelo con los datos de entrenamiento escalados\n",
        "base_model.fit(X_train_scaled, y_train) # Ajusta el modelo.\n",
        "\n",
        "# Realiza predicciones sobre el conjunto de prueba\n",
        "y_pred_base = base_model.predict(X_test_scaled) # Predice las etiquetas para los datos de prueba.\n",
        "\n",
        "# Evalúa el rendimiento del modelo base\n",
        "f1_base = f1_score(y_test, y_pred_base, average='weighted') # Calcula el F1-Score ponderado.\n",
        "print(f\"\\nF1-Score del modelo base: {f1_base:.4f}\") # Imprime el F1-Score.\n",
        "print(\"\\nReporte de Clasificación del modelo base:\")\n",
        "print(classification_report(y_test, y_pred_base)) # Imprime métricas detalladas (precisión, recall, f1-score)."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Entrenamiento del Modelo Base (Random Forest) ---\n",
            "\n",
            "F1-Score del modelo base: 0.9706\n",
            "\n",
            "Reporte de Clasificación del modelo base:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYTwoQq-6qo-",
        "outputId": "e4140c22-8850-4a70-a0fa-e373f05f87ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **3. Aplicar Optimización Bayesiana – Parte A (Scikit-Optimize) 🤖**\n",
        "\n",
        "Ahora aplicamos la primera técnica de optimización. **Scikit-Optimize (`skopt`)** se integra perfectamente con Scikit-learn a través de la clase `BayesSearchCV`. Esta herramienta busca de manera inteligente los mejores hiperparámetros. En lugar de probar todas las combinaciones como Grid Search, `BayesSearchCV` utiliza los resultados de evaluaciones anteriores para decidir qué combinación probar a continuación, haciendo el proceso mucho más eficiente.\n",
        "\n",
        "  * **Definimos un espacio de búsqueda:** Indicamos los rangos de valores para `n_estimators`, `max_depth` y `min_samples_split`.\n",
        "  * **Ejecutamos la búsqueda:** Configuramos `BayesSearchCV` para que realice 30 iteraciones (`n_iter=30`), use validación cruzada de 3 pliegues (`cv=3`) y optimice para la métrica F1 (`scoring='f1'`).\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "HnpvgiRd6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. Aplicar Optimización Bayesiana – Parte A (Scikit-Optimize)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 3. Optimización Bayesiana con Scikit-Optimize ---\")\n",
        "\n",
        "# Definición del espacio de búsqueda para los hiperparámetros\n",
        "# Se especifica un rango para cada hiperparámetro que se quiere optimizar.\n",
        "search_space_skopt = {\n",
        "    'n_estimators': Integer(50, 500),      # Número de árboles en el bosque (entero entre 50 y 500).\n",
        "    'max_depth': Integer(5, 50),           # Profundidad máxima de cada árbol (entero entre 5 y 50).\n",
        "    'min_samples_split': Integer(2, 20)    # Número mínimo de muestras para dividir un nodo (entero entre 2 y 20).\n",
        "}\n",
        "\n",
        "# Configuración de la optimización bayesiana con BayesSearchCV\n",
        "opt_skopt = BayesSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42), # El modelo a optimizar.\n",
        "    search_spaces=search_space_skopt,      # El espacio de búsqueda definido.\n",
        "    n_iter=30,                             # Número de iteraciones de la optimización.\n",
        "    cv=3,                                  # Validación cruzada con 3 folds.\n",
        "    scoring='f1',                          # Métrica objetivo a maximizar.\n",
        "    random_state=42,                       # Semilla para reproducibilidad.\n",
        "    n_jobs=-1                              # Usar todos los núcleos de CPU disponibles para acelerar.\n",
        ")\n",
        "\n",
        "# Inicia el cronómetro para medir el tiempo de ejecución\n",
        "start_time_skopt = time.time()\n",
        "\n",
        "# Ejecuta la búsqueda de hiperparámetros\n",
        "opt_skopt.fit(X_train_scaled, y_train) # Inicia el proceso de optimización.\n",
        "\n",
        "# Detiene el cronómetro y calcula el tiempo total\n",
        "exec_time_skopt = time.time() - start_time_skopt\n",
        "\n",
        "# Muestra los mejores hiperparámetros encontrados\n",
        "print(f\"Mejores hiperparámetros (Scikit-Optimize): {opt_skopt.best_params_}\")\n",
        "print(f\"Tiempo de ejecución (Scikit-Optimize): {exec_time_skopt:.2f} segundos\")\n",
        "\n",
        "# Evalúa el modelo optimizado en el conjunto de prueba\n",
        "best_model_skopt = opt_skopt.best_estimator_ # Obtiene el mejor modelo encontrado.\n",
        "y_pred_skopt = best_model_skopt.predict(X_test_scaled) # Realiza predicciones con el mejor modelo.\n",
        "f1_skopt = f1_score(y_test, y_pred_skopt, average='weighted') # Calcula el F1-Score.\n",
        "\n",
        "print(f\"\\nF1-Score del modelo optimizado (Scikit-Optimize): {f1_skopt:.4f}\")\n",
        "print(\"\\nReporte de Clasificación (Scikit-Optimize):\")\n",
        "print(classification_report(y_test, y_pred_skopt))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Optimización Bayesiana con Scikit-Optimize ---\n",
            "Mejores hiperparámetros (Scikit-Optimize): OrderedDict([('max_depth', 50), ('min_samples_split', 2), ('n_estimators', 50)])\n",
            "Tiempo de ejecución (Scikit-Optimize): 78.68 segundos\n",
            "\n",
            "F1-Score del modelo optimizado (Scikit-Optimize): 0.9706\n",
            "\n",
            "Reporte de Clasificación (Scikit-Optimize):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hSx9bhm6qo-",
        "outputId": "e92bff6f-1a5e-4e64-c4db-aae7561a0512"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **4. Aplicar Optimización Bayesiana – Parte B (Hyperopt) 🧠**\n",
        "\n",
        "La segunda técnica que probaremos es **Hyperopt**. Esta librería es más flexible pero requiere una configuración un poco más manual.\n",
        "\n",
        "  * **Definimos el espacio de búsqueda:** Usamos la sintaxis propia de Hyperopt (`hp.quniform`) para definir los mismos rangos que en `skopt`. `quniform` genera números uniformemente distribuidos que luego redondeamos a enteros.\n",
        "  * **Creamos una función objetivo:** Esta función (`objective`) toma un conjunto de hiperparámetros, entrena un modelo con ellos, lo evalúa mediante validación cruzada y devuelve una \"pérdida\". Como Hyperopt siempre *minimiza*, devolvemos el F1-Score negativo.\n",
        "  * **Ejecutamos la optimización:** Usamos la función `fmin` para que busque los parámetros que minimizan nuestra función objetivo, utilizando el algoritmo `tpe.suggest` (Tree-structured Parzen Estimator).\n",
        "\n",
        "<!-- end list -->"
      ],
      "metadata": {
        "id": "wzR0pu9z6qo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 4. Aplicar Optimización Bayesiana – Parte B (Hyperopt)\n",
        "# =============================================================================\n",
        "print(\"\\n--- 4. Optimización Bayesiana con Hyperopt ---\")\n",
        "\n",
        "# Definición del mismo espacio de búsqueda usando la sintaxis de Hyperopt\n",
        "# hp.quniform(label, low, high, q) devuelve un valor como round(uniform(low, high) / q) * q\n",
        "# Usamos q=1 para obtener valores enteros.\n",
        "search_space_hyperopt = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 1), # Rango para n_estimators.\n",
        "    'max_depth': hp.quniform('max_depth', 5, 50, 1),          # Rango para max_depth.\n",
        "    'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1) # Rango para min_samples_split.\n",
        "}\n",
        "\n",
        "# Definición de la función objetivo que Hyperopt intentará minimizar\n",
        "def objective(params):\n",
        "    # Hyperopt pasa los parámetros como float, hay que convertirlos a entero para el modelo\n",
        "    params['n_estimators'] = int(params['n_estimators'])\n",
        "    params['max_depth'] = int(params['max_depth'])\n",
        "    params['min_samples_split'] = int(params['min_samples_split'])\n",
        "\n",
        "    # Crea el clasificador con los hiperparámetros recibidos\n",
        "    clf = RandomForestClassifier(**params, random_state=42)\n",
        "\n",
        "    # Calcula el F1-score mediante validación cruzada para una evaluación robusta\n",
        "    f1 = cross_val_score(clf, X_train_scaled, y_train, cv=3, scoring='f1').mean()\n",
        "\n",
        "    # Hyperopt minimiza la función, por lo que devolvemos el F1-score negativo\n",
        "    return {'loss': -f1, 'status': STATUS_OK}\n",
        "\n",
        "# Objeto para almacenar el historial de la búsqueda\n",
        "trials = Trials()\n",
        "\n",
        "# Inicia el cronómetro\n",
        "start_time_hyperopt = time.time()\n",
        "\n",
        "# Ejecuta la optimización con la función fmin\n",
        "best_params_hyperopt = fmin(\n",
        "    fn=objective,                         # La función objetivo a minimizar.\n",
        "    space=search_space_hyperopt,          # El espacio de búsqueda.\n",
        "    algo=tpe.suggest,                     # El algoritmo de optimización (Tree-structured Parzen Estimator).\n",
        "    max_evals=30,                         # El número de evaluaciones (debe ser igual a n_iter de skopt).\n",
        "    trials=trials,                        # El objeto para guardar el historial de la búsqueda.\n",
        "    rstate=np.random.default_rng(42)      # Semilla para reproducibilidad.\n",
        ")\n",
        "\n",
        "# Detiene el cronómetro y calcula el tiempo total\n",
        "exec_time_hyperopt = time.time() - start_time_hyperopt\n",
        "\n",
        "# fmin devuelve los parámetros optimizados como float, los convertimos a enteros\n",
        "best_params_hyperopt['n_estimators'] = int(best_params_hyperopt['n_estimators'])\n",
        "best_params_hyperopt['max_depth'] = int(best_params_hyperopt['max_depth'])\n",
        "best_params_hyperopt['min_samples_split'] = int(best_params_hyperopt['min_samples_split'])\n",
        "\n",
        "# Muestra los resultados\n",
        "print(f\"Mejores hiperparámetros (Hyperopt): {best_params_hyperopt}\")\n",
        "print(f\"Tiempo de ejecución (Hyperopt): {exec_time_hyperopt:.2f} segundos\")\n",
        "\n",
        "# Entrena el modelo final con los mejores hiperparámetros encontrados por Hyperopt\n",
        "final_model_hyperopt = RandomForestClassifier(**best_params_hyperopt, random_state=42)\n",
        "final_model_hyperopt.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evalúa el modelo final\n",
        "y_pred_hyperopt = final_model_hyperopt.predict(X_test_scaled)\n",
        "f1_hyperopt = f1_score(y_test, y_pred_hyperopt, average='weighted')\n",
        "print(f\"\\nF1-Score del modelo optimizado (Hyperopt): {f1_hyperopt:.4f}\")\n",
        "print(\"\\nReporte de Clasificación (Hyperopt):\")\n",
        "print(classification_report(y_test, y_pred_hyperopt))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Optimización Bayesiana con Hyperopt ---\n",
            "100%|██████████| 30/30 [00:50<00:00,  1.70s/trial, best loss: -0.9703867119562045]\n",
            "Mejores hiperparámetros (Hyperopt): {'max_depth': 17, 'min_samples_split': 3, 'n_estimators': 66}\n",
            "Tiempo de ejecución (Hyperopt): 51.01 segundos\n",
            "\n",
            "F1-Score del modelo optimizado (Hyperopt): 0.9706\n",
            "\n",
            "Reporte de Clasificación (Hyperopt):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        63\n",
            "           1       0.96      0.99      0.98       108\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSSkx6l_6qo_",
        "outputId": "57800091-a28d-44c5-919e-eb83a74dfe33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **5. Comparar y Reflexionar 📊**\n",
        "\n",
        "Para facilitar el análisis, consolidamos las métricas clave (F1-Score, tiempo) y los parámetros encontrados de los tres modelos (Base, Scikit-Optimize y Hyperopt) en una única tabla. Esto nos permite visualizar de forma clara y directa cuál fue el resultado de cada enfoque."
      ],
      "metadata": {
        "id": "GYwjTFJn6qo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 5. Comparar y Reflexionar\n",
        "# =============================================================================\n",
        "print(\"\\n--- 5. Comparación y Reflexión Final ---\")\n",
        "\n",
        "# Creación de un DataFrame para comparar los resultados de manera clara\n",
        "summary = pd.DataFrame({\n",
        "    'Modelo': ['Base', 'Scikit-Optimize', 'Hyperopt'], # Nombres de los modelos evaluados.\n",
        "    'F1-Score (Test)': [f1_base, f1_skopt, f1_hyperopt], # Métrica de rendimiento clave.\n",
        "    'Tiempo de Optimización (s)': [0, exec_time_skopt, exec_time_hyperopt], # Eficiencia computacional.\n",
        "    'Mejores Parámetros': [ # Hiperparámetros que generaron el mejor resultado.\n",
        "        'Default', # El modelo base usa los parámetros por defecto.\n",
        "        str(opt_skopt.best_params_), # Parámetros encontrados por Scikit-Optimize.\n",
        "        str(best_params_hyperopt) # Parámetros encontrados por Hyperopt.\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Formatea las columnas numéricas para una mejor lectura\n",
        "summary['F1-Score (Test)'] = summary['F1-Score (Test)'].apply(lambda x: f\"{x:.4f}\")\n",
        "summary['Tiempo de Optimización (s)'] = summary['Tiempo de Optimización (s)'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Imprime la tabla de resumen\n",
        "# Establece la opción para mostrar el contenido completo de las columnas\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(\"\\nTabla Comparativa de Resultados:\")\n",
        "print(summary)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 5. Comparación y Reflexión Final ---\n",
            "\n",
            "Tabla Comparativa de Resultados:\n",
            "            Modelo F1-Score (Test) Tiempo de Optimización (s)  \\\n",
            "0             Base          0.9706                       0.00   \n",
            "1  Scikit-Optimize          0.9706                      78.68   \n",
            "2         Hyperopt          0.9706                      51.01   \n",
            "\n",
            "                                                                 Mejores Parámetros  \n",
            "0                                                                           Default  \n",
            "1  OrderedDict([('max_depth', 50), ('min_samples_split', 2), ('n_estimators', 50)])  \n",
            "2                     {'max_depth': 17, 'min_samples_split': 3, 'n_estimators': 66}  \n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AzHNAL66qo_",
        "outputId": "87103152-4c52-4670-c63a-99d17b508417"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qué técnica fue más efectiva y por qué.  \n",
        "\n",
        "### **Análisis de Efectividad: Scikit-Optimize vs. Hyperopt**\n",
        "\n",
        "Para determinar qué técnica fue más efectiva, debemos evaluar los resultados desde tres perspectivas clave: la **calidad predictiva del modelo final**, la **eficiencia computacional** del proceso de optimización y la **simplicidad** de la solución.\n",
        "\n",
        "#### **1. Calidad Predictiva (F1-Score)**\n",
        "\n",
        "Este es el criterio más importante. El objetivo de la optimización es encontrar un modelo que generalice mejor y, por lo tanto, tenga un mejor rendimiento en datos no vistos.\n",
        "\n",
        "* **Modelo Base:** F1-Score = 0.9706\n",
        "* **Modelo con Scikit-Optimize:** F1-Score = 0.9706\n",
        "* **Modelo con Hyperopt:** F1-Score = 0.9706\n",
        "\n",
        "**Análisis:**\n",
        "Sorprendentemente, ambas técnicas de optimización bayesiana encontraron combinaciones de hiperparámetros que resultaron en un **F1-Score idéntico** al del modelo base. Esto nos lleva a una conclusión fundamental: para este dataset y con la métrica F1-Score, los parámetros por defecto del `RandomForestClassifier` de Scikit-learn ya son excepcionalmente buenos.\n",
        "\n",
        "Desde el punto de vista del rendimiento puro, **hay un triple empate**. Ninguna técnica de optimización logró superar al modelo base, lo que significa que el costo computacional de la optimización no se tradujo en una mejora predictiva.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Eficiencia Computacional (Tiempo de Optimización)**\n",
        "\n",
        "Si varias técnicas alcanzan el mismo nivel de rendimiento, la siguiente medida de efectividad es la rapidez con la que lo logran.\n",
        "\n",
        "* **Scikit-Optimize:** 78.68 segundos\n",
        "* **Hyperopt:** 51.01 segundos\n",
        "\n",
        "**Análisis:**\n",
        "Aquí hay un claro ganador. **Hyperopt fue significativamente más eficiente que Scikit-Optimize**. Logró encontrar una combinación de hiperparámetros con el mismo rendimiento máximo en solo **51.01 segundos**, mientras que Scikit-Optimize tardó **78.68 segundos**. Esto representa un **ahorro de tiempo de aproximadamente el 35%**.\n",
        "\n",
        "Esta diferencia puede deberse a la eficiencia del algoritmo subyacente (`TPE` en Hyperopt) o a la forma en que explora el espacio de búsqueda. En esta ejecución, Hyperopt navegó por el espacio de hiperparámetros de manera más efectiva para llegar a una solución óptima más rápidamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Simplicidad de la Solución (Análisis de Hiperparámetros)**\n",
        "\n",
        "* **Scikit-Optimize:** `max_depth=50`, `min_samples_split=2`, `n_estimators=50`\n",
        "* **Hyperopt:** `max_depth=17`, `min_samples_split=3`, `n_estimators=66`\n",
        "\n",
        "**Análisis:**\n",
        "Ambas librerías encontraron soluciones diferentes para el mismo problema, lo que demuestra que en el espacio de hiperparámetros pueden existir múltiples \"picos\" de rendimiento similar.\n",
        "* **Scikit-Optimize** optó por un modelo con árboles muy profundos (`max_depth=50`) pero menos numerosos (`n_estimators=50`).\n",
        "* **Hyperopt** prefirió un modelo con árboles más restringidos en profundidad (`max_depth=17`) pero compensado con un mayor número de ellos (`n_estimators=66`). Un modelo con menor profundidad máxima como el de Hyperopt suele ser menos propenso al sobreajuste, lo que podría considerarse una ventaja teórica, aunque en la práctica no se reflejó en un mejor F1-Score.\n",
        "\n",
        "---\n",
        "\n",
        "### **¿Qué técnica fue más efectiva?**\n",
        "\n",
        "La respuesta depende de cómo definas \"efectividad\":\n",
        "\n",
        "* Si la **efectividad se mide únicamente por la calidad del modelo final (F1-Score)**, entonces **ninguna fue más efectiva que la otra, ni siquiera que el modelo base**. Todas llegaron al mismo techo de rendimiento. En este escenario, el enfoque más efectivo sería, irónicamente, no optimizar y usar el modelo base, ahorrando tiempo y recursos.\n",
        "\n",
        "* Si la **efectividad se mide por la capacidad de encontrar la mejor solución posible de la manera más eficiente**, entonces **Hyperopt fue la técnica claramente superior**. Cumplió el objetivo de optimización (alcanzar el F1-Score máximo) utilizando un 35% menos de tiempo computacional que Scikit-Optimize.\n",
        "\n",
        "**Veredicto Final:**\n",
        "\n",
        "Considerando que el propósito de estas herramientas es el **proceso de optimización** en sí mismo, **Hyperopt demostró ser más efectiva en este caso particular**. Fue más rápida y, por lo tanto, más eficiente en el uso de recursos para lograr el mismo resultado de alta calidad."
      ],
      "metadata": {
        "id": "T-E3DFgoCzmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **6. Documentación y presentación ✍️**\n",
        "### **Conclusiones: Optimización Bayesiana vs. Técnicas Tradicionales (Grid Search y Random Search)**\n",
        "\n",
        "La elección de una técnica de optimización de hiperparámetros es una de las decisiones más críticas para maximizar el rendimiento de un modelo de Machine Learning. Si bien las técnicas tradicionales como Grid Search y Random Search son populares por su simplicidad, la Optimización Bayesiana representa un paradigma fundamentalmente más avanzado e inteligente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **El Paradigma de Búsqueda: La Diferencia Fundamental 🧠**\n",
        "\n",
        "Para entender por qué la Optimización Bayesiana es superior, es crucial analizar cómo funciona cada método \"bajo el capó\".\n",
        "\n",
        "1.  **Grid Search (Búsqueda en Rejilla - El Enfoque de Fuerza Bruta):**\n",
        "    * **¿Cómo funciona?:** Define una \"rejilla\" discreta de valores para cada hiperparámetro y prueba, de manera exhaustiva, **todas las combinaciones posibles**.\n",
        "    * **Su Debilidad:** Es un método \"ciego\" y terriblemente ineficiente. No aprende de las evaluaciones anteriores. Si una región del espacio de búsqueda produce resultados consistentemente malos, Grid Search seguirá perdiendo tiempo en ella. Su costo computacional crece exponencialmente con cada nuevo hiperparámetro (la \"maldición de la dimensionalidad\"), haciéndolo inviable para problemas complejos.\n",
        "\n",
        "2.  **Random Search (Búsqueda Aleatoria - El Enfoque Estocástico):**\n",
        "    * **¿Cómo funciona?:** En lugar de probar todo, selecciona un número fijo de combinaciones de hiperparámetros de manera aleatoria dentro de un espacio definido.\n",
        "    * **Su Ventaja y Debilidad:** Es más eficiente que Grid Search porque no se atasca explorando una dimensión de hiperparámetros sin importancia. Sin embargo, también es un método \"ciego\". Cada prueba es un evento independiente; no utiliza la información de los resultados anteriores para guiar su próxima elección. Esencialmente, es como buscar un tesoro en un campo enorme cerrando los ojos y eligiendo lugares al azar.\n",
        "\n",
        "3.  **Optimización Bayesiana (Búsqueda Inteligente - El Enfoque Informado):**\n",
        "    * **¿Cómo funciona?:** Trata la optimización como un problema de inferencia estadística. Funciona en un ciclo de dos pasos:\n",
        "        1.  **Construye un Modelo Sustituto (Surrogate Model):** Crea un modelo probabilístico interno (comúnmente un Proceso Gaussiano) que funciona como un \"mapa\" de cómo los hiperparámetros probablemente afectan la puntuación del modelo. Este mapa se actualiza con cada nueva evaluación, volviéndose más preciso con el tiempo.\n",
        "        2.  **Usa una Función de Adquisición (Acquisition Function):** Este es el \"cerebro\" del proceso. Utiliza el mapa del modelo sustituto para decidir qué combinación de hiperparámetros probar a continuación. Lo hace equilibrando inteligentemente dos objetivos:\n",
        "            * **Explotación (Exploitation):** Probar en áreas donde el modelo sustituto predice un alto rendimiento (cerca de los mejores resultados encontrados hasta ahora).\n",
        "            * **Exploración (Exploration):** Probar en áreas de alta incertidumbre, donde el modelo sabe poco pero podría haber un pico de rendimiento oculto.\n",
        "    * **Su Fortaleza:** Este enfoque es **informado**. Cada prueba está estratégicamente elegida para maximizar lo que se aprende sobre el espacio de búsqueda. No pierde tiempo en regiones poco prometedoras y se enfoca rápidamente en las áreas que importan.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Comparativa Directa: Ventajas y Desventajas 📊**\n",
        "\n",
        "| Criterio | Grid Search | Random Search | Optimización Bayesiana |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Eficiencia Computacional** | **Muy Baja.** Inviable para más de 3-4 hiperparámetros. | **Media.** Mucho mejor que Grid Search. Eficaz con un presupuesto fijo. | **Muy Alta.** Diseñada para encontrar óptimos en el menor número de iteraciones posible. |\n",
        "| **Calidad de la Solución** | **Variable.** Solo garantiza el óptimo si está en la rejilla y se tiene tiempo infinito. | **Buena.** A menudo encuentra soluciones muy buenas de forma rápida. | **Excelente.** Tiende a encontrar soluciones mejores o iguales que Random Search, pero con menos iteraciones. |\n",
        "| **Proceso de Búsqueda** | Ciego y exhaustivo. | Ciego y aleatorio. | **Informado y adaptativo.** |\n",
        "| **Implementación** | Muy fácil (integrado en `sklearn`). | Muy fácil (integrado en `sklearn`). | Fácil/Intermedia (requiere librerías como `scikit-optimize` o `hyperopt`). |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Conclusión Final: ¿Cuándo Usar Cada Técnica? 🎯**\n",
        "\n",
        "* **Usa Grid Search si...** tienes un espacio de búsqueda extremadamente pequeño (ej. 2 hiperparámetros con 3 valores cada uno) y quieres probar absolutamente todo por completitud. En la práctica, su uso hoy en día es muy limitado y generalmente no se recomienda.\n",
        "\n",
        "* **Usa Random Search si...** necesitas un método rápido, fácil de implementar y que ofrezca una mejora sustancial sobre los parámetros por defecto. Es un excelente **punto de partida** o *baseline* para cualquier problema de optimización. Si el coste de evaluar tu modelo es bajo, Random Search puede ser suficiente.\n",
        "\n",
        "* **Usa Optimización Bayesiana si...**\n",
        "    * **El rendimiento del modelo es crítico.** Quieres exprimir hasta la última gota de potencial de tu clasificador.\n",
        "    * **El coste de cada evaluación (entrenamiento del modelo) es alto.** Esto es clave para modelos como redes neuronales profundas, ensambles grandes o al trabajar con datasets masivos. El ahorro de unas pocas docenas de iteraciones puede significar horas o días de cómputo.\n",
        "    * **Estás trabajando en un problema complejo** con muchos hiperparámetros que interactúan de formas no lineales.\n",
        "\n",
        "En resumen, mientras que Random Search democratizó la optimización haciéndola más eficiente que Grid Search, la **Optimización Bayesiana representa el siguiente paso evolutivo, cambiando de un enfoque de \"fuerza bruta\" a uno de \"estrategia inteligente\"**. Para cualquier proyecto serio de Machine Learning, es la técnica preferida para lograr resultados de vanguardia."
      ],
      "metadata": {
        "id": "5L6SNxYJEhtV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWpUaqWvC_Ja"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}