# An√°lisis de Componentes Principales (PCA) para Reducci√≥n de Dimensionalidad

Este proyecto presenta un an√°lisis detallado de la t√©cnica de Reducci√≥n de Dimensionalidad mediante An√°lisis de Componentes Principales (PCA). Utilizando el dataset "Wine", el notebook demuestra un flujo de trabajo completo, desde la preparaci√≥n y estandarizaci√≥n de los datos hasta la evaluaci√≥n del impacto de PCA en un modelo predictivo.

-----

### üéØ **Objetivo Principal**

  - **Prop√≥sito:** Demostrar la implementaci√≥n, fundamentaci√≥n te√≥rica y aplicaci√≥n pr√°ctica de PCA para simplificar un dataset multivariado, facilitar su visualizaci√≥n y evaluar su efecto en el rendimiento de un modelo de clasificaci√≥n.
  - **Problema de Negocio:** Determinar si es posible reducir la complejidad de un dataset (disminuyendo el n√∫mero de caracter√≠sticas) sin sacrificar, e incluso mejorando, la precisi√≥n de un modelo predictivo.

### üìä **Dataset Utilizado**

  - **Nombre:** Wine
  - **Fuente:** Repositorio de datasets de `scikit-learn`.

### üõ†Ô∏è **Metodolog√≠a y Modelos Aplicados**

El proyecto sigue un flujo de trabajo estructurado que incluye:

1.  **An√°lisis Exploratorio y Preprocesamiento:** Carga del dataset "Wine", seguido de una **estandarizaci√≥n** (`StandardScaler`) para asegurar que todas las caracter√≠sticas tengan la misma escala, un paso crucial para PCA.
2.  **An√°lisis de Varianza:** Se aplica PCA sobre el dataset completo para analizar la **varianza explicada** por cada componente principal y determinar el n√∫mero √≥ptimo de dimensiones a conservar.
3.  **Reducci√≥n y Visualizaci√≥n:** El dataset se reduce a **dos componentes principales** para visualizar la separabilidad de las clases de vino en un plano 2D mediante gr√°ficos de dispersi√≥n, densidad y cajas.
4.  **Evaluaci√≥n Comparativa:** Se compara el rendimiento (medido con **Accuracy**) de dos modelos de clasificaci√≥n `K-Nearest Neighbors (KNN)`:
      - **Modelo Base:** Entrenado con las 13 caracter√≠sticas originales estandarizadas.
      - **Modelo con PCA:** Entrenado √∫nicamente con los 2 componentes principales extra√≠dos.

### üöÄ **Resultados y Hallazgos Principales**

  - **Efectividad de la Reducci√≥n:** Los dos primeros componentes principales (PC1 y PC2) lograron capturar el **55.4% de la varianza total**, demostrando ser suficientes para una excelente separaci√≥n visual de las tres clases de vino.
  - **Poder de Separaci√≥n:** El an√°lisis visual y de cajas revel√≥ que:
      - **PC1** act√∫a como un gran diferenciador entre la `class_0` y la `class_1`.
      - **PC2** a√≠sla eficazmente a la `class_2` del resto.
  - **Modelo Ganador üèÜ:** Sorprendentemente, el **modelo con PCA (2 dimensiones)** fue el de mejor rendimiento, alcanzando una **precisi√≥n del 96.30%**, superando ligeramente al modelo base con 13 dimensiones (94.44%).
  - **Optimizaci√≥n del Modelo:** PCA no solo simplific√≥ el modelo en un **84.6%** (de 13 a 2 caracter√≠sticas), sino que tambi√©n mejor√≥ su rendimiento al actuar como un filtro de ruido, eliminando variaciones menos relevantes.

### üèÜ **Recomendaci√≥n Final**

Se recomienda implementar **PCA como un paso de preprocesamiento** para este dataset. La t√©cnica no solo es una herramienta poderosa para la visualizaci√≥n, sino que optimiza el modelo de clasificaci√≥n, haci√©ndolo m√°s simple, eficiente y preciso al enfocarse en las caracter√≠sticas m√°s informativas.

# [**Ir al Proyecto**](../Actividad_3_PCA/Actividad_3_Modulo_6_Reducci√≥n_de_dimensionalidad_con_PCA.ipynb)

---

## ‚öôÔ∏è **C√≥mo Ejecutar el Notebook**

Para correr este proyecto en tu entorno local, sigue estos pasos:

1.  **Aseg√∫rate de tener Python 3.8 o superior.**
2.  **Clona o descarga este repositorio.**
3.  **Instala las librer√≠as necesarias:**
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn
    ```
4.  **Ejecuta el notebook de Jupyter:**
    `Actividad_3_Modulo_6_Reducci√≥n_de_dimensionalidad_con_PCA.ipynb`

---

[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos No Supervisados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_4_Segmentacion_Anomalias/README.md)
