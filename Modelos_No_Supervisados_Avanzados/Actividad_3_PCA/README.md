# Reducci√≥n de Dimensionalidad con PCA para Clasificaci√≥n de Vinos

Este proyecto demuestra la aplicaci√≥n y el poder del An√°lisis de Componentes Principales (PCA) para reducir la dimensionalidad de un conjunto de datos. El objetivo es simplificar un dataset complejo, pasando de 13 caracter√≠sticas a solo 2, y luego evaluar c√≥mo esta reducci√≥n afecta el rendimiento de un modelo de clasificaci√≥n.

---

### üéØ **Objetivo Principal**
- **Prop√≥sito:** Aplicar la t√©cnica de PCA para reducir un conjunto de datos multivariado, reteniendo la m√°xima varianza posible y facilitando la visualizaci√≥n de las clases.
- **Problema de Negocio:** Demostrar que es posible entrenar un modelo de machine learning de alta precisi√≥n utilizando un n√∫mero significativamente menor de caracter√≠sticas, lo que reduce la complejidad del modelo y los costos computacionales.

### üìä **Dataset Utilizado**
- **Nombre:** Wine Dataset
- **Fuente:** Un conjunto de datos sobre las propiedades qu√≠micas de diferentes vinos de Italia, cargado directamente desde la librer√≠a `sklearn.datasets`.

### üõ†Ô∏è **Metodolog√≠a y Modelos Aplicados**
El flujo de trabajo se centra en la transformaci√≥n de datos y la evaluaci√≥n de un modelo de clasificaci√≥n:
1.  **Preprocesamiento:** Los datos fueron estandarizados utilizando `StandardScaler`. Este es un paso crucial antes de aplicar PCA para asegurar que todas las variables contribuyan de manera equitativa.
2.  **Reducci√≥n de Dimensionalidad:** Se aplic√≥ el **An√°lisis de Componentes Principales (PCA)** para transformar las 13 caracter√≠sticas fisicoqu√≠micas originales en solo **2 componentes principales**.
3.  **Modelo de Clasificaci√≥n:** Se entren√≥ un modelo de `LogisticRegression` utilizando √∫nicamente los 2 componentes generados por PCA como caracter√≠sticas de entrada.
4.  **Evaluaci√≥n y Visualizaci√≥n:** El rendimiento del clasificador se midi√≥ con un **reporte de clasificaci√≥n** (precisi√≥n, recall, F1-score). Finalmente, se visualiz√≥ el resultado en un gr√°fico de dispersi√≥n que muestra la separaci√≥n de las clases en el nuevo espacio 2D y las fronteras de decisi√≥n aprendidas por el modelo.

### üöÄ **Resultados y Hallazgos Principales**
- **Reducci√≥n Exitosa:** PCA redujo de manera efectiva la dimensionalidad del dataset de **13 caracter√≠sticas a solo 2**.
- **Retenci√≥n de Varianza:** A pesar de la dr√°stica reducci√≥n, los dos componentes principales lograron capturar y explicar aproximadamente el **56% de la varianza** total del conjunto de datos original.
- **Rendimiento Excepcional del Modelo üèÜ:** El modelo de `LogisticRegression`, entrenado con solo 2 componentes, alcanz√≥ una impresionante **exactitud (accuracy) del 97%** en el conjunto de prueba. Esto demuestra que la informaci√≥n m√°s relevante para la clasificaci√≥n se conserv√≥ con √©xito.
- **Clara Separabilidad Visual:** El gr√°fico de dispersi√≥n de los dos componentes principales mostr√≥ una **separaci√≥n visual casi perfecta** entre las tres clases de vino, validando la efectividad de PCA para crear un nuevo espacio de caracter√≠sticas altamente informativo.

### üèÜ **Recomendaci√≥n Final**
- El **An√°lisis de Componentes Principales (PCA)** es una t√©cnica extremadamente poderosa y eficiente para la reducci√≥n de dimensionalidad. Permite simplificar modelos complejos y visualizar datos de alta dimensionalidad sin sacrificar significativamente el rendimiento predictivo.
- La estrategia de combinar **PCA para la extracci√≥n de caracter√≠sticas** con un clasificador simple como la **Regresi√≥n Log√≠stica** es un enfoque robusto y eficaz para abordar problemas de clasificaci√≥n con muchas variables.

# [**Ir al Proyecto**](../Actividad_3_PCA/Actividad_3_Modulo_6_Reducci√≥n_de_dimensionalidad_con_PCA.ipynb)

---

## ‚öôÔ∏è **C√≥mo Ejecutar el Notebook**

Para correr este proyecto en tu entorno local, sigue estos pasos:

1.  **Aseg√∫rate de tener Python 3.8 o superior.**
2.  **Clona o descarga este repositorio.**
3.  **Instala las librer√≠as necesarias:**
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn
    ```
4.  **Ejecuta el notebook de Jupyter:**
    `Actividad_3_Modulo_6_Reducci√≥n_de_dimensionalidad_con_PCA.ipynb`

---

[Volver al √≠ndice principal](../../README.md) | [Volver a Modelos No Supervisados](../README.md) | [Actividad Siguiente ‚Üí](../Actividad_4_Segmentacion_Anomalias/README.md)
